services:
  mlflow:
    container_name: neuralripper-mlflow
    build:
      context: ..
      dockerfile: docker/Dockerfile.mlflow
    ports: ["5000:5000"]
    restart: unless-stopped
    volumes: [mlflow_data:/var/lib/mlflow/mlflow-db]
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=us-west-2
    # LOCAL: just name whatever, tradition is username/repo:tag for dockerhub
    image: neuralripper/mlflow:dev

  backend:
    container_name: neuralripper-backend
    build:
      context: ..
      dockerfile: docker/Dockerfile.backend
    ports: ["8000:8000"]
    restart: unless-stopped
    environment:
      - MLFLOW_TRACKING_URI=https://neuralripper.com/mlflow  # Use production mlflow for both local dev and actual training
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=us-west-2
    # LOCAL: just name whatever, tradition is username/repo:tag for dockerhub
    image: neuralripper/backend:dev 

  frontend:
    container_name: neuralripper-frontend
    build:
      context: ..
      dockerfile: docker/Dockerfile.frontend
      args:
        AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
        AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
        VITE_API_BASE_URL: https://neuralripper.com/api
    ports: ["3000:3000"]
    restart: unless-stopped
    # LOCAL: just name whatever, tradition is username/repo:tag for dockerhub
    image: neuralripper/frontend:dev

  nginx:
    container_name: neuralripper-nginx
    build:
      context: ..
      dockerfile: docker/Dockerfile.nginx
    ports: ["80:80", "443:443"]
    restart: unless-stopped
    depends_on: [frontend, backend, mlflow]
    # LOCAL: just name whatever, tradition is username/repo:tag for dockerhub
    image: neuralripper/nginx:dev

volumes:
  mlflow_data:
