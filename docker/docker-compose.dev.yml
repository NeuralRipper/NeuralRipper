services:
  # mlflow:
  #   Local MLflow disabled - all environments share production instance at neuralripper.com/mlflow
  #   This ensures unified experiment tracking and artifact storage across local dev and production

  backend:
    container_name: neuralripper-backend
    build:
      context: ..
      dockerfile: docker/Dockerfile.backend
    ports: ["8000:8000"]
    restart: unless-stopped
    environment:
      - MLFLOW_TRACKING_URI=https://neuralripper.com/mlflow  # Use production mlflow for both local dev and actual training
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=us-east-1
    # LOCAL: just name whatever, tradition is username/repo:tag for dockerhub
    image: neuralripper/backend:dev 

  frontend:
    container_name: neuralripper-frontend
    build:
      context: ..
      dockerfile: docker/Dockerfile.frontend
      args:
        AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
        AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
        VITE_API_BASE_URL: https://neuralripper.com/api
    ports: ["3000:3000"]
    restart: unless-stopped
    # LOCAL: just name whatever, tradition is username/repo:tag for dockerhub
    image: neuralripper/frontend:dev

  nginx:
    container_name: neuralripper-nginx
    build:
      context: ..
      dockerfile: docker/Dockerfile.nginx
      args:
        AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
        AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    ports: ["80:80", "443:443"]
    restart: unless-stopped
    depends_on: [frontend, backend]
    # LOCAL: just name whatever, tradition is username/repo:tag for dockerhub
    image: neuralripper/nginx:dev
