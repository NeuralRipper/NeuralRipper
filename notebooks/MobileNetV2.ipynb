{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T07:25:59.030957Z",
     "start_time": "2025-06-30T07:25:59.026589Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "1. Transform Configuration\n",
    "\"\"\"\n",
    "from torchvision import transforms\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "2. Load Data & Analysis & Display\n",
    "\"\"\"\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torch.utils.data import Subset\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "data_root = project_root / \"data\"\n",
    "\n",
    "train_ds = CIFAR100(\n",
    "    root=data_root,\n",
    "    train=True,     # create dataset from train set, otherwise will be test set\n",
    "    transform=train_tf\n",
    ")\n",
    "\n",
    "# use small dataset to display image content\n",
    "train_ds_small = Subset(train_ds, range(100, 200))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=10, ncols=10, figsize=(32, 32))\n",
    "\n",
    "# image in tensor form | class it belongs to\n",
    "for idx, (img_tensor, cls_num) in enumerate(train_ds_small):\n",
    "    img = img_tensor.permute(1, 2, 0)       # convert image to be plotted (H, W, C)\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "       # denormalize all images back to normal\n",
    "    row, col = idx // 10, idx % 10\n",
    "    axes[row, col].imshow(img)\n",
    "    axes[row, col].set_title(f\"Class-{cls_num}\")\n",
    "\n"
   ],
   "id": "4e30fbac1adcb370",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T08:17:49.903996Z",
     "start_time": "2025-06-30T08:17:49.899746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "3. DataLoader for torch\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=128,         # IMPORTANT: must match what we use in the model params!!!\n",
    "    shuffle=True,\n",
    "    num_workers=0,          # MPS and multiprocessing don't work well together, might slow down\n",
    "    pin_memory=False        # Important for MPS       TODO: understand this\n",
    ")\n",
    "print(f\"[ALL]Training dataset size: {len(train_ds)}\")"
   ],
   "id": "7fd916dda7ab1780",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALL]Training dataset size: 50000\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T08:17:50.569315Z",
     "start_time": "2025-06-30T08:17:50.564530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up loggings\n",
    "import logging, time, sys\n",
    "\n",
    "format = '%(asctime)s - %(levelname)s - %(filename)s - PID:%(process)d - TID:%(thread)d - %(message)s'\n",
    "logger = logging.getLogger(__name__ + str(time.time()))     # in jupyter notebook, avoid accumulating multiple loggers\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = False  # create a logger with getLogger(__name__), it sends messages to both your custom handler AND the root logger by default. Setting propagate = False stops this behavior.\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(logging.Formatter(format))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.debug(\"Logger Initialization Completed\")"
   ],
   "id": "f20f2f15c8db1c33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-30 01:17:50,566 - DEBUG - 1454778220.py - PID:3660 - TID:8784977664 - Logger Initialization Completed\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T08:31:42.290075Z",
     "start_time": "2025-06-30T08:31:42.274815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "4. Define Model\n",
    "\"\"\"\n",
    "\n",
    "from torch import nn, optim\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "import torchvision\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "\n",
    "class MyMobileNetV2(nn.Module):\n",
    "    def __init__(self, num_epochs=10, batch_size=32, num_classes=100, learning_rate=5e-3, use_mlflow=True):\n",
    "        super().__init__()\n",
    "        self._num_classes = num_classes     # by default 100 for CIFAR100\n",
    "        self._use_mlflow = use_mlflow\n",
    "        self._best_acc = -1     # use to compare the current best accuracy\n",
    "\n",
    "        # Model skeleton\n",
    "        self._model = torchvision.models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "        # IMAGENET classifier (input layer, output layer)\n",
    "        # Sequential((0): Dropout(p=0.2, inplace=True)\n",
    "        #            (1): Linear(in_features=1280, out_features=1000, bias=True))\n",
    "        # replaces to 100 classes to fit CIFAR100\n",
    "        self._model.classifier[1] = nn.Linear(1280, 100)\n",
    "\n",
    "        self._device = self._set_device()\n",
    "        # set it to device setup; by default, model weights are on CPU, and input data is on MPS device\n",
    "        self._model.to(self._device)\n",
    "\n",
    "        # Hyperparameters\n",
    "        self._batch_size = batch_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        # Loss function & Optimizer\n",
    "        self._criterion = self._set_criterion()\n",
    "        self._optimizer = self._set_optimizer()\n",
    "\n",
    "    def _set_device(self):\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    def _set_optimizer(self):\n",
    "        # TODO: SGD understanding, along with Adam\n",
    "        return optim.SGD(self._model.parameters(), lr=5e-3, momentum=0.9, weight_decay=4e-5)\n",
    "\n",
    "    def _set_criterion(self):\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    @property\n",
    "    def optimizer(self):\n",
    "        return self._optimizer.__class__.__name__\n",
    "\n",
    "    # Train Epoch for 1 Loop\n",
    "    def train_epoch(self, data_loader, epoch_idx):\n",
    "        \"\"\"\n",
    "        1. Prediction: tensor.shape = [1, 32], 32 samples\n",
    "        Original tensor: [32, 100], 32 samples in one batch, 100 classes in each sample\n",
    "        2. Mask tensor is boolean tenser in [32, 100], True/False\n",
    "        3. Use argmax column direction, we get [32, 1], the index of the largest probability in each sample\n",
    "        4. All the prediction, targets, loss, are tensor objects\n",
    "\n",
    "        Args:\n",
    "            data_loader: pytorch DataLoader instance for image iteration\n",
    "            epoch_idx: current epoch number\n",
    "        Return:\n",
    "            epoch_loss: the average loss for current epoch: total loss / total batches\n",
    "            epoch_acc: the average accuracy for current epoch: total correct prediction / total true labels\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting epoch {epoch_idx+1}, total batches: {len(data_loader)}\")\n",
    "\n",
    "        # Set model mode to train, so the Dropout, BatchNorm are up to work\n",
    "        self._model.train()\n",
    "        epoch_total_loss = 0.0  # Track full epoch\n",
    "        running_loss = 0.0      # Track 10-batch average\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        for idx, (images, targets) in enumerate(data_loader):\n",
    "            images = images.to(self._device)\n",
    "            # labels represented in int, not one-hot encoding\n",
    "            targets = targets.to(self._device)\n",
    "            # Clears(Reset) accumulated gradients from the previous iteration\n",
    "            self._optimizer.zero_grad()\n",
    "            # inference result from the model, it will auto call forward(images)\n",
    "            logits = self._model(images)\n",
    "            # Calculate the loss, compare Inference Prediction vs. True Labels\n",
    "            loss = self._criterion(logits, targets)\n",
    "            # backtrack to update the gradients\n",
    "            loss.backward()\n",
    "            # Update weights and parameters using latest gradients from backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            predictions = logits.argmax(dim=1)\n",
    "\n",
    "            # how many predictions match true labels\n",
    "            running_correct += (predictions == targets).sum().item()\n",
    "            # total number of the true labels\n",
    "            running_total += targets.size(0)\n",
    "            running_loss += loss.item()\n",
    "            epoch_total_loss += loss.item()\n",
    "\n",
    "            # print out progress every 10 batches\n",
    "            if idx % 10 == 9:\n",
    "                avg_loss = running_loss / 10\n",
    "                curr_acc = running_correct / running_total\n",
    "                logger.info(f\"Epoch {epoch_idx + 1}| Batch {idx + 1} | Avg Loss {avg_loss: .4f} | Accuracy: {curr_acc:.4f}\")\n",
    "                running_loss = 0.0      # reset for every 10 batches\n",
    "\n",
    "        # return loss and accuracy for current training epoch\n",
    "        epoch_loss = epoch_total_loss / len(data_loader)     # total loss / total batches\n",
    "        epoch_acc = running_correct / running_total     # total correct prediction / total true labels\n",
    "\n",
    "        logger.info(f\"Epoch loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    # MLFlow Setup\n",
    "    def _setup_mlflow(self):\n",
    "        \"\"\"Initialize Mlflow experiment and log parameters\"\"\"\n",
    "        mlflow.set_tracking_uri(\"http://127.0.0.1:5555\")\n",
    "        # setup name of experiment\n",
    "        mlflow.set_experiment(f\"{self._model.__class__.__name__}-{train_ds.__class__.__name__}\")\n",
    "        # this will start a global state for all the mflow.log_*()\n",
    "        mlflow.start_run(run_name=datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "        mlflow.log_params({\n",
    "            \"model\": self._model.__class__.__name__,\n",
    "            \"dataset\": train_ds.__class__.__name__,\n",
    "            \"batch_size\": self._batch_size,\n",
    "            \"learning_rate\": self._learning_rate,\n",
    "            \"epochs\": self._num_epochs,\n",
    "            \"device\": self._device.type,\n",
    "            \"optimizer\": self._optimizer.__class__.__name__,\n",
    "            \"num_classes\": self._num_classes\n",
    "        })\n",
    "\n",
    "    def _log_metrics(self, epoch, epoch_loss, epoch_acc):\n",
    "        \"\"\"Log metrics to Mlflow\"\"\"\n",
    "        if not self._use_mlflow:\n",
    "            return\n",
    "\n",
    "        metrics = {\n",
    "            \"train_loss\": epoch_loss,\n",
    "            \"train_accuracy\": epoch_acc,\n",
    "            \"learning_rate\": self._optimizer.param_groups[0][\"lr\"]\n",
    "        }\n",
    "\n",
    "        mlflow.log_metrics(metrics, step=epoch)\n",
    "\n",
    "    def _log_best_model(self, epoch_acc):\n",
    "        \"\"\"Log model if it's the best so far\"\"\"\n",
    "        if not self._use_mlflow:\n",
    "            return\n",
    "\n",
    "        # Only log current model if the accuracy is better\n",
    "        if epoch_acc <= self._best_acc:\n",
    "            return\n",
    "        # update to better accuracy\n",
    "        self._best_acc = epoch_acc\n",
    "\n",
    "        # TODO: understand this\n",
    "        # FIX: Set to eval mode for signature creation\n",
    "        self._model.eval()\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.randn(1, 3, 224, 224).to(self._device)\n",
    "            signature = infer_signature(\n",
    "                    sample_input.cpu().numpy(),\n",
    "                    self._model(sample_input).detach().cpu().numpy()\n",
    "            )\n",
    "        self._model.train()   # Return to training mode\n",
    "\n",
    "        # Log the model, the first one will always log, then keep overriding for better ones\n",
    "        mlflow.pytorch.log_model(\n",
    "            self._model,\n",
    "            artifact_path=\"best_model\",\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        \"\"\"Main training loop with Mlflow integration\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Training {self._num_epochs} epochs on {self._device}\")\n",
    "            # init mlflow, new run & experiment\n",
    "            if self._use_mlflow:\n",
    "                self._setup_mlflow()\n",
    "\n",
    "            for epoch in range(self._num_epochs):\n",
    "                epoch_loss, epoch_acc = self.train_epoch(train_loader, epoch)\n",
    "                logger.info(f\"Epoch {epoch + 1}/{self._num_epochs}: Avg Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "                # log metrics to mlflow\n",
    "                if self._use_mlflow:\n",
    "                    self._log_metrics(epoch, epoch_loss, epoch_acc)\n",
    "\n",
    "                # update current best model to gcs\n",
    "                self._log_best_model(epoch_acc)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Train process failed, error: {e}\")\n",
    "        finally:\n",
    "            if self._use_mlflow:\n",
    "                logger.debug(\"Mlflow: Ending current run...\")\n",
    "                mlflow.end_run()\n",
    "                logger.debug(\"Mlflow: current run ended successfully\")\n"
   ],
   "id": "dd7605be244cdc01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T08:21:45.624980Z",
     "start_time": "2025-06-30T08:17:58.597516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "5. Train\n",
    "\"\"\"\n",
    "\n",
    "m = MyMobileNetV2(batch_size=128, num_epochs=10)\n",
    "m.train(train_loader)\n"
   ],
   "id": "ece8e3199f27bd14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-30 01:17:58,729 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Training 10 epochs on mps\n",
      "2025-06-30 01:17:58,770 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 1, total batches: 391\n",
      "2025-06-30 01:18:00,645 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 10 | Avg Loss  4.6819 | Accuracy: 0.0141\n",
      "2025-06-30 01:18:01,100 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 20 | Avg Loss  4.6430 | Accuracy: 0.0141\n",
      "2025-06-30 01:18:01,552 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 30 | Avg Loss  4.5995 | Accuracy: 0.0133\n",
      "2025-06-30 01:18:02,009 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 40 | Avg Loss  4.5748 | Accuracy: 0.0146\n",
      "2025-06-30 01:18:02,465 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 50 | Avg Loss  4.5199 | Accuracy: 0.0208\n",
      "2025-06-30 01:18:02,919 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 60 | Avg Loss  4.5120 | Accuracy: 0.0247\n",
      "2025-06-30 01:18:03,377 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 70 | Avg Loss  4.4592 | Accuracy: 0.0283\n",
      "2025-06-30 01:18:03,833 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 80 | Avg Loss  4.4047 | Accuracy: 0.0334\n",
      "2025-06-30 01:18:04,300 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 90 | Avg Loss  4.3308 | Accuracy: 0.0368\n",
      "2025-06-30 01:18:04,759 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 100 | Avg Loss  4.2876 | Accuracy: 0.0399\n",
      "2025-06-30 01:18:05,263 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 110 | Avg Loss  4.2055 | Accuracy: 0.0445\n",
      "2025-06-30 01:18:05,730 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 120 | Avg Loss  4.1015 | Accuracy: 0.0499\n",
      "2025-06-30 01:18:06,239 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 130 | Avg Loss  4.0823 | Accuracy: 0.0532\n",
      "2025-06-30 01:18:06,756 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 140 | Avg Loss  4.0093 | Accuracy: 0.0564\n",
      "2025-06-30 01:18:07,218 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 150 | Avg Loss  3.8597 | Accuracy: 0.0611\n",
      "2025-06-30 01:18:07,713 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 160 | Avg Loss  3.8318 | Accuracy: 0.0655\n",
      "2025-06-30 01:18:08,192 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 170 | Avg Loss  3.7451 | Accuracy: 0.0704\n",
      "2025-06-30 01:18:08,677 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 180 | Avg Loss  3.7690 | Accuracy: 0.0746\n",
      "2025-06-30 01:18:09,168 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 190 | Avg Loss  3.6151 | Accuracy: 0.0801\n",
      "2025-06-30 01:18:09,635 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 200 | Avg Loss  3.5708 | Accuracy: 0.0847\n",
      "2025-06-30 01:18:10,152 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 210 | Avg Loss  3.4783 | Accuracy: 0.0894\n",
      "2025-06-30 01:18:10,613 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 220 | Avg Loss  3.4726 | Accuracy: 0.0938\n",
      "2025-06-30 01:18:11,074 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 230 | Avg Loss  3.4306 | Accuracy: 0.0984\n",
      "2025-06-30 01:18:11,535 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 240 | Avg Loss  3.3406 | Accuracy: 0.1035\n",
      "2025-06-30 01:18:11,991 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 250 | Avg Loss  3.3352 | Accuracy: 0.1078\n",
      "2025-06-30 01:18:12,448 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 260 | Avg Loss  3.2431 | Accuracy: 0.1127\n",
      "2025-06-30 01:18:12,906 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 270 | Avg Loss  3.3112 | Accuracy: 0.1159\n",
      "2025-06-30 01:18:13,365 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 280 | Avg Loss  3.2253 | Accuracy: 0.1199\n",
      "2025-06-30 01:18:13,891 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 290 | Avg Loss  3.1559 | Accuracy: 0.1248\n",
      "2025-06-30 01:18:14,363 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 300 | Avg Loss  3.1686 | Accuracy: 0.1284\n",
      "2025-06-30 01:18:14,821 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 310 | Avg Loss  3.1357 | Accuracy: 0.1315\n",
      "2025-06-30 01:18:15,281 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 320 | Avg Loss  3.0288 | Accuracy: 0.1353\n",
      "2025-06-30 01:18:15,738 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 330 | Avg Loss  3.0441 | Accuracy: 0.1392\n",
      "2025-06-30 01:18:16,199 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 340 | Avg Loss  3.0522 | Accuracy: 0.1427\n",
      "2025-06-30 01:18:16,657 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 350 | Avg Loss  2.9868 | Accuracy: 0.1462\n",
      "2025-06-30 01:18:17,114 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 360 | Avg Loss  2.9742 | Accuracy: 0.1497\n",
      "2025-06-30 01:18:17,572 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 370 | Avg Loss  2.9121 | Accuracy: 0.1535\n",
      "2025-06-30 01:18:18,029 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 380 | Avg Loss  2.9283 | Accuracy: 0.1565\n",
      "2025-06-30 01:18:18,486 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1| Batch 390 | Avg Loss  2.9413 | Accuracy: 0.1595\n",
      "2025-06-30 01:18:19,035 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 3.6900, Accuracy: 0.1596\n",
      "2025-06-30 01:18:19,035 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 1/10: Avg Loss: 3.6900 | Accuracy: 0.1596\n",
      "2025-06-30 01:18:25,700 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 2, total batches: 391\n",
      "2025-06-30 01:18:26,218 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 10 | Avg Loss  2.8344 | Accuracy: 0.2922\n",
      "2025-06-30 01:18:26,676 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 20 | Avg Loss  2.7647 | Accuracy: 0.3031\n",
      "2025-06-30 01:18:27,132 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 30 | Avg Loss  2.7897 | Accuracy: 0.3073\n",
      "2025-06-30 01:18:27,588 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 40 | Avg Loss  2.8181 | Accuracy: 0.3041\n",
      "2025-06-30 01:18:28,045 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 50 | Avg Loss  2.8012 | Accuracy: 0.3034\n",
      "2025-06-30 01:18:28,502 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 60 | Avg Loss  2.6973 | Accuracy: 0.3060\n",
      "2025-06-30 01:18:28,959 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 70 | Avg Loss  2.7307 | Accuracy: 0.3064\n",
      "2025-06-30 01:18:29,417 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 80 | Avg Loss  2.7498 | Accuracy: 0.3057\n",
      "2025-06-30 01:18:29,876 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 90 | Avg Loss  2.7451 | Accuracy: 0.3078\n",
      "2025-06-30 01:18:30,332 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 100 | Avg Loss  2.7006 | Accuracy: 0.3085\n",
      "2025-06-30 01:18:30,790 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 110 | Avg Loss  2.6623 | Accuracy: 0.3094\n",
      "2025-06-30 01:18:31,246 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 120 | Avg Loss  2.6749 | Accuracy: 0.3099\n",
      "2025-06-30 01:18:31,705 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 130 | Avg Loss  2.6552 | Accuracy: 0.3103\n",
      "2025-06-30 01:18:32,162 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 140 | Avg Loss  2.6697 | Accuracy: 0.3108\n",
      "2025-06-30 01:18:32,620 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 150 | Avg Loss  2.5725 | Accuracy: 0.3130\n",
      "2025-06-30 01:18:33,078 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 160 | Avg Loss  2.5958 | Accuracy: 0.3146\n",
      "2025-06-30 01:18:33,537 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 170 | Avg Loss  2.6794 | Accuracy: 0.3146\n",
      "2025-06-30 01:18:33,994 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 180 | Avg Loss  2.4970 | Accuracy: 0.3164\n",
      "2025-06-30 01:18:34,451 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 190 | Avg Loss  2.5134 | Accuracy: 0.3181\n",
      "2025-06-30 01:18:34,910 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 200 | Avg Loss  2.4738 | Accuracy: 0.3204\n",
      "2025-06-30 01:18:35,368 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 210 | Avg Loss  2.4865 | Accuracy: 0.3226\n",
      "2025-06-30 01:18:35,826 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 220 | Avg Loss  2.5262 | Accuracy: 0.3237\n",
      "2025-06-30 01:18:36,290 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 230 | Avg Loss  2.5219 | Accuracy: 0.3255\n",
      "2025-06-30 01:18:36,748 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 240 | Avg Loss  2.5122 | Accuracy: 0.3268\n",
      "2025-06-30 01:18:37,204 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 250 | Avg Loss  2.5013 | Accuracy: 0.3279\n",
      "2025-06-30 01:18:37,662 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 260 | Avg Loss  2.4414 | Accuracy: 0.3293\n",
      "2025-06-30 01:18:38,119 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 270 | Avg Loss  2.5269 | Accuracy: 0.3299\n",
      "2025-06-30 01:18:38,576 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 280 | Avg Loss  2.4489 | Accuracy: 0.3311\n",
      "2025-06-30 01:18:39,033 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 290 | Avg Loss  2.4901 | Accuracy: 0.3319\n",
      "2025-06-30 01:18:39,492 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 300 | Avg Loss  2.4639 | Accuracy: 0.3330\n",
      "2025-06-30 01:18:39,950 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 310 | Avg Loss  2.5084 | Accuracy: 0.3335\n",
      "2025-06-30 01:18:40,411 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 320 | Avg Loss  2.4566 | Accuracy: 0.3343\n",
      "2025-06-30 01:18:40,872 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 330 | Avg Loss  2.4094 | Accuracy: 0.3356\n",
      "2025-06-30 01:18:41,332 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 340 | Avg Loss  2.4013 | Accuracy: 0.3369\n",
      "2025-06-30 01:18:41,791 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 350 | Avg Loss  2.4283 | Accuracy: 0.3377\n",
      "2025-06-30 01:18:42,327 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 360 | Avg Loss  2.3544 | Accuracy: 0.3394\n",
      "2025-06-30 01:18:42,872 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 370 | Avg Loss  2.3306 | Accuracy: 0.3408\n",
      "2025-06-30 01:18:43,401 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 380 | Avg Loss  2.3260 | Accuracy: 0.3425\n",
      "2025-06-30 01:18:43,937 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2| Batch 390 | Avg Loss  2.3494 | Accuracy: 0.3438\n",
      "2025-06-30 01:18:43,979 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 2.5673, Accuracy: 0.3437\n",
      "2025-06-30 01:18:43,979 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 2/10: Avg Loss: 2.5673 | Accuracy: 0.3437\n",
      "2025-06-30 01:18:48,079 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 3, total batches: 391\n",
      "2025-06-30 01:18:48,581 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 10 | Avg Loss  2.2507 | Accuracy: 0.4070\n",
      "2025-06-30 01:18:49,036 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 20 | Avg Loss  2.2368 | Accuracy: 0.3988\n",
      "2025-06-30 01:18:49,494 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 30 | Avg Loss  2.3252 | Accuracy: 0.3956\n",
      "2025-06-30 01:18:49,951 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 40 | Avg Loss  2.2207 | Accuracy: 0.4020\n",
      "2025-06-30 01:18:50,408 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 50 | Avg Loss  2.2574 | Accuracy: 0.4033\n",
      "2025-06-30 01:18:50,864 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 60 | Avg Loss  2.2526 | Accuracy: 0.4051\n",
      "2025-06-30 01:18:51,321 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 70 | Avg Loss  2.2131 | Accuracy: 0.4064\n",
      "2025-06-30 01:18:51,778 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 80 | Avg Loss  2.2696 | Accuracy: 0.4052\n",
      "2025-06-30 01:18:52,235 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 90 | Avg Loss  2.2155 | Accuracy: 0.4052\n",
      "2025-06-30 01:18:52,693 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 100 | Avg Loss  2.3081 | Accuracy: 0.4056\n",
      "2025-06-30 01:18:53,150 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 110 | Avg Loss  2.2512 | Accuracy: 0.4050\n",
      "2025-06-30 01:18:53,606 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 120 | Avg Loss  2.1883 | Accuracy: 0.4068\n",
      "2025-06-30 01:18:54,062 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 130 | Avg Loss  2.1716 | Accuracy: 0.4075\n",
      "2025-06-30 01:18:54,519 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 140 | Avg Loss  2.1987 | Accuracy: 0.4078\n",
      "2025-06-30 01:18:54,975 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 150 | Avg Loss  2.1335 | Accuracy: 0.4097\n",
      "2025-06-30 01:18:55,433 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 160 | Avg Loss  2.2264 | Accuracy: 0.4101\n",
      "2025-06-30 01:18:55,890 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 170 | Avg Loss  2.2143 | Accuracy: 0.4107\n",
      "2025-06-30 01:18:56,347 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 180 | Avg Loss  2.1580 | Accuracy: 0.4113\n",
      "2025-06-30 01:18:56,804 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 190 | Avg Loss  2.1705 | Accuracy: 0.4113\n",
      "2025-06-30 01:18:57,261 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 200 | Avg Loss  2.1622 | Accuracy: 0.4116\n",
      "2025-06-30 01:18:57,718 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 210 | Avg Loss  2.3082 | Accuracy: 0.4105\n",
      "2025-06-30 01:18:58,174 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 220 | Avg Loss  2.2581 | Accuracy: 0.4103\n",
      "2025-06-30 01:18:58,631 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 230 | Avg Loss  2.1363 | Accuracy: 0.4109\n",
      "2025-06-30 01:18:59,087 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 240 | Avg Loss  2.1573 | Accuracy: 0.4116\n",
      "2025-06-30 01:18:59,544 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 250 | Avg Loss  2.1923 | Accuracy: 0.4123\n",
      "2025-06-30 01:19:00,001 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 260 | Avg Loss  2.2708 | Accuracy: 0.4118\n",
      "2025-06-30 01:19:00,459 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 270 | Avg Loss  2.1155 | Accuracy: 0.4129\n",
      "2025-06-30 01:19:00,914 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 280 | Avg Loss  2.2013 | Accuracy: 0.4129\n",
      "2025-06-30 01:19:01,371 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 290 | Avg Loss  2.1904 | Accuracy: 0.4133\n",
      "2025-06-30 01:19:01,829 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 300 | Avg Loss  2.0886 | Accuracy: 0.4143\n",
      "2025-06-30 01:19:02,284 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 310 | Avg Loss  2.1455 | Accuracy: 0.4148\n",
      "2025-06-30 01:19:02,742 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 320 | Avg Loss  2.0957 | Accuracy: 0.4154\n",
      "2025-06-30 01:19:03,199 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 330 | Avg Loss  2.1675 | Accuracy: 0.4160\n",
      "2025-06-30 01:19:03,655 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 340 | Avg Loss  2.1970 | Accuracy: 0.4162\n",
      "2025-06-30 01:19:04,112 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 350 | Avg Loss  2.1157 | Accuracy: 0.4168\n",
      "2025-06-30 01:19:04,649 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 360 | Avg Loss  2.1458 | Accuracy: 0.4171\n",
      "2025-06-30 01:19:05,186 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 370 | Avg Loss  2.1260 | Accuracy: 0.4176\n",
      "2025-06-30 01:19:05,726 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 380 | Avg Loss  2.1183 | Accuracy: 0.4181\n",
      "2025-06-30 01:19:06,262 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3| Batch 390 | Avg Loss  2.1224 | Accuracy: 0.4186\n",
      "2025-06-30 01:19:06,301 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 2.1944, Accuracy: 0.4186\n",
      "2025-06-30 01:19:06,301 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 3/10: Avg Loss: 2.1944 | Accuracy: 0.4186\n",
      "2025-06-30 01:19:10,025 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 4, total batches: 391\n",
      "2025-06-30 01:19:10,549 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 10 | Avg Loss  2.0399 | Accuracy: 0.4531\n",
      "2025-06-30 01:19:11,006 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 20 | Avg Loss  1.9855 | Accuracy: 0.4555\n",
      "2025-06-30 01:19:11,464 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 30 | Avg Loss  1.9940 | Accuracy: 0.4604\n",
      "2025-06-30 01:19:11,923 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 40 | Avg Loss  1.9523 | Accuracy: 0.4629\n",
      "2025-06-30 01:19:12,380 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 50 | Avg Loss  2.0409 | Accuracy: 0.4600\n",
      "2025-06-30 01:19:12,837 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 60 | Avg Loss  2.0326 | Accuracy: 0.4576\n",
      "2025-06-30 01:19:13,293 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 70 | Avg Loss  1.9609 | Accuracy: 0.4588\n",
      "2025-06-30 01:19:13,751 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 80 | Avg Loss  2.0555 | Accuracy: 0.4563\n",
      "2025-06-30 01:19:14,209 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 90 | Avg Loss  2.0368 | Accuracy: 0.4562\n",
      "2025-06-30 01:19:14,667 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 100 | Avg Loss  1.9667 | Accuracy: 0.4582\n",
      "2025-06-30 01:19:15,125 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 110 | Avg Loss  2.0467 | Accuracy: 0.4571\n",
      "2025-06-30 01:19:15,583 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 120 | Avg Loss  2.0064 | Accuracy: 0.4576\n",
      "2025-06-30 01:19:16,041 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 130 | Avg Loss  1.8945 | Accuracy: 0.4589\n",
      "2025-06-30 01:19:16,500 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 140 | Avg Loss  2.0574 | Accuracy: 0.4588\n",
      "2025-06-30 01:19:16,960 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 150 | Avg Loss  1.9991 | Accuracy: 0.4585\n",
      "2025-06-30 01:19:17,419 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 160 | Avg Loss  2.0317 | Accuracy: 0.4578\n",
      "2025-06-30 01:19:17,876 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 170 | Avg Loss  1.9949 | Accuracy: 0.4574\n",
      "2025-06-30 01:19:18,332 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 180 | Avg Loss  2.0242 | Accuracy: 0.4578\n",
      "2025-06-30 01:19:18,789 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 190 | Avg Loss  2.0107 | Accuracy: 0.4586\n",
      "2025-06-30 01:19:19,246 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 200 | Avg Loss  2.0357 | Accuracy: 0.4580\n",
      "2025-06-30 01:19:19,705 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 210 | Avg Loss  1.9027 | Accuracy: 0.4585\n",
      "2025-06-30 01:19:20,163 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 220 | Avg Loss  1.9623 | Accuracy: 0.4585\n",
      "2025-06-30 01:19:20,620 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 230 | Avg Loss  1.9494 | Accuracy: 0.4591\n",
      "2025-06-30 01:19:21,076 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 240 | Avg Loss  2.0203 | Accuracy: 0.4595\n",
      "2025-06-30 01:19:21,533 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 250 | Avg Loss  1.9300 | Accuracy: 0.4603\n",
      "2025-06-30 01:19:21,989 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 260 | Avg Loss  1.9311 | Accuracy: 0.4608\n",
      "2025-06-30 01:19:22,445 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 270 | Avg Loss  1.9926 | Accuracy: 0.4611\n",
      "2025-06-30 01:19:22,902 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 280 | Avg Loss  1.9899 | Accuracy: 0.4608\n",
      "2025-06-30 01:19:23,359 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 290 | Avg Loss  1.9756 | Accuracy: 0.4608\n",
      "2025-06-30 01:19:23,816 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 300 | Avg Loss  1.9516 | Accuracy: 0.4609\n",
      "2025-06-30 01:19:24,273 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 310 | Avg Loss  1.9683 | Accuracy: 0.4607\n",
      "2025-06-30 01:19:24,730 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 320 | Avg Loss  2.0100 | Accuracy: 0.4605\n",
      "2025-06-30 01:19:25,189 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 330 | Avg Loss  1.9009 | Accuracy: 0.4608\n",
      "2025-06-30 01:19:25,645 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 340 | Avg Loss  1.9248 | Accuracy: 0.4611\n",
      "2025-06-30 01:19:26,102 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 350 | Avg Loss  1.8864 | Accuracy: 0.4617\n",
      "2025-06-30 01:19:26,648 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 360 | Avg Loss  1.9821 | Accuracy: 0.4620\n",
      "2025-06-30 01:19:27,184 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 370 | Avg Loss  1.9041 | Accuracy: 0.4629\n",
      "2025-06-30 01:19:27,722 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 380 | Avg Loss  1.9247 | Accuracy: 0.4634\n",
      "2025-06-30 01:19:28,259 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4| Batch 390 | Avg Loss  2.0099 | Accuracy: 0.4635\n",
      "2025-06-30 01:19:28,298 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 1.9817, Accuracy: 0.4635\n",
      "2025-06-30 01:19:28,298 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 4/10: Avg Loss: 1.9817 | Accuracy: 0.4635\n",
      "2025-06-30 01:19:32,320 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 5, total batches: 391\n",
      "2025-06-30 01:19:32,842 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 10 | Avg Loss  1.8779 | Accuracy: 0.4953\n",
      "2025-06-30 01:19:33,298 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 20 | Avg Loss  1.8257 | Accuracy: 0.5004\n",
      "2025-06-30 01:19:33,755 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 30 | Avg Loss  1.7547 | Accuracy: 0.4995\n",
      "2025-06-30 01:19:34,213 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 40 | Avg Loss  1.8778 | Accuracy: 0.4908\n",
      "2025-06-30 01:19:34,669 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 50 | Avg Loss  1.7896 | Accuracy: 0.4941\n",
      "2025-06-30 01:19:35,128 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 60 | Avg Loss  1.7782 | Accuracy: 0.4978\n",
      "2025-06-30 01:19:35,584 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 70 | Avg Loss  1.7983 | Accuracy: 0.5017\n",
      "2025-06-30 01:19:36,042 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 80 | Avg Loss  1.8389 | Accuracy: 0.4970\n",
      "2025-06-30 01:19:36,500 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 90 | Avg Loss  1.8497 | Accuracy: 0.4948\n",
      "2025-06-30 01:19:36,959 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 100 | Avg Loss  1.8371 | Accuracy: 0.4951\n",
      "2025-06-30 01:19:37,417 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 110 | Avg Loss  1.8652 | Accuracy: 0.4960\n",
      "2025-06-30 01:19:37,875 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 120 | Avg Loss  1.8360 | Accuracy: 0.4970\n",
      "2025-06-30 01:19:38,332 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 130 | Avg Loss  1.7232 | Accuracy: 0.4996\n",
      "2025-06-30 01:19:38,791 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 140 | Avg Loss  1.9478 | Accuracy: 0.4976\n",
      "2025-06-30 01:19:39,247 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 150 | Avg Loss  1.8943 | Accuracy: 0.4963\n",
      "2025-06-30 01:19:39,704 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 160 | Avg Loss  1.8480 | Accuracy: 0.4975\n",
      "2025-06-30 01:19:40,161 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 170 | Avg Loss  1.8639 | Accuracy: 0.4967\n",
      "2025-06-30 01:19:40,621 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 180 | Avg Loss  1.7750 | Accuracy: 0.4985\n",
      "2025-06-30 01:19:41,078 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 190 | Avg Loss  1.8000 | Accuracy: 0.4981\n",
      "2025-06-30 01:19:41,537 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 200 | Avg Loss  1.8522 | Accuracy: 0.4969\n",
      "2025-06-30 01:19:41,996 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 210 | Avg Loss  1.8498 | Accuracy: 0.4968\n",
      "2025-06-30 01:19:42,455 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 220 | Avg Loss  1.9118 | Accuracy: 0.4958\n",
      "2025-06-30 01:19:42,914 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 230 | Avg Loss  1.7754 | Accuracy: 0.4966\n",
      "2025-06-30 01:19:43,374 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 240 | Avg Loss  1.8434 | Accuracy: 0.4969\n",
      "2025-06-30 01:19:43,833 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 250 | Avg Loss  1.7851 | Accuracy: 0.4976\n",
      "2025-06-30 01:19:44,291 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 260 | Avg Loss  1.8976 | Accuracy: 0.4969\n",
      "2025-06-30 01:19:44,749 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 270 | Avg Loss  1.8923 | Accuracy: 0.4955\n",
      "2025-06-30 01:19:45,207 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 280 | Avg Loss  1.8568 | Accuracy: 0.4955\n",
      "2025-06-30 01:19:45,665 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 290 | Avg Loss  1.7979 | Accuracy: 0.4962\n",
      "2025-06-30 01:19:46,123 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 300 | Avg Loss  1.8942 | Accuracy: 0.4959\n",
      "2025-06-30 01:19:46,581 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 310 | Avg Loss  1.8800 | Accuracy: 0.4953\n",
      "2025-06-30 01:19:47,039 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 320 | Avg Loss  1.8781 | Accuracy: 0.4950\n",
      "2025-06-30 01:19:47,499 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 330 | Avg Loss  1.8873 | Accuracy: 0.4944\n",
      "2025-06-30 01:19:47,958 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 340 | Avg Loss  1.8966 | Accuracy: 0.4940\n",
      "2025-06-30 01:19:48,418 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 350 | Avg Loss  1.8002 | Accuracy: 0.4941\n",
      "2025-06-30 01:19:48,874 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 360 | Avg Loss  1.7965 | Accuracy: 0.4945\n",
      "2025-06-30 01:19:49,332 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 370 | Avg Loss  1.7881 | Accuracy: 0.4953\n",
      "2025-06-30 01:19:49,793 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 380 | Avg Loss  1.7313 | Accuracy: 0.4963\n",
      "2025-06-30 01:19:50,252 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5| Batch 390 | Avg Loss  1.8857 | Accuracy: 0.4961\n",
      "2025-06-30 01:19:50,290 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 1.8377, Accuracy: 0.4961\n",
      "2025-06-30 01:19:50,290 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 5/10: Avg Loss: 1.8377 | Accuracy: 0.4961\n",
      "2025-06-30 01:19:54,361 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 6, total batches: 391\n",
      "2025-06-30 01:19:54,882 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 10 | Avg Loss  1.6879 | Accuracy: 0.5500\n",
      "2025-06-30 01:19:55,338 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 20 | Avg Loss  1.7721 | Accuracy: 0.5234\n",
      "2025-06-30 01:19:55,796 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 30 | Avg Loss  1.7555 | Accuracy: 0.5198\n",
      "2025-06-30 01:19:56,254 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 40 | Avg Loss  1.7649 | Accuracy: 0.5141\n",
      "2025-06-30 01:19:56,713 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 50 | Avg Loss  1.6807 | Accuracy: 0.5181\n",
      "2025-06-30 01:19:57,170 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 60 | Avg Loss  1.7316 | Accuracy: 0.5195\n",
      "2025-06-30 01:19:57,628 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 70 | Avg Loss  1.6973 | Accuracy: 0.5215\n",
      "2025-06-30 01:19:58,084 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 80 | Avg Loss  1.7194 | Accuracy: 0.5208\n",
      "2025-06-30 01:19:58,542 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 90 | Avg Loss  1.7580 | Accuracy: 0.5213\n",
      "2025-06-30 01:19:58,999 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 100 | Avg Loss  1.6417 | Accuracy: 0.5248\n",
      "2025-06-30 01:19:59,456 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 110 | Avg Loss  1.7600 | Accuracy: 0.5227\n",
      "2025-06-30 01:19:59,913 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 120 | Avg Loss  1.7455 | Accuracy: 0.5225\n",
      "2025-06-30 01:20:00,370 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 130 | Avg Loss  1.7608 | Accuracy: 0.5212\n",
      "2025-06-30 01:20:00,829 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 140 | Avg Loss  1.6862 | Accuracy: 0.5209\n",
      "2025-06-30 01:20:01,287 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 150 | Avg Loss  1.7750 | Accuracy: 0.5207\n",
      "2025-06-30 01:20:01,745 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 160 | Avg Loss  1.7923 | Accuracy: 0.5200\n",
      "2025-06-30 01:20:02,202 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 170 | Avg Loss  1.5949 | Accuracy: 0.5215\n",
      "2025-06-30 01:20:02,661 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 180 | Avg Loss  1.7603 | Accuracy: 0.5202\n",
      "2025-06-30 01:20:03,119 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 190 | Avg Loss  1.6987 | Accuracy: 0.5208\n",
      "2025-06-30 01:20:03,577 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 200 | Avg Loss  1.6433 | Accuracy: 0.5218\n",
      "2025-06-30 01:20:04,034 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 210 | Avg Loss  1.7006 | Accuracy: 0.5228\n",
      "2025-06-30 01:20:04,494 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 220 | Avg Loss  1.7748 | Accuracy: 0.5228\n",
      "2025-06-30 01:20:04,954 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 230 | Avg Loss  1.5778 | Accuracy: 0.5243\n",
      "2025-06-30 01:20:05,412 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 240 | Avg Loss  1.7422 | Accuracy: 0.5245\n",
      "2025-06-30 01:20:05,871 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 250 | Avg Loss  1.7362 | Accuracy: 0.5243\n",
      "2025-06-30 01:20:06,330 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 260 | Avg Loss  1.7492 | Accuracy: 0.5235\n",
      "2025-06-30 01:20:06,787 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 270 | Avg Loss  1.6880 | Accuracy: 0.5242\n",
      "2025-06-30 01:20:07,246 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 280 | Avg Loss  1.8040 | Accuracy: 0.5235\n",
      "2025-06-30 01:20:07,705 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 290 | Avg Loss  1.5857 | Accuracy: 0.5246\n",
      "2025-06-30 01:20:08,164 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 300 | Avg Loss  1.7222 | Accuracy: 0.5243\n",
      "2025-06-30 01:20:08,623 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 310 | Avg Loss  1.7939 | Accuracy: 0.5239\n",
      "2025-06-30 01:20:09,082 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 320 | Avg Loss  1.6673 | Accuracy: 0.5239\n",
      "2025-06-30 01:20:09,540 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 330 | Avg Loss  1.7457 | Accuracy: 0.5237\n",
      "2025-06-30 01:20:09,998 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 340 | Avg Loss  1.7528 | Accuracy: 0.5234\n",
      "2025-06-30 01:20:10,457 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 350 | Avg Loss  1.7654 | Accuracy: 0.5233\n",
      "2025-06-30 01:20:11,010 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 360 | Avg Loss  1.7248 | Accuracy: 0.5228\n",
      "2025-06-30 01:20:11,562 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 370 | Avg Loss  1.8058 | Accuracy: 0.5226\n",
      "2025-06-30 01:20:12,091 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 380 | Avg Loss  1.7199 | Accuracy: 0.5227\n",
      "2025-06-30 01:20:12,628 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6| Batch 390 | Avg Loss  1.7748 | Accuracy: 0.5225\n",
      "2025-06-30 01:20:12,666 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 1.7239, Accuracy: 0.5225\n",
      "2025-06-30 01:20:12,666 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 6/10: Avg Loss: 1.7239 | Accuracy: 0.5225\n",
      "2025-06-30 01:20:16,738 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 7, total batches: 391\n",
      "2025-06-30 01:20:17,255 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 10 | Avg Loss  1.6141 | Accuracy: 0.5531\n",
      "2025-06-30 01:20:17,712 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 20 | Avg Loss  1.6188 | Accuracy: 0.5543\n",
      "2025-06-30 01:20:18,169 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 30 | Avg Loss  1.6414 | Accuracy: 0.5516\n",
      "2025-06-30 01:20:18,629 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 40 | Avg Loss  1.5597 | Accuracy: 0.5539\n",
      "2025-06-30 01:20:19,087 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 50 | Avg Loss  1.5993 | Accuracy: 0.5544\n",
      "2025-06-30 01:20:19,545 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 60 | Avg Loss  1.5565 | Accuracy: 0.5543\n",
      "2025-06-30 01:20:20,003 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 70 | Avg Loss  1.5991 | Accuracy: 0.5548\n",
      "2025-06-30 01:20:20,461 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 80 | Avg Loss  1.6830 | Accuracy: 0.5513\n",
      "2025-06-30 01:20:20,919 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 90 | Avg Loss  1.5660 | Accuracy: 0.5524\n",
      "2025-06-30 01:20:21,377 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 100 | Avg Loss  1.6757 | Accuracy: 0.5513\n",
      "2025-06-30 01:20:21,835 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 110 | Avg Loss  1.5862 | Accuracy: 0.5510\n",
      "2025-06-30 01:20:22,294 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 120 | Avg Loss  1.6091 | Accuracy: 0.5498\n",
      "2025-06-30 01:20:22,752 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 130 | Avg Loss  1.7437 | Accuracy: 0.5468\n",
      "2025-06-30 01:20:23,210 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 140 | Avg Loss  1.6468 | Accuracy: 0.5456\n",
      "2025-06-30 01:20:23,670 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 150 | Avg Loss  1.6716 | Accuracy: 0.5441\n",
      "2025-06-30 01:20:24,128 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 160 | Avg Loss  1.7115 | Accuracy: 0.5426\n",
      "2025-06-30 01:20:24,587 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 170 | Avg Loss  1.6115 | Accuracy: 0.5426\n",
      "2025-06-30 01:20:25,046 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 180 | Avg Loss  1.6635 | Accuracy: 0.5419\n",
      "2025-06-30 01:20:25,505 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 190 | Avg Loss  1.7452 | Accuracy: 0.5405\n",
      "2025-06-30 01:20:25,963 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 200 | Avg Loss  1.6964 | Accuracy: 0.5390\n",
      "2025-06-30 01:20:26,423 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 210 | Avg Loss  1.6123 | Accuracy: 0.5396\n",
      "2025-06-30 01:20:26,882 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 220 | Avg Loss  1.6003 | Accuracy: 0.5401\n",
      "2025-06-30 01:20:27,339 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 230 | Avg Loss  1.5790 | Accuracy: 0.5404\n",
      "2025-06-30 01:20:27,797 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 240 | Avg Loss  1.6186 | Accuracy: 0.5405\n",
      "2025-06-30 01:20:28,254 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 250 | Avg Loss  1.5853 | Accuracy: 0.5411\n",
      "2025-06-30 01:20:28,711 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 260 | Avg Loss  1.7176 | Accuracy: 0.5398\n",
      "2025-06-30 01:20:29,169 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 270 | Avg Loss  1.7171 | Accuracy: 0.5391\n",
      "2025-06-30 01:20:29,626 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 280 | Avg Loss  1.6332 | Accuracy: 0.5395\n",
      "2025-06-30 01:20:30,085 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 290 | Avg Loss  1.6085 | Accuracy: 0.5398\n",
      "2025-06-30 01:20:30,543 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 300 | Avg Loss  1.5650 | Accuracy: 0.5407\n",
      "2025-06-30 01:20:31,002 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 310 | Avg Loss  1.7111 | Accuracy: 0.5403\n",
      "2025-06-30 01:20:31,461 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 320 | Avg Loss  1.5310 | Accuracy: 0.5411\n",
      "2025-06-30 01:20:31,921 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 330 | Avg Loss  1.5996 | Accuracy: 0.5418\n",
      "2025-06-30 01:20:32,379 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 340 | Avg Loss  1.6916 | Accuracy: 0.5417\n",
      "2025-06-30 01:20:32,837 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 350 | Avg Loss  1.6644 | Accuracy: 0.5414\n",
      "2025-06-30 01:20:33,296 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 360 | Avg Loss  1.6532 | Accuracy: 0.5414\n",
      "2025-06-30 01:20:33,754 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 370 | Avg Loss  1.6954 | Accuracy: 0.5409\n",
      "2025-06-30 01:20:34,213 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 380 | Avg Loss  1.6199 | Accuracy: 0.5407\n",
      "2025-06-30 01:20:34,671 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7| Batch 390 | Avg Loss  1.6284 | Accuracy: 0.5408\n",
      "2025-06-30 01:20:34,714 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 1.6367, Accuracy: 0.5408\n",
      "2025-06-30 01:20:34,715 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 7/10: Avg Loss: 1.6367 | Accuracy: 0.5408\n",
      "2025-06-30 01:20:38,714 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 8, total batches: 391\n",
      "2025-06-30 01:20:39,238 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 10 | Avg Loss  1.4898 | Accuracy: 0.5750\n",
      "2025-06-30 01:20:39,695 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 20 | Avg Loss  1.4874 | Accuracy: 0.5762\n",
      "2025-06-30 01:20:40,153 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 30 | Avg Loss  1.5362 | Accuracy: 0.5714\n",
      "2025-06-30 01:20:40,616 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 40 | Avg Loss  1.5387 | Accuracy: 0.5715\n",
      "2025-06-30 01:20:41,076 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 50 | Avg Loss  1.5332 | Accuracy: 0.5708\n",
      "2025-06-30 01:20:41,534 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 60 | Avg Loss  1.4962 | Accuracy: 0.5715\n",
      "2025-06-30 01:20:41,993 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 70 | Avg Loss  1.5709 | Accuracy: 0.5667\n",
      "2025-06-30 01:20:42,452 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 80 | Avg Loss  1.5372 | Accuracy: 0.5668\n",
      "2025-06-30 01:20:42,912 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 90 | Avg Loss  1.5470 | Accuracy: 0.5658\n",
      "2025-06-30 01:20:43,372 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 100 | Avg Loss  1.6141 | Accuracy: 0.5640\n",
      "2025-06-30 01:20:43,831 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 110 | Avg Loss  1.6284 | Accuracy: 0.5618\n",
      "2025-06-30 01:20:44,290 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 120 | Avg Loss  1.5420 | Accuracy: 0.5626\n",
      "2025-06-30 01:20:44,749 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 130 | Avg Loss  1.5988 | Accuracy: 0.5613\n",
      "2025-06-30 01:20:45,209 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 140 | Avg Loss  1.5363 | Accuracy: 0.5610\n",
      "2025-06-30 01:20:45,670 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 150 | Avg Loss  1.5267 | Accuracy: 0.5607\n",
      "2025-06-30 01:20:46,129 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 160 | Avg Loss  1.4383 | Accuracy: 0.5624\n",
      "2025-06-30 01:20:46,589 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 170 | Avg Loss  1.5547 | Accuracy: 0.5609\n",
      "2025-06-30 01:20:47,048 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 180 | Avg Loss  1.4855 | Accuracy: 0.5622\n",
      "2025-06-30 01:20:47,505 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 190 | Avg Loss  1.5901 | Accuracy: 0.5608\n",
      "2025-06-30 01:20:47,964 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 200 | Avg Loss  1.5971 | Accuracy: 0.5597\n",
      "2025-06-30 01:20:48,424 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 210 | Avg Loss  1.5642 | Accuracy: 0.5596\n",
      "2025-06-30 01:20:48,881 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 220 | Avg Loss  1.6636 | Accuracy: 0.5584\n",
      "2025-06-30 01:20:49,340 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 230 | Avg Loss  1.5313 | Accuracy: 0.5583\n",
      "2025-06-30 01:20:49,798 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 240 | Avg Loss  1.6453 | Accuracy: 0.5575\n",
      "2025-06-30 01:20:50,258 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 250 | Avg Loss  1.5427 | Accuracy: 0.5577\n",
      "2025-06-30 01:20:50,717 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 260 | Avg Loss  1.4924 | Accuracy: 0.5584\n",
      "2025-06-30 01:20:51,178 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 270 | Avg Loss  1.5090 | Accuracy: 0.5593\n",
      "2025-06-30 01:20:51,637 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 280 | Avg Loss  1.5321 | Accuracy: 0.5590\n",
      "2025-06-30 01:20:52,095 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 290 | Avg Loss  1.5755 | Accuracy: 0.5586\n",
      "2025-06-30 01:20:52,556 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 300 | Avg Loss  1.5370 | Accuracy: 0.5581\n",
      "2025-06-30 01:20:53,016 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 310 | Avg Loss  1.5065 | Accuracy: 0.5587\n",
      "2025-06-30 01:20:53,489 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 320 | Avg Loss  1.4753 | Accuracy: 0.5594\n",
      "2025-06-30 01:20:53,951 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 330 | Avg Loss  1.5365 | Accuracy: 0.5594\n",
      "2025-06-30 01:20:54,409 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 340 | Avg Loss  1.4791 | Accuracy: 0.5596\n",
      "2025-06-30 01:20:54,868 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 350 | Avg Loss  1.5384 | Accuracy: 0.5594\n",
      "2025-06-30 01:20:55,328 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 360 | Avg Loss  1.5317 | Accuracy: 0.5592\n",
      "2025-06-30 01:20:55,792 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 370 | Avg Loss  1.5386 | Accuracy: 0.5594\n",
      "2025-06-30 01:20:56,251 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 380 | Avg Loss  1.5144 | Accuracy: 0.5598\n",
      "2025-06-30 01:20:56,710 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8| Batch 390 | Avg Loss  1.6210 | Accuracy: 0.5593\n",
      "2025-06-30 01:20:56,749 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 1.5438, Accuracy: 0.5592\n",
      "2025-06-30 01:20:56,749 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 8/10: Avg Loss: 1.5438 | Accuracy: 0.5592\n",
      "2025-06-30 01:21:00,911 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 9, total batches: 391\n",
      "2025-06-30 01:21:01,436 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 10 | Avg Loss  1.4041 | Accuracy: 0.5945\n",
      "2025-06-30 01:21:01,893 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 20 | Avg Loss  1.4227 | Accuracy: 0.5938\n",
      "2025-06-30 01:21:02,350 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 30 | Avg Loss  1.4299 | Accuracy: 0.5956\n",
      "2025-06-30 01:21:02,808 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 40 | Avg Loss  1.4881 | Accuracy: 0.5896\n",
      "2025-06-30 01:21:03,267 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 50 | Avg Loss  1.3962 | Accuracy: 0.5945\n",
      "2025-06-30 01:21:03,725 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 60 | Avg Loss  1.4487 | Accuracy: 0.5919\n",
      "2025-06-30 01:21:04,183 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 70 | Avg Loss  1.4975 | Accuracy: 0.5886\n",
      "2025-06-30 01:21:04,641 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 80 | Avg Loss  1.4740 | Accuracy: 0.5887\n",
      "2025-06-30 01:21:05,100 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 90 | Avg Loss  1.5042 | Accuracy: 0.5875\n",
      "2025-06-30 01:21:05,560 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 100 | Avg Loss  1.4539 | Accuracy: 0.5881\n",
      "2025-06-30 01:21:06,020 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 110 | Avg Loss  1.4270 | Accuracy: 0.5882\n",
      "2025-06-30 01:21:06,477 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 120 | Avg Loss  1.3342 | Accuracy: 0.5909\n",
      "2025-06-30 01:21:06,936 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 130 | Avg Loss  1.5199 | Accuracy: 0.5886\n",
      "2025-06-30 01:21:07,395 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 140 | Avg Loss  1.4905 | Accuracy: 0.5888\n",
      "2025-06-30 01:21:07,855 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 150 | Avg Loss  1.5069 | Accuracy: 0.5866\n",
      "2025-06-30 01:21:08,313 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 160 | Avg Loss  1.5027 | Accuracy: 0.5851\n",
      "2025-06-30 01:21:08,771 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 170 | Avg Loss  1.4395 | Accuracy: 0.5856\n",
      "2025-06-30 01:21:09,232 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 180 | Avg Loss  1.4701 | Accuracy: 0.5859\n",
      "2025-06-30 01:21:09,691 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 190 | Avg Loss  1.5466 | Accuracy: 0.5840\n",
      "2025-06-30 01:21:10,151 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 200 | Avg Loss  1.4787 | Accuracy: 0.5839\n",
      "2025-06-30 01:21:10,644 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 210 | Avg Loss  1.4908 | Accuracy: 0.5836\n",
      "2025-06-30 01:21:11,108 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 220 | Avg Loss  1.5246 | Accuracy: 0.5827\n",
      "2025-06-30 01:21:11,596 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 230 | Avg Loss  1.4727 | Accuracy: 0.5821\n",
      "2025-06-30 01:21:12,059 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 240 | Avg Loss  1.5057 | Accuracy: 0.5819\n",
      "2025-06-30 01:21:12,521 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 250 | Avg Loss  1.5587 | Accuracy: 0.5808\n",
      "2025-06-30 01:21:12,980 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 260 | Avg Loss  1.5253 | Accuracy: 0.5805\n",
      "2025-06-30 01:21:13,441 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 270 | Avg Loss  1.5335 | Accuracy: 0.5799\n",
      "2025-06-30 01:21:13,902 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 280 | Avg Loss  1.5102 | Accuracy: 0.5799\n",
      "2025-06-30 01:21:14,441 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 290 | Avg Loss  1.5451 | Accuracy: 0.5800\n",
      "2025-06-30 01:21:14,913 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 300 | Avg Loss  1.6087 | Accuracy: 0.5790\n",
      "2025-06-30 01:21:15,378 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 310 | Avg Loss  1.5295 | Accuracy: 0.5791\n",
      "2025-06-30 01:21:15,836 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 320 | Avg Loss  1.5424 | Accuracy: 0.5783\n",
      "2025-06-30 01:21:16,295 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 330 | Avg Loss  1.5448 | Accuracy: 0.5779\n",
      "2025-06-30 01:21:16,757 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 340 | Avg Loss  1.5081 | Accuracy: 0.5776\n",
      "2025-06-30 01:21:17,264 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 350 | Avg Loss  1.5364 | Accuracy: 0.5766\n",
      "2025-06-30 01:21:17,786 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 360 | Avg Loss  1.5677 | Accuracy: 0.5758\n",
      "2025-06-30 01:21:18,329 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 370 | Avg Loss  1.5215 | Accuracy: 0.5754\n",
      "2025-06-30 01:21:18,858 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 380 | Avg Loss  1.5008 | Accuracy: 0.5752\n",
      "2025-06-30 01:21:19,393 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9| Batch 390 | Avg Loss  1.5126 | Accuracy: 0.5748\n",
      "2025-06-30 01:21:19,431 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 1.4956, Accuracy: 0.5747\n",
      "2025-06-30 01:21:19,432 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 9/10: Avg Loss: 1.4956 | Accuracy: 0.5747\n",
      "2025-06-30 01:21:23,272 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Starting epoch 10, total batches: 391\n",
      "2025-06-30 01:21:23,795 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 10 | Avg Loss  1.4003 | Accuracy: 0.5992\n",
      "2025-06-30 01:21:24,254 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 20 | Avg Loss  1.3731 | Accuracy: 0.5977\n",
      "2025-06-30 01:21:24,711 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 30 | Avg Loss  1.3685 | Accuracy: 0.6060\n",
      "2025-06-30 01:21:25,173 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 40 | Avg Loss  1.3622 | Accuracy: 0.6080\n",
      "2025-06-30 01:21:25,631 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 50 | Avg Loss  1.3591 | Accuracy: 0.6033\n",
      "2025-06-30 01:21:26,090 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 60 | Avg Loss  1.4315 | Accuracy: 0.5999\n",
      "2025-06-30 01:21:26,547 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 70 | Avg Loss  1.4140 | Accuracy: 0.5991\n",
      "2025-06-30 01:21:27,003 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 80 | Avg Loss  1.3784 | Accuracy: 0.5987\n",
      "2025-06-30 01:21:27,462 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 90 | Avg Loss  1.4299 | Accuracy: 0.5971\n",
      "2025-06-30 01:21:27,920 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 100 | Avg Loss  1.4577 | Accuracy: 0.5947\n",
      "2025-06-30 01:21:28,378 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 110 | Avg Loss  1.4274 | Accuracy: 0.5942\n",
      "2025-06-30 01:21:28,837 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 120 | Avg Loss  1.4765 | Accuracy: 0.5939\n",
      "2025-06-30 01:21:29,295 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 130 | Avg Loss  1.4321 | Accuracy: 0.5924\n",
      "2025-06-30 01:21:29,755 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 140 | Avg Loss  1.4472 | Accuracy: 0.5915\n",
      "2025-06-30 01:21:30,215 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 150 | Avg Loss  1.4800 | Accuracy: 0.5911\n",
      "2025-06-30 01:21:30,675 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 160 | Avg Loss  1.4428 | Accuracy: 0.5908\n",
      "2025-06-30 01:21:31,134 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 170 | Avg Loss  1.3816 | Accuracy: 0.5926\n",
      "2025-06-30 01:21:31,604 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 180 | Avg Loss  1.4884 | Accuracy: 0.5908\n",
      "2025-06-30 01:21:32,091 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 190 | Avg Loss  1.4763 | Accuracy: 0.5899\n",
      "2025-06-30 01:21:32,556 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 200 | Avg Loss  1.4285 | Accuracy: 0.5893\n",
      "2025-06-30 01:21:33,019 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 210 | Avg Loss  1.4195 | Accuracy: 0.5893\n",
      "2025-06-30 01:21:33,478 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 220 | Avg Loss  1.4990 | Accuracy: 0.5888\n",
      "2025-06-30 01:21:33,940 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 230 | Avg Loss  1.4369 | Accuracy: 0.5887\n",
      "2025-06-30 01:21:34,410 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 240 | Avg Loss  1.5080 | Accuracy: 0.5876\n",
      "2025-06-30 01:21:34,883 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 250 | Avg Loss  1.4653 | Accuracy: 0.5877\n",
      "2025-06-30 01:21:35,343 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 260 | Avg Loss  1.4970 | Accuracy: 0.5872\n",
      "2025-06-30 01:21:35,808 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 270 | Avg Loss  1.4472 | Accuracy: 0.5868\n",
      "2025-06-30 01:21:36,272 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 280 | Avg Loss  1.5547 | Accuracy: 0.5854\n",
      "2025-06-30 01:21:36,732 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 290 | Avg Loss  1.4272 | Accuracy: 0.5851\n",
      "2025-06-30 01:21:37,192 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 300 | Avg Loss  1.4834 | Accuracy: 0.5850\n",
      "2025-06-30 01:21:37,652 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 310 | Avg Loss  1.5457 | Accuracy: 0.5844\n",
      "2025-06-30 01:21:38,121 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 320 | Avg Loss  1.4079 | Accuracy: 0.5852\n",
      "2025-06-30 01:21:38,586 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 330 | Avg Loss  1.4108 | Accuracy: 0.5857\n",
      "2025-06-30 01:21:39,050 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 340 | Avg Loss  1.4254 | Accuracy: 0.5855\n",
      "2025-06-30 01:21:39,514 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 350 | Avg Loss  1.4581 | Accuracy: 0.5853\n",
      "2025-06-30 01:21:39,977 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 360 | Avg Loss  1.4427 | Accuracy: 0.5854\n",
      "2025-06-30 01:21:40,441 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 370 | Avg Loss  1.3835 | Accuracy: 0.5857\n",
      "2025-06-30 01:21:40,905 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 380 | Avg Loss  1.4299 | Accuracy: 0.5858\n",
      "2025-06-30 01:21:41,367 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10| Batch 390 | Avg Loss  1.4470 | Accuracy: 0.5857\n",
      "2025-06-30 01:21:41,405 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch loss: 1.4396, Accuracy: 0.5857\n",
      "2025-06-30 01:21:41,406 - INFO - 1561975117.py - PID:3660 - TID:8784977664 - Epoch 10/10: Avg Loss: 1.4396 | Accuracy: 0.5857\n",
      "2025-06-30 01:21:45,585 - DEBUG - 1561975117.py - PID:3660 - TID:8784977664 - Mlflow: Ending current run...\n",
      "🏃 View run 20250630_011758 at: http://127.0.0.1:5555/#/experiments/3/runs/ff6828d602fd41df86cd102f54622afa\n",
      "🧪 View experiment at: http://127.0.0.1:5555/#/experiments/3\n",
      "2025-06-30 01:21:45,622 - DEBUG - 1561975117.py - PID:3660 - TID:8784977664 - Mlflow: current run ended successfully\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b3ae40e8a557157a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3e37934922123dea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "13d4444f4196a7f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b845509a6e520b34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd52a78361867bcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c2b2f8c94f6ad5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c79bdd8e6ad330df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
