{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCF70rRvASrn"
   },
   "outputs": [],
   "source": [
    "!pip install mlflow thop torchvision\n",
    "# Core imports and setup\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import numpy as np\n",
    "import psutil\n",
    "import platform\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from thop import profile\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1751928801664,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "eOnj5Ur9AVQi",
    "outputId": "4458cdf1-6416-4cf7-8bb5-54a7a4cff30d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-17 01:10:59,900 - DEBUG - 1078719332.py - PID:21996 - TID:8462606080 - Logger initialization completed\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "format_str = '%(asctime)s - %(levelname)s - %(filename)s - PID:%(process)d - TID:%(thread)d - %(message)s'\n",
    "logger = logging.getLogger(__name__ + str(time.time()))\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = False\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(logging.Formatter(format_str))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.debug(\"Logger initialization completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ObMPtBTFA8Z5"
   },
   "outputs": [],
   "source": [
    "class ComprehensiveTrainingMonitor:\n",
    "    \"\"\"Advanced training monitor with complete metrics tracking for MLflow\"\"\"\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device, model_name, dataset_name,\n",
    "                 batch_size=32, epochs=10, input_size=(3, 32, 32),\n",
    "                 mlflow_uri=\"https://mlflow-server-631028107267.us-central1.run.app\",\n",
    "                 use_mlflow=True, **kwargs):\n",
    "        # Core components\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        # Training parameters\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.input_size = input_size\n",
    "        self.mlflow_uri = mlflow_uri\n",
    "        self.use_mlflow = use_mlflow\n",
    "\n",
    "        # Auto-extracted parameters\n",
    "        self.lr = optimizer.param_groups[0]['lr']\n",
    "        self.optimizer_name = optimizer.__class__.__name__\n",
    "        self.loss_name = criterion.__class__.__name__\n",
    "        self.weight_decay = optimizer.param_groups[0].get('weight_decay', 0)\n",
    "        self.momentum = optimizer.param_groups[0].get('momentum', 0)\n",
    "\n",
    "        # Training state\n",
    "        self.start_time = time.time()\n",
    "        self.epoch_times = []\n",
    "        self.best_metric = -1\n",
    "        self.prev_loss = None\n",
    "        self.batch_times = []\n",
    "        self.run_started = False  # Track run state\n",
    "\n",
    "        # Optional parameters\n",
    "        self.train_size = kwargs.get('train_size', 0)\n",
    "        self.val_size = kwargs.get('val_size', 0)\n",
    "        self.num_workers = kwargs.get('num_workers', 0)\n",
    "        self.use_pretrained = kwargs.get('use_pretrained', False)\n",
    "        self.random_seed = kwargs.get('random_seed', 42)\n",
    "\n",
    "        self.run_id = None  # Mlflow current run id\n",
    "\n",
    "    def setup_mlflow(self):\n",
    "        \"\"\"Setup MLflow with comprehensive parameter logging\"\"\"\n",
    "        if not self.use_mlflow or self.run_started:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Ensure any existing run is ended\n",
    "            if mlflow.active_run():\n",
    "                mlflow.end_run()\n",
    "\n",
    "            # Configure MLflow client\n",
    "            mlflow.set_tracking_uri(self.mlflow_uri)\n",
    "            mlflow.set_experiment(f\"{self.model_name}-{self.dataset_name}\")\n",
    "\n",
    "            # Start single run\n",
    "            run_name = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            mlflow.start_run(run_name=run_name)\n",
    "            self.run_id = run_name\n",
    "            self.run_started = True\n",
    "\n",
    "            # Log comprehensive parameters\n",
    "            all_params = {\n",
    "                **self._get_core_params(),\n",
    "                **self._get_model_params(),\n",
    "                **self._get_system_params(),\n",
    "                **self._get_environment_params(),\n",
    "                **self._get_data_params(),\n",
    "                **self._get_training_params(),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(all_params)\n",
    "            logger.info(f\"MLflow tracking initialized: {self.mlflow_uri}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"MLflow setup failed: {e}\")\n",
    "            self.use_mlflow = False\n",
    "\n",
    "    def _get_core_params(self):\n",
    "        \"\"\"Core training parameters\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"dataset_name\": self.dataset_name,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"learning_rate\": self.lr,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"optimizer\": self.optimizer_name,\n",
    "            \"loss_function\": self.loss_name,\n",
    "            \"device\": str(self.device),\n",
    "            \"random_seed\": self.random_seed,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"momentum\": self.momentum,\n",
    "        }\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Model architecture parameters\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "        # Model size calculation\n",
    "        param_size = sum(p.numel() * p.element_size() for p in self.model.parameters())\n",
    "        buffer_size = sum(b.numel() * b.element_size() for b in self.model.buffers())\n",
    "        model_size_mb = (param_size + buffer_size) / (1024 ** 2)\n",
    "\n",
    "        # FLOPs calculation\n",
    "        flops_m = 0\n",
    "        try:\n",
    "            sample_input = torch.randn(1, *self.input_size)\n",
    "            flops, _ = profile(self.model, inputs=(sample_input,), verbose=False)\n",
    "            flops_m = round(flops / 1e6, 2)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"FLOPs calculation failed: {e}\")\n",
    "\n",
    "        return {\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"parameters_millions\": round(total_params / 1e6, 2),\n",
    "            \"model_size_mb\": round(model_size_mb, 2),\n",
    "            \"flops_millions\": flops_m,\n",
    "            \"input_size\": str(self.input_size),\n",
    "            \"use_pretrained\": self.use_pretrained,\n",
    "            \"model_architecture\": self.model.__class__.__name__,\n",
    "        }\n",
    "\n",
    "    def _get_system_params(self):\n",
    "        \"\"\"System and hardware parameters\"\"\"\n",
    "        gpu_info = {}\n",
    "        if torch.cuda.is_available():\n",
    "            props = torch.cuda.get_device_properties(0)\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": torch.cuda.get_device_name(0),\n",
    "                \"gpu_memory_gb\": round(props.total_memory / (1024**3), 2),\n",
    "                \"cuda_version\": torch.version.cuda,\n",
    "                \"num_gpus\": torch.cuda.device_count(),\n",
    "            }\n",
    "        elif torch.backends.mps.is_available():\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": \"Apple Silicon MPS\",\n",
    "                \"device_type\": \"mps\"\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"cpu_count\": psutil.cpu_count(),\n",
    "            \"memory_total_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"python_version\": platform.python_version(),\n",
    "            \"pytorch_version\": torch.__version__,\n",
    "            **gpu_info\n",
    "        }\n",
    "\n",
    "    def _get_environment_params(self):\n",
    "        \"\"\"Environment and reproducibility parameters\"\"\"\n",
    "        git_info = {}\n",
    "        try:\n",
    "            commit = subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip()\n",
    "            branch = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD']).decode().strip()\n",
    "            git_info = {\n",
    "                \"git_commit\": commit[:8],\n",
    "                \"git_branch\": branch,\n",
    "            }\n",
    "        except:\n",
    "            git_info = {\"git_commit\": \"unknown\", \"git_branch\": \"unknown\"}\n",
    "\n",
    "        return git_info\n",
    "\n",
    "    def _get_data_params(self):\n",
    "        \"\"\"Data pipeline parameters\"\"\"\n",
    "        return {\n",
    "            \"train_size\": self.train_size,\n",
    "            \"val_size\": self.val_size,\n",
    "            \"total_samples\": self.train_size + self.val_size,\n",
    "            \"num_workers\": self.num_workers,\n",
    "        }\n",
    "\n",
    "    def _get_training_params(self):\n",
    "        \"\"\"Advanced training configuration\"\"\"\n",
    "        return {\n",
    "            \"mlflow_uri\": self.mlflow_uri,\n",
    "            \"experiment_name\": f\"{self.model_name}-{self.dataset_name}\",\n",
    "        }\n",
    "\n",
    "    def log_epoch_metrics(self, epoch, epoch_loss, epoch_acc, batch_count=None):\n",
    "        \"\"\"Comprehensive epoch metrics logging\"\"\"\n",
    "        if not self.use_mlflow or not self.run_started:\n",
    "            return {}\n",
    "\n",
    "        try:\n",
    "            current_time = time.time()\n",
    "\n",
    "            # Timing metrics\n",
    "            epoch_time = current_time - (self.start_time if epoch == 0 else self.start_time + sum(self.epoch_times))\n",
    "            self.epoch_times.append(epoch_time)\n",
    "\n",
    "            # Core metrics\n",
    "            metrics = {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": epoch_loss,\n",
    "                \"train_accuracy\": epoch_acc,\n",
    "                \"learning_rate\": self.optimizer.param_groups[0][\"lr\"],\n",
    "                \"epoch_time_seconds\": epoch_time,\n",
    "                \"total_time_seconds\": current_time - self.start_time,\n",
    "                \"avg_epoch_time\": sum(self.epoch_times) / len(self.epoch_times),\n",
    "            }\n",
    "\n",
    "            # Training dynamics\n",
    "            if self.prev_loss is not None:\n",
    "                loss_improvement = self.prev_loss - epoch_loss\n",
    "                metrics.update({\n",
    "                    \"loss_improvement\": loss_improvement,\n",
    "                    \"loss_improvement_percent\": (loss_improvement / self.prev_loss) * 100 if self.prev_loss != 0 else 0,\n",
    "                })\n",
    "            self.prev_loss = epoch_loss\n",
    "\n",
    "            # Performance metrics\n",
    "            if batch_count and epoch_time > 0:\n",
    "                samples_per_sec = (self.batch_size * batch_count) / epoch_time\n",
    "                metrics.update({\n",
    "                    \"batches_per_second\": batch_count / epoch_time,\n",
    "                    \"samples_per_second\": samples_per_sec,\n",
    "                })\n",
    "\n",
    "            # GPU/MPS metrics\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_metrics = self._get_gpu_metrics()\n",
    "                metrics.update(gpu_metrics)\n",
    "\n",
    "            # System metrics\n",
    "            system_metrics = self._get_system_metrics()\n",
    "            metrics.update(system_metrics)\n",
    "\n",
    "            mlflow.log_metrics(metrics, step=epoch)\n",
    "            return metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log epoch metrics: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _get_gpu_metrics(self):\n",
    "        \"\"\"GPU metrics for CUDA\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            return {}\n",
    "\n",
    "        allocated = torch.cuda.memory_allocated()\n",
    "        reserved = torch.cuda.memory_reserved()\n",
    "        total = torch.cuda.get_device_properties(0).total_memory\n",
    "\n",
    "        return {\n",
    "            \"gpu_memory_allocated_mb\": allocated / (1024**2),\n",
    "            \"gpu_memory_reserved_mb\": reserved / (1024**2),\n",
    "            \"gpu_memory_allocated_percent\": (allocated / total) * 100,\n",
    "            \"gpu_memory_reserved_percent\": (reserved / total) * 100,\n",
    "        }\n",
    "\n",
    "    def _get_system_metrics(self):\n",
    "        \"\"\"Real-time system resource utilization\"\"\"\n",
    "        cpu_percent = psutil.cpu_percent(interval=None)\n",
    "        memory = psutil.virtual_memory()\n",
    "\n",
    "        return {\n",
    "            \"cpu_percent\": cpu_percent,\n",
    "            \"memory_used_percent\": memory.percent,\n",
    "            \"memory_available_gb\": memory.available / (1024**3),\n",
    "        }\n",
    "\n",
    "    def should_log_model(self, current_metric, metric_name=\"accuracy\"):\n",
    "        \"\"\"Enhanced model checkpointing with improvement tracking\"\"\"\n",
    "        if current_metric > self.best_metric:\n",
    "            improvement = current_metric - self.best_metric\n",
    "            self.best_metric = current_metric\n",
    "\n",
    "            if self.use_mlflow and self.run_started:\n",
    "                try:\n",
    "                    mlflow.log_metrics({\n",
    "                        f\"best_{metric_name}\": current_metric,\n",
    "                        f\"{metric_name}_improvement\": improvement,\n",
    "                        \"checkpoint_epoch\": len(self.epoch_times),\n",
    "                    }, step=len(self.epoch_times))\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to log best model metrics: {e}\")\n",
    "\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def log_model_artifact(self, signature=None):\n",
    "        \"\"\"Log model with comprehensive metadata (metrics only, no artifacts)\"\"\"\n",
    "        if not self.use_mlflow or not self.run_started:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Log model metadata as parameters instead of artifacts to avoid GCS issues\n",
    "            model_metadata = {\n",
    "                \"best_model_architecture\": self.model.__class__.__name__,\n",
    "                \"best_model_accuracy\": self.best_metric,\n",
    "                \"best_model_training_time_hours\": (time.time() - self.start_time) / 3600,\n",
    "                \"best_model_epochs_trained\": len(self.epoch_times),\n",
    "                \"best_model_parameters_count\": sum(p.numel() for p in self.model.parameters()),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(model_metadata)\n",
    "            logger.info(f\"Model metadata logged for accuracy: {self.best_metric:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log model metadata: {e}\")\n",
    "\n",
    "    def end_run(self, status=\"FINISHED\"):\n",
    "        \"\"\"Clean up and end MLflow run\"\"\"\n",
    "        if self.use_mlflow and self.run_started:\n",
    "            try:\n",
    "                total_time = time.time() - self.start_time\n",
    "                summary = {\n",
    "                    \"final_total_training_time_minutes\": round(total_time / 60, 2),\n",
    "                    \"final_best_accuracy\": self.best_metric,\n",
    "                    \"final_epochs_completed\": len(self.epoch_times),\n",
    "                }\n",
    "                mlflow.log_params(summary)\n",
    "                mlflow.end_run(status=status)\n",
    "                self.run_started = False\n",
    "                return summary\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to end MLflow run properly: {e}\")\n",
    "                return {}\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import rerun as rr\n",
    "\n",
    "\n",
    "class RerunLogger:\n",
    "    def __init__(self, run_id: str, model_name:str, backend_url: str = \"http://localhost:8000\"):\n",
    "        self.run_id = run_id\n",
    "        self.model_name = model_name\n",
    "        self.backend_url = backend_url\n",
    "        self.gcs_bucket = \"neuralripper-mlflow-artifacts\"\n",
    "        self.viewer_url = None\n",
    "        self.internal_url = None\n",
    "        self.initialized = False\n",
    "    \n",
    "    def get_viewer_urls(self):\n",
    "        \"\"\"Get viewer URLs from backend\"\"\"\n",
    "        try:\n",
    "            res = requests.get(f\"{self.backend_url}/rerun/{self.run_id}/live\")\n",
    "            if res.status_code == 200:\n",
    "                data = res.json()\n",
    "                self.viewer_url = data[\"viewer_url\"]\n",
    "                self.internal_url = data[\"internal_url\"]\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get viewer URLs: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"Init rerun connection\"\"\"\n",
    "        if self.get_viewer_urls():\n",
    "            logger.debug(f\"internal_url: {self.internal_url}\")\n",
    "            logger.debug(f\"viewer_url: {self.viewer_url}\")\n",
    "\n",
    "            # Extract gRPC port from internal url, use for uploading recordings\n",
    "            grpc_port = self.internal_url.split(':')[-1]\n",
    "\n",
    "            # Init recording\n",
    "            rr.init(f\"{self.model_name}_{self.run_id}\", spawn=False)\n",
    "\n",
    "            # Connect to backend gRPC server(send the recordings data to backend so it can serve in viewer url)\n",
    "            rr.connect_grpc(f\"127.0.0.1:{grpc_port}\")\n",
    "            # rr.connect_grpc(grpc_port)\n",
    "            # rr.connect_grpc()\n",
    "\n",
    "            self.initialized = True\n",
    "            print(f\"Rerun live viewer: {self.viewer_url}\")\n",
    "            print(f\"Connected to gRPC: 127.0.0.1:{grpc_port}\")\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def log_training_step(self, epoch: int, step: int, loss: float, accuracy: float, \n",
    "                          lr: float, gpu_memory: dict = None, system_metrics: dict = None):\n",
    "        \"\"\"Log training metrics to rerun\"\"\"\n",
    "        if not self.initialized:\n",
    "            return\n",
    "            \n",
    "        rr.log(\"training/loss\", rr.Scalars(loss))\n",
    "        rr.log(\"training/accuracy\", rr.Scalars(accuracy))\n",
    "        rr.log(\"training/learning_rate\", rr.Scalars(lr))\n",
    "        rr.log(\"progress/epoch\", rr.Scalars(epoch))\n",
    "        rr.log(\"progress/step\", rr.Scalars(step))\n",
    "        \n",
    "        if gpu_memory:\n",
    "            rr.log(\"system/gpu_memory_mb\", rr.Scalars(gpu_memory.get('gpu_memory_allocated_mb', 0)))\n",
    "        if system_metrics:\n",
    "            rr.log(\"system/cpu_percent\", rr.Scalars(system_metrics.get('cpu_percent', 0)))\n",
    "            rr.log(\"system/memory_percent\", rr.Scalars(system_metrics.get('memory_used_percent', 0)))\n",
    "\n",
    "    def save_recording(self):\n",
    "        \"\"\"Save recording directly to GCS\"\"\"\n",
    "        if not self.initialized:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            gcs_path = f\"gs://{self.gcs_bucket}/rerun_recordings/{self.model_name}_{self.run_id}.rrd\"\n",
    "            rr.save(gcs_path)\n",
    "            print(f\"Recording saved: {gcs_path}\")\n",
    "            return gcs_path\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save recording: {e}\")\n",
    "            return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "P_kRN-fBA9Ve"
   },
   "outputs": [],
   "source": [
    "class EnhancedMobileNetV2:\n",
    "    \"\"\"MobileNetV2 with comprehensive monitoring integration\"\"\"\n",
    "\n",
    "    def __init__(self, num_epochs=10, batch_size=128, num_classes=100,\n",
    "                 learning_rate=5e-3, use_mlflow=True):\n",
    "        # Core parameters\n",
    "        self._num_classes = num_classes\n",
    "        self._use_mlflow = use_mlflow\n",
    "        self._batch_size = batch_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        # Create model components\n",
    "        self._model = self._create_model()\n",
    "        self._device = self._set_device()\n",
    "        self._model.to(self._device)\n",
    "        self._criterion = self._set_criterion()\n",
    "        self._optimizer = self._set_optimizer()\n",
    "\n",
    "        # Initialize comprehensive monitor\n",
    "        self.monitor = ComprehensiveTrainingMonitor(\n",
    "            model=self._model,\n",
    "            optimizer=self._optimizer,\n",
    "            criterion=self._criterion,\n",
    "            device=self._device,\n",
    "            model_name='MobileNetV2',\n",
    "            dataset_name='CIFAR-100',\n",
    "            batch_size=batch_size,\n",
    "            epochs=num_epochs,\n",
    "            input_size=(3, 32, 32),\n",
    "            use_mlflow=use_mlflow,\n",
    "            use_pretrained=True,\n",
    "            train_size=50000,\n",
    "            val_size=10000,\n",
    "            num_workers=0,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Model initialized on device: {self._device}\")\n",
    "        logger.info(f\"Model parameters: {sum(p.numel() for p in self._model.parameters()):,}\")\n",
    "\n",
    "        self.rerun_logger = None    # rerun logger will be init when training starts\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Create MobileNetV2 model with CIFAR-100 adaptation\"\"\"\n",
    "        model = torchvision.models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "        # Adapt classifier for CIFAR-100 (100 classes)\n",
    "        model.classifier[1] = nn.Linear(1280, self._num_classes)\n",
    "        return model\n",
    "\n",
    "    def _set_device(self):\n",
    "        \"\"\"Set appropriate device for training\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def _set_optimizer(self):\n",
    "        \"\"\"Configure SGD optimizer with momentum and weight decay\"\"\"\n",
    "        return optim.SGD(self._model.parameters(),\n",
    "                        lr=self._learning_rate,\n",
    "                        momentum=0.9,\n",
    "                        weight_decay=4e-5)\n",
    "\n",
    "    def _set_criterion(self):\n",
    "        \"\"\"Set loss function for classification\"\"\"\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    def train_epoch(self, data_loader, epoch_idx):\n",
    "        \"\"\"Enhanced training epoch with comprehensive monitoring\"\"\"\n",
    "        logger.info(f\"Starting epoch {epoch_idx+1}, total batches: {len(data_loader)}\")\n",
    "\n",
    "        self._model.train()\n",
    "        epoch_total_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "        batch_count = len(data_loader)\n",
    "\n",
    "        for idx, (images, targets) in enumerate(data_loader):\n",
    "            images = images.to(self._device)\n",
    "            targets = targets.to(self._device)\n",
    "\n",
    "            self._optimizer.zero_grad()\n",
    "            logits = self._model(images)\n",
    "            loss = self._criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            running_correct += (predictions == targets).sum().item()\n",
    "            running_total += targets.size(0)\n",
    "            running_loss += loss.item()\n",
    "            epoch_total_loss += loss.item()\n",
    "\n",
    "            # Progress logging every 10 batches\n",
    "            if idx % 10 == 9:\n",
    "                avg_loss = running_loss / 10\n",
    "                curr_acc = running_correct / running_total\n",
    "                logger.info(f\"Epoch {epoch_idx + 1} | Batch {idx + 1} | \"\n",
    "                          f\"Avg Loss: {avg_loss:.4f} | Accuracy: {curr_acc:.4f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "                # Rerun loggings\n",
    "                if self.rerun_logger:\n",
    "                    gpu_metrics = self.monitor._get_gpu_metrics()\n",
    "                    sys_metrics = self.monitor._get_system_metrics()\n",
    "\n",
    "                    self.rerun_logger.log_training_step(\n",
    "                        epoch=epoch_idx,\n",
    "                        step=(epoch_idx * len(data_loader)) + idx,\n",
    "                        loss=avg_loss,\n",
    "                        accuracy=curr_acc,\n",
    "                        lr=self._optimizer.param_groups[0]['lr'],\n",
    "                        gpu_memory=gpu_metrics,\n",
    "                        system_metrics=sys_metrics\n",
    "                    )\n",
    "\n",
    "\n",
    "        epoch_loss = epoch_total_loss / batch_count\n",
    "        epoch_acc = running_correct / running_total\n",
    "\n",
    "        logger.info(f\"Epoch {epoch_idx + 1} completed - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "        return epoch_loss, epoch_acc, batch_count\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        \"\"\"Enhanced training with comprehensive monitoring\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Starting training for {self._num_epochs} epochs on {self._device}\")\n",
    "\n",
    "            # Setup MLflow once at the beginning\n",
    "            self.monitor.setup_mlflow()\n",
    "\n",
    "            # Init RerunLogger\n",
    "            if self.monitor.run_id:\n",
    "                self.rerun_logger = RerunLogger(self.monitor.run_id, \"MobileNetV2\")\n",
    "                self.rerun_logger.initialize()\n",
    "\n",
    "            for epoch in range(self._num_epochs):\n",
    "                epoch_loss, epoch_acc, batch_count = self.train_epoch(train_loader, epoch)\n",
    "\n",
    "                # Log comprehensive epoch metrics\n",
    "                metrics = self.monitor.log_epoch_metrics(epoch, epoch_loss, epoch_acc, batch_count)\n",
    "\n",
    "                # Model checkpointing for best performance (metadata only)\n",
    "                if self.monitor.should_log_model(epoch_acc):\n",
    "                    self.monitor.log_model_artifact()\n",
    "                    logger.info(f\"New best model metadata saved with accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "                # Enhanced progress display\n",
    "                print(f\"Epoch {epoch+1}/{self._num_epochs}: \"\n",
    "                      f\"Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | \"\n",
    "                      f\"Time: {metrics.get('epoch_time_seconds', 0):.1f}s | \"\n",
    "                      f\"LR: {metrics.get('learning_rate', 0):.2e} | \"\n",
    "                      f\"Memory: {metrics.get('memory_used_percent', 0):.1f}%\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training failed: {e}\")\n",
    "            self.monitor.end_run(status=\"FAILED\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Save rerun recording after training\n",
    "            if self.rerun_logger:\n",
    "                self.rerun_logger.save_recording()\n",
    "\n",
    "            summary = self.monitor.end_run()\n",
    "            logger.info(f\"Training completed. Summary: {summary}\")\n",
    "            print(f\"\\nTraining Summary:\")\n",
    "            print(f\"Total time: {summary.get('final_total_training_time_minutes', 0):.1f} minutes\")\n",
    "            print(f\"Best accuracy: {summary.get('final_best_accuracy', 0):.4f}\")\n",
    "            print(f\"Epochs completed: {summary.get('final_epochs_completed', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11683,
     "status": "ok",
     "timestamp": 1751928813456,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "rUkj617FBnqH",
    "outputId": "55448d5e-64b9-4cdc-d046-816cda95c31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Number of classes: 100\n",
      "Class names (first 10): ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']\n",
      "Subset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Data transforms for CIFAR-100\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Data augmentation\n",
    "    transforms.RandomHorizontalFlip(0.5),   # Random horizontal flip\n",
    "    transforms.ToTensor(),                  # Convert to tensor\n",
    "    transforms.Normalize(                   # Normalize with ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "train_ds = datasets.CIFAR100(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_tf\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# only use first 10000 images for local training\n",
    "train_subset = Subset(train_ds, range(10000))\n",
    "\n",
    "print(f\"Training dataset size: {len(train_ds)}\")\n",
    "print(f\"Number of classes: {len(train_ds.classes)}\")\n",
    "print(f\"Class names (first 10): {train_ds.classes[:10]}\")\n",
    "print(f\"Subset size: {len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "Bll8T_8uBEc_"
   },
   "outputs": [],
   "source": [
    "# Optional: Visualize a sample of the data\n",
    "def visualize_samples(dataset, num_samples=16):\n",
    "    \"\"\"Visualize a sample of images from the dataset\"\"\"\n",
    "    # Create subset for visualization\n",
    "    sample_indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img_tensor, class_idx = dataset[idx]\n",
    "\n",
    "        # Denormalize image for display\n",
    "        img = img_tensor.permute(1, 2, 0)\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Class: {dataset.classes[class_idx]}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to visualize samples\n",
    "# visualize_samples(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1751928813518,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "wDN0WcGZBFLy",
    "outputId": "4d82f86c-3795-41ac-bcec-973b28770326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per epoch: 391\n",
      "Total samples per epoch: 50048\n"
     ]
    }
   ],
   "source": [
    "# Create data loader\n",
    "train_loader = DataLoader(\n",
    "    # train_subset,       # subset for local test, change to original ds for production\n",
    "    train_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,      # Set to 0 for MPS compatibility\n",
    "    pin_memory=False    # Disable for MPS\n",
    ")\n",
    "\n",
    "print(f\"Number of batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Total samples per epoch: {len(train_loader) * 128}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 866,
     "status": "ok",
     "timestamp": 1751928814386,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "i-3WhL4dBGlf",
    "outputId": "d6eaf687-a862-4a30-b913-0f39bd0dade8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 01:12:25,852 - INFO - 2346846570.py - PID:21996 - TID:8462606080 - Initializing Enhanced MobileNetV2 model\n",
      "2025-07-18 01:12:26,050 - INFO - 3724282253.py - PID:21996 - TID:8462606080 - Model initialized on device: mps\n",
      "2025-07-18 01:12:26,051 - INFO - 3724282253.py - PID:21996 - TID:8462606080 - Model parameters: 2,351,972\n",
      "Model initialized successfully!\n",
      "Device: mps\n",
      "Total parameters: 2,351,972\n",
      "Trainable parameters: 2,351,972\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "logger.info(\"Initializing Enhanced MobileNetV2 model\")\n",
    "\n",
    "model = EnhancedMobileNetV2(\n",
    "    num_epochs=5,\n",
    "    batch_size=128,\n",
    "    num_classes=100,\n",
    "    learning_rate=3e-3,\n",
    "    use_mlflow=True\n",
    ")\n",
    "\n",
    "print(\"Model initialized successfully!\")\n",
    "print(f\"Device: {model._device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model._model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model._model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JC5fvLRjBH8C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " STARTING ENHANCED MOBILENETV2 TRAINING\n",
      "==================================================\n",
      "Dataset: CIFAR-100 (100 classes)\n",
      "Model: MobileNetV2 (pretrained)\n",
      "Epochs: 5\n",
      "Batch size: 128\n",
      "Learning rate: 0.003\n",
      "MLflow tracking: Enabled\n",
      "MLflow URI: https://mlflow-server-631028107267.us-central1.run.app\n",
      "==================================================\n",
      "\n",
      "2025-07-18 01:12:26,114 - INFO - 3724282253.py - PID:21996 - TID:8462606080 - Starting training for 5 epochs on mps\n",
      "2025-07-18 01:12:27,468 - WARNING - 821454703.py - PID:21996 - TID:8462606080 - FLOPs calculation failed: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device\n",
      "2025-07-18 01:12:28,727 - INFO - 821454703.py - PID:21996 - TID:8462606080 - MLflow tracking initialized: https://mlflow-server-631028107267.us-central1.run.app\n",
      "2025-07-18 01:12:28,746 - DEBUG - 638891431.py - PID:21996 - TID:8462606080 - internal_url: localhost:64237\n",
      "2025-07-18 01:12:28,747 - DEBUG - 638891431.py - PID:21996 - TID:8462606080 - viewer_url: rerun://localhost:64237\n",
      "2025-07-18 01:12:28,748 - ERROR - 3724282253.py - PID:21996 - TID:8462606080 - Training failed: invalid endpoint \"127.0.0.1:64237\": Unexpected URI:: 127.0.0.1:64237\n",
      "ðŸƒ View run 20250718_011226 at: https://mlflow-server-631028107267.us-central1.run.app/#/experiments/1/runs/a027ed522b5f4e648b1906cd4e6e5a35\n",
      "ðŸ§ª View experiment at: https://mlflow-server-631028107267.us-central1.run.app/#/experiments/1\n",
      "2025-07-18 01:12:31,468 - INFO - 3724282253.py - PID:21996 - TID:8462606080 - Training completed. Summary: {}\n",
      "\n",
      "Training Summary:\n",
      "Total time: 0.0 minutes\n",
      "Best accuracy: 0.0000\n",
      "Epochs completed: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid endpoint \"127.0.0.1:64237\": Unexpected URI:: 127.0.0.1:64237",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[156], line 137\u001b[0m, in \u001b[0;36mEnhancedMobileNetV2.train\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor\u001b[38;5;241m.\u001b[39mrun_id:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrerun_logger \u001b[38;5;241m=\u001b[39m RerunLogger(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor\u001b[38;5;241m.\u001b[39mrun_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMobileNetV2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrerun_logger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_epochs):\n\u001b[1;32m    140\u001b[0m     epoch_loss, epoch_acc, batch_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_epoch(train_loader, epoch)\n",
      "Cell \u001b[0;32mIn[155], line 42\u001b[0m, in \u001b[0;36mRerunLogger.initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m rr\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, spawn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Connect to backend gRPC server(send the recordings data to backend so it can serve in viewer url)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43mrr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_grpc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m127.0.0.1:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgrpc_port\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# rr.connect_grpc(grpc_port)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# rr.connect_grpc()\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/ripper/lib/python3.11/site-packages/rerun_sdk/rerun/sinks.py:84\u001b[0m, in \u001b[0;36mconnect_grpc\u001b[0;34m(url, flush_timeout_sec, default_blueprint, recording)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default_blueprint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     blueprint_storage \u001b[38;5;241m=\u001b[39m create_in_memory_blueprint(\n\u001b[1;32m     80\u001b[0m         application_id\u001b[38;5;241m=\u001b[39mapplication_id,\n\u001b[1;32m     81\u001b[0m         blueprint\u001b[38;5;241m=\u001b[39mdefault_blueprint,\n\u001b[1;32m     82\u001b[0m     )\u001b[38;5;241m.\u001b[39mstorage\n\u001b[0;32m---> 84\u001b[0m \u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_grpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflush_timeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflush_timeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_blueprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblueprint_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecording\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecording\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_native\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid endpoint \"127.0.0.1:64237\": Unexpected URI:: 127.0.0.1:64237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-07-19T06:52:27Z \u001b[1m\u001b[31mERROR\u001b[0m re_grpc_client::message_proxy::write\u001b[90m]\u001b[0m Write messages call failed: status: Unknown, message: \"transport error\", details: [], metadata: MetadataMap { headers: {} }\n"
     ]
    }
   ],
   "source": [
    "# Start training with comprehensive monitoring\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" STARTING ENHANCED MOBILENETV2 TRAINING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset: CIFAR-100 (100 classes)\")\n",
    "print(f\"Model: MobileNetV2 (pretrained)\")\n",
    "print(f\"Epochs: {model._num_epochs}\")\n",
    "print(f\"Batch size: {model._batch_size}\")\n",
    "print(f\"Learning rate: {model._learning_rate}\")\n",
    "print(f\"MLflow tracking: {'Enabled' if model._use_mlflow else 'Disabled'}\")\n",
    "print(f\"MLflow URI: {model.monitor.mlflow_uri}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Start training\n",
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3TvvXzbBz7Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMYZDW3c+maUFI63troF8xy",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ripper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
