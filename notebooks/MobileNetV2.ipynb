{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wCF70rRvASrn"},"outputs":[],"source":["!pip install mlflow thop\n","# Core imports and setup\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms, datasets\n","from torchvision.models import MobileNet_V2_Weights\n","from torch.utils.data import DataLoader, Subset\n","\n","import mlflow\n","import mlflow.pytorch\n","from mlflow.models import infer_signature\n","\n","import numpy as np\n","import psutil\n","import platform\n","import subprocess\n","from datetime import datetime\n","from thop import profile\n","\n","import logging\n","import sys\n","import matplotlib.pyplot as plt\n","\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"Torchvision version: {torchvision.__version__}\")\n","print(f\"MLflow version: {mlflow.__version__}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1751928801664,"user":{"displayName":"DizzyDoze","userId":"13303002129287970688"},"user_tz":420},"id":"eOnj5Ur9AVQi","outputId":"4458cdf1-6416-4cf7-8bb5-54a7a4cff30d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-07-07 22:53:21,672 - DEBUG - ipython-input-2-1078719332.py - PID:616 - TID:135040586224256 - Logger initialization completed\n"]}],"source":["# Setup logging\n","format_str = '%(asctime)s - %(levelname)s - %(filename)s - PID:%(process)d - TID:%(thread)d - %(message)s'\n","logger = logging.getLogger(__name__ + str(time.time()))\n","logger.setLevel(logging.DEBUG)\n","logger.propagate = False\n","handler = logging.StreamHandler(sys.stdout)\n","handler.setFormatter(logging.Formatter(format_str))\n","logger.addHandler(handler)\n","\n","logger.debug(\"Logger initialization completed\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ObMPtBTFA8Z5"},"outputs":[],"source":["class ComprehensiveTrainingMonitor:\n","    \"\"\"Advanced training monitor with complete metrics tracking for MLflow\"\"\"\n","\n","    def __init__(self, model, optimizer, criterion, device, model_name, dataset_name,\n","                 batch_size=32, epochs=10, input_size=(3, 32, 32),\n","                 mlflow_uri=\"https://mlflow-server-631028107267.us-central1.run.app\",\n","                 use_mlflow=True, **kwargs):\n","        # Core components\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.device = device\n","        self.model_name = model_name\n","        self.dataset_name = dataset_name\n","\n","        # Training parameters\n","        self.batch_size = batch_size\n","        self.epochs = epochs\n","        self.input_size = input_size\n","        self.mlflow_uri = mlflow_uri\n","        self.use_mlflow = use_mlflow\n","\n","        # Auto-extracted parameters\n","        self.lr = optimizer.param_groups[0]['lr']\n","        self.optimizer_name = optimizer.__class__.__name__\n","        self.loss_name = criterion.__class__.__name__\n","        self.weight_decay = optimizer.param_groups[0].get('weight_decay', 0)\n","        self.momentum = optimizer.param_groups[0].get('momentum', 0)\n","\n","        # Training state\n","        self.start_time = time.time()\n","        self.epoch_times = []\n","        self.best_metric = -1\n","        self.prev_loss = None\n","        self.batch_times = []\n","        self.run_started = False  # Track run state\n","\n","        # Optional parameters\n","        self.train_size = kwargs.get('train_size', 0)\n","        self.val_size = kwargs.get('val_size', 0)\n","        self.num_workers = kwargs.get('num_workers', 0)\n","        self.use_pretrained = kwargs.get('use_pretrained', False)\n","        self.random_seed = kwargs.get('random_seed', 42)\n","\n","    def setup_mlflow(self):\n","        \"\"\"Setup MLflow with comprehensive parameter logging\"\"\"\n","        if not self.use_mlflow or self.run_started:\n","            return\n","\n","        try:\n","            # Ensure any existing run is ended\n","            if mlflow.active_run():\n","                mlflow.end_run()\n","\n","            # Configure MLflow client\n","            mlflow.set_tracking_uri(self.mlflow_uri)\n","            mlflow.set_experiment(f\"{self.model_name}-{self.dataset_name}\")\n","\n","            # Start single run\n","            mlflow.start_run(run_name=datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n","            self.run_started = True\n","\n","            # Log comprehensive parameters\n","            all_params = {\n","                **self._get_core_params(),\n","                **self._get_model_params(),\n","                **self._get_system_params(),\n","                **self._get_environment_params(),\n","                **self._get_data_params(),\n","                **self._get_training_params(),\n","            }\n","\n","            mlflow.log_params(all_params)\n","            logger.info(f\"MLflow tracking initialized: {self.mlflow_uri}\")\n","\n","        except Exception as e:\n","            logger.error(f\"MLflow setup failed: {e}\")\n","            self.use_mlflow = False\n","\n","    def _get_core_params(self):\n","        \"\"\"Core training parameters\"\"\"\n","        return {\n","            \"model_name\": self.model_name,\n","            \"dataset_name\": self.dataset_name,\n","            \"batch_size\": self.batch_size,\n","            \"learning_rate\": self.lr,\n","            \"epochs\": self.epochs,\n","            \"optimizer\": self.optimizer_name,\n","            \"loss_function\": self.loss_name,\n","            \"device\": str(self.device),\n","            \"random_seed\": self.random_seed,\n","            \"weight_decay\": self.weight_decay,\n","            \"momentum\": self.momentum,\n","        }\n","\n","    def _get_model_params(self):\n","        \"\"\"Model architecture parameters\"\"\"\n","        total_params = sum(p.numel() for p in self.model.parameters())\n","        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n","\n","        # Model size calculation\n","        param_size = sum(p.numel() * p.element_size() for p in self.model.parameters())\n","        buffer_size = sum(b.numel() * b.element_size() for b in self.model.buffers())\n","        model_size_mb = (param_size + buffer_size) / (1024 ** 2)\n","\n","        # FLOPs calculation\n","        flops_m = 0\n","        try:\n","            sample_input = torch.randn(1, *self.input_size)\n","            flops, _ = profile(self.model, inputs=(sample_input,), verbose=False)\n","            flops_m = round(flops / 1e6, 2)\n","        except Exception as e:\n","            logger.warning(f\"FLOPs calculation failed: {e}\")\n","\n","        return {\n","            \"total_parameters\": total_params,\n","            \"trainable_parameters\": trainable_params,\n","            \"parameters_millions\": round(total_params / 1e6, 2),\n","            \"model_size_mb\": round(model_size_mb, 2),\n","            \"flops_millions\": flops_m,\n","            \"input_size\": str(self.input_size),\n","            \"use_pretrained\": self.use_pretrained,\n","            \"model_architecture\": self.model.__class__.__name__,\n","        }\n","\n","    def _get_system_params(self):\n","        \"\"\"System and hardware parameters\"\"\"\n","        gpu_info = {}\n","        if torch.cuda.is_available():\n","            props = torch.cuda.get_device_properties(0)\n","            gpu_info = {\n","                \"gpu_name\": torch.cuda.get_device_name(0),\n","                \"gpu_memory_gb\": round(props.total_memory / (1024**3), 2),\n","                \"cuda_version\": torch.version.cuda,\n","                \"num_gpus\": torch.cuda.device_count(),\n","            }\n","        elif torch.backends.mps.is_available():\n","            gpu_info = {\n","                \"gpu_name\": \"Apple Silicon MPS\",\n","                \"device_type\": \"mps\"\n","            }\n","\n","        return {\n","            \"cpu_count\": psutil.cpu_count(),\n","            \"memory_total_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n","            \"platform\": platform.platform(),\n","            \"python_version\": platform.python_version(),\n","            \"pytorch_version\": torch.__version__,\n","            **gpu_info\n","        }\n","\n","    def _get_environment_params(self):\n","        \"\"\"Environment and reproducibility parameters\"\"\"\n","        git_info = {}\n","        try:\n","            commit = subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip()\n","            branch = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD']).decode().strip()\n","            git_info = {\n","                \"git_commit\": commit[:8],\n","                \"git_branch\": branch,\n","            }\n","        except:\n","            git_info = {\"git_commit\": \"unknown\", \"git_branch\": \"unknown\"}\n","\n","        return git_info\n","\n","    def _get_data_params(self):\n","        \"\"\"Data pipeline parameters\"\"\"\n","        return {\n","            \"train_size\": self.train_size,\n","            \"val_size\": self.val_size,\n","            \"total_samples\": self.train_size + self.val_size,\n","            \"num_workers\": self.num_workers,\n","        }\n","\n","    def _get_training_params(self):\n","        \"\"\"Advanced training configuration\"\"\"\n","        return {\n","            \"mlflow_uri\": self.mlflow_uri,\n","            \"experiment_name\": f\"{self.model_name}-{self.dataset_name}\",\n","        }\n","\n","    def log_epoch_metrics(self, epoch, epoch_loss, epoch_acc, batch_count=None):\n","        \"\"\"Comprehensive epoch metrics logging\"\"\"\n","        if not self.use_mlflow or not self.run_started:\n","            return {}\n","\n","        try:\n","            current_time = time.time()\n","\n","            # Timing metrics\n","            epoch_time = current_time - (self.start_time if epoch == 0 else self.start_time + sum(self.epoch_times))\n","            self.epoch_times.append(epoch_time)\n","\n","            # Core metrics\n","            metrics = {\n","                \"epoch\": epoch,\n","                \"train_loss\": epoch_loss,\n","                \"train_accuracy\": epoch_acc,\n","                \"learning_rate\": self.optimizer.param_groups[0][\"lr\"],\n","                \"epoch_time_seconds\": epoch_time,\n","                \"total_time_seconds\": current_time - self.start_time,\n","                \"avg_epoch_time\": sum(self.epoch_times) / len(self.epoch_times),\n","            }\n","\n","            # Training dynamics\n","            if self.prev_loss is not None:\n","                loss_improvement = self.prev_loss - epoch_loss\n","                metrics.update({\n","                    \"loss_improvement\": loss_improvement,\n","                    \"loss_improvement_percent\": (loss_improvement / self.prev_loss) * 100 if self.prev_loss != 0 else 0,\n","                })\n","            self.prev_loss = epoch_loss\n","\n","            # Performance metrics\n","            if batch_count and epoch_time > 0:\n","                samples_per_sec = (self.batch_size * batch_count) / epoch_time\n","                metrics.update({\n","                    \"batches_per_second\": batch_count / epoch_time,\n","                    \"samples_per_second\": samples_per_sec,\n","                })\n","\n","            # GPU/MPS metrics\n","            if torch.cuda.is_available():\n","                gpu_metrics = self._get_gpu_metrics()\n","                metrics.update(gpu_metrics)\n","\n","            # System metrics\n","            system_metrics = self._get_system_metrics()\n","            metrics.update(system_metrics)\n","\n","            mlflow.log_metrics(metrics, step=epoch)\n","            return metrics\n","\n","        except Exception as e:\n","            logger.warning(f\"Failed to log epoch metrics: {e}\")\n","            return {}\n","\n","    def _get_gpu_metrics(self):\n","        \"\"\"GPU metrics for CUDA\"\"\"\n","        if not torch.cuda.is_available():\n","            return {}\n","\n","        allocated = torch.cuda.memory_allocated()\n","        reserved = torch.cuda.memory_reserved()\n","        total = torch.cuda.get_device_properties(0).total_memory\n","\n","        return {\n","            \"gpu_memory_allocated_mb\": allocated / (1024**2),\n","            \"gpu_memory_reserved_mb\": reserved / (1024**2),\n","            \"gpu_memory_allocated_percent\": (allocated / total) * 100,\n","            \"gpu_memory_reserved_percent\": (reserved / total) * 100,\n","        }\n","\n","    def _get_system_metrics(self):\n","        \"\"\"Real-time system resource utilization\"\"\"\n","        cpu_percent = psutil.cpu_percent(interval=None)\n","        memory = psutil.virtual_memory()\n","\n","        return {\n","            \"cpu_percent\": cpu_percent,\n","            \"memory_used_percent\": memory.percent,\n","            \"memory_available_gb\": memory.available / (1024**3),\n","        }\n","\n","    def should_log_model(self, current_metric, metric_name=\"accuracy\"):\n","        \"\"\"Enhanced model checkpointing with improvement tracking\"\"\"\n","        if current_metric > self.best_metric:\n","            improvement = current_metric - self.best_metric\n","            self.best_metric = current_metric\n","\n","            if self.use_mlflow and self.run_started:\n","                try:\n","                    mlflow.log_metrics({\n","                        f\"best_{metric_name}\": current_metric,\n","                        f\"{metric_name}_improvement\": improvement,\n","                        \"checkpoint_epoch\": len(self.epoch_times),\n","                    }, step=len(self.epoch_times))\n","                except Exception as e:\n","                    logger.warning(f\"Failed to log best model metrics: {e}\")\n","\n","            return True\n","        return False\n","\n","    def log_model_artifact(self, signature=None):\n","        \"\"\"Log model with comprehensive metadata (metrics only, no artifacts)\"\"\"\n","        if not self.use_mlflow or not self.run_started:\n","            return\n","\n","        try:\n","            # Log model metadata as parameters instead of artifacts to avoid GCS issues\n","            model_metadata = {\n","                \"best_model_architecture\": self.model.__class__.__name__,\n","                \"best_model_accuracy\": self.best_metric,\n","                \"best_model_training_time_hours\": (time.time() - self.start_time) / 3600,\n","                \"best_model_epochs_trained\": len(self.epoch_times),\n","                \"best_model_parameters_count\": sum(p.numel() for p in self.model.parameters()),\n","            }\n","\n","            mlflow.log_params(model_metadata)\n","            logger.info(f\"Model metadata logged for accuracy: {self.best_metric:.4f}\")\n","\n","        except Exception as e:\n","            logger.warning(f\"Failed to log model metadata: {e}\")\n","\n","    def end_run(self, status=\"FINISHED\"):\n","        \"\"\"Clean up and end MLflow run\"\"\"\n","        if self.use_mlflow and self.run_started:\n","            try:\n","                total_time = time.time() - self.start_time\n","                summary = {\n","                    \"final_total_training_time_minutes\": round(total_time / 60, 2),\n","                    \"final_best_accuracy\": self.best_metric,\n","                    \"final_epochs_completed\": len(self.epoch_times),\n","                }\n","                mlflow.log_params(summary)\n","                mlflow.end_run(status=status)\n","                self.run_started = False\n","                return summary\n","            except Exception as e:\n","                logger.warning(f\"Failed to end MLflow run properly: {e}\")\n","                return {}\n","        return {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_kRN-fBA9Ve"},"outputs":[],"source":["class EnhancedMobileNetV2:\n","    \"\"\"MobileNetV2 with comprehensive monitoring integration\"\"\"\n","\n","    def __init__(self, num_epochs=10, batch_size=128, num_classes=100,\n","                 learning_rate=5e-3, use_mlflow=True):\n","        # Core parameters\n","        self._num_classes = num_classes\n","        self._use_mlflow = use_mlflow\n","        self._batch_size = batch_size\n","        self._num_epochs = num_epochs\n","        self._learning_rate = learning_rate\n","\n","        # Create model components\n","        self._model = self._create_model()\n","        self._device = self._set_device()\n","        self._model.to(self._device)\n","        self._criterion = self._set_criterion()\n","        self._optimizer = self._set_optimizer()\n","\n","        # Initialize comprehensive monitor\n","        self.monitor = ComprehensiveTrainingMonitor(\n","            model=self._model,\n","            optimizer=self._optimizer,\n","            criterion=self._criterion,\n","            device=self._device,\n","            model_name='MobileNetV2',\n","            dataset_name='CIFAR-100',\n","            batch_size=batch_size,\n","            epochs=num_epochs,\n","            input_size=(3, 32, 32),\n","            use_mlflow=use_mlflow,\n","            use_pretrained=True,\n","            train_size=50000,\n","            val_size=10000,\n","            num_workers=0,\n","        )\n","\n","        logger.info(f\"Model initialized on device: {self._device}\")\n","        logger.info(f\"Model parameters: {sum(p.numel() for p in self._model.parameters()):,}\")\n","\n","    def _create_model(self):\n","        \"\"\"Create MobileNetV2 model with CIFAR-100 adaptation\"\"\"\n","        model = torchvision.models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n","        # Adapt classifier for CIFAR-100 (100 classes)\n","        model.classifier[1] = nn.Linear(1280, self._num_classes)\n","        return model\n","\n","    def _set_device(self):\n","        \"\"\"Set appropriate device for training\"\"\"\n","        if torch.backends.mps.is_available():\n","            return torch.device(\"mps\")\n","        elif torch.cuda.is_available():\n","            return torch.device(\"cuda\")\n","        return torch.device(\"cpu\")\n","\n","    def _set_optimizer(self):\n","        \"\"\"Configure SGD optimizer with momentum and weight decay\"\"\"\n","        return optim.SGD(self._model.parameters(),\n","                        lr=self._learning_rate,\n","                        momentum=0.9,\n","                        weight_decay=4e-5)\n","\n","    def _set_criterion(self):\n","        \"\"\"Set loss function for classification\"\"\"\n","        return nn.CrossEntropyLoss()\n","\n","    def train_epoch(self, data_loader, epoch_idx):\n","        \"\"\"Enhanced training epoch with comprehensive monitoring\"\"\"\n","        logger.info(f\"Starting epoch {epoch_idx+1}, total batches: {len(data_loader)}\")\n","\n","        self._model.train()\n","        epoch_total_loss = 0.0\n","        running_loss = 0.0\n","        running_correct = 0\n","        running_total = 0\n","        batch_count = len(data_loader)\n","\n","        for idx, (images, targets) in enumerate(data_loader):\n","            images = images.to(self._device)\n","            targets = targets.to(self._device)\n","\n","            self._optimizer.zero_grad()\n","            logits = self._model(images)\n","            loss = self._criterion(logits, targets)\n","            loss.backward()\n","            self._optimizer.step()\n","\n","            predictions = logits.argmax(dim=1)\n","            running_correct += (predictions == targets).sum().item()\n","            running_total += targets.size(0)\n","            running_loss += loss.item()\n","            epoch_total_loss += loss.item()\n","\n","            # Progress logging every 10 batches\n","            if idx % 10 == 9:\n","                avg_loss = running_loss / 10\n","                curr_acc = running_correct / running_total\n","                logger.info(f\"Epoch {epoch_idx + 1} | Batch {idx + 1} | \"\n","                          f\"Avg Loss: {avg_loss:.4f} | Accuracy: {curr_acc:.4f}\")\n","                running_loss = 0.0\n","\n","        epoch_loss = epoch_total_loss / batch_count\n","        epoch_acc = running_correct / running_total\n","\n","        logger.info(f\"Epoch {epoch_idx + 1} completed - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n","        return epoch_loss, epoch_acc, batch_count\n","\n","    def train(self, train_loader):\n","        \"\"\"Enhanced training with comprehensive monitoring\"\"\"\n","        try:\n","            logger.info(f\"Starting training for {self._num_epochs} epochs on {self._device}\")\n","\n","            # Setup MLflow once at the beginning\n","            self.monitor.setup_mlflow()\n","\n","            for epoch in range(self._num_epochs):\n","                epoch_loss, epoch_acc, batch_count = self.train_epoch(train_loader, epoch)\n","\n","                # Log comprehensive epoch metrics\n","                metrics = self.monitor.log_epoch_metrics(epoch, epoch_loss, epoch_acc, batch_count)\n","\n","                # Model checkpointing for best performance (metadata only)\n","                if self.monitor.should_log_model(epoch_acc):\n","                    self.monitor.log_model_artifact()\n","                    logger.info(f\"New best model metadata saved with accuracy: {epoch_acc:.4f}\")\n","\n","                # Enhanced progress display\n","                print(f\"Epoch {epoch+1}/{self._num_epochs}: \"\n","                      f\"Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | \"\n","                      f\"Time: {metrics.get('epoch_time_seconds', 0):.1f}s | \"\n","                      f\"LR: {metrics.get('learning_rate', 0):.2e} | \"\n","                      f\"Memory: {metrics.get('memory_used_percent', 0):.1f}%\")\n","\n","        except Exception as e:\n","            logger.error(f\"Training failed: {e}\")\n","            self.monitor.end_run(status=\"FAILED\")\n","            raise\n","        finally:\n","            summary = self.monitor.end_run()\n","            logger.info(f\"Training completed. Summary: {summary}\")\n","            print(f\"\\nTraining Summary:\")\n","            print(f\"Total time: {summary.get('final_total_training_time_minutes', 0):.1f} minutes\")\n","            print(f\"Best accuracy: {summary.get('final_best_accuracy', 0):.4f}\")\n","            print(f\"Epochs completed: {summary.get('final_epochs_completed', 0)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11683,"status":"ok","timestamp":1751928813456,"user":{"displayName":"DizzyDoze","userId":"13303002129287970688"},"user_tz":420},"id":"rUkj617FBnqH","outputId":"55448d5e-64b9-4cdc-d046-816cda95c31d"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 169M/169M [00:05<00:00, 28.9MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training dataset size: 50000\n","Number of classes: 100\n","Class names (first 10): ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']\n"]}],"source":["# Data transforms for CIFAR-100\n","train_tf = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),  # Data augmentation\n","    transforms.RandomHorizontalFlip(0.5),   # Random horizontal flip\n","    transforms.ToTensor(),                  # Convert to tensor\n","    transforms.Normalize(                   # Normalize with ImageNet stats\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])\n","\n","# Load CIFAR-100 dataset\n","train_ds = datasets.CIFAR100(\n","    root=\"./data\",\n","    train=True,\n","    download=True,\n","    transform=train_tf\n",")\n","\n","print(f\"Training dataset size: {len(train_ds)}\")\n","print(f\"Number of classes: {len(train_ds.classes)}\")\n","print(f\"Class names (first 10): {train_ds.classes[:10]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bll8T_8uBEc_"},"outputs":[],"source":["# Optional: Visualize a sample of the data\n","def visualize_samples(dataset, num_samples=16):\n","    \"\"\"Visualize a sample of images from the dataset\"\"\"\n","    # Create subset for visualization\n","    sample_indices = np.random.choice(len(dataset), num_samples, replace=False)\n","\n","    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n","    axes = axes.ravel()\n","\n","    for i, idx in enumerate(sample_indices):\n","        img_tensor, class_idx = dataset[idx]\n","\n","        # Denormalize image for display\n","        img = img_tensor.permute(1, 2, 0)\n","        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n","        img = torch.clamp(img, 0, 1)\n","\n","        axes[i].imshow(img)\n","        axes[i].set_title(f\"Class: {dataset.classes[class_idx]}\")\n","        axes[i].axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Uncomment to visualize samples\n","# visualize_samples(train_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1751928813518,"user":{"displayName":"DizzyDoze","userId":"13303002129287970688"},"user_tz":420},"id":"wDN0WcGZBFLy","outputId":"4d82f86c-3795-41ac-bcec-973b28770326"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of batches per epoch: 391\n","Total samples per epoch: 50048\n"]}],"source":["# Create data loader\n","train_loader = DataLoader(\n","    train_ds,\n","    batch_size=128,\n","    shuffle=True,\n","    num_workers=0,      # Set to 0 for MPS compatibility\n","    pin_memory=False    # Disable for MPS\n",")\n","\n","print(f\"Number of batches per epoch: {len(train_loader)}\")\n","print(f\"Total samples per epoch: {len(train_loader) * 128}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":866,"status":"ok","timestamp":1751928814386,"user":{"displayName":"DizzyDoze","userId":"13303002129287970688"},"user_tz":420},"id":"i-3WhL4dBGlf","outputId":"d6eaf687-a862-4a30-b913-0f39bd0dade8"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-07-07 22:53:33,517 - INFO - ipython-input-8-2671463812.py - PID:616 - TID:135040586224256 - Initializing Enhanced MobileNetV2 model\n"]},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n","100%|██████████| 13.6M/13.6M [00:00<00:00, 48.8MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["2025-07-07 22:53:34,389 - INFO - ipython-input-4-1834505936.py - PID:616 - TID:135040586224256 - Model initialized on device: cuda\n","2025-07-07 22:53:34,393 - INFO - ipython-input-4-1834505936.py - PID:616 - TID:135040586224256 - Model parameters: 2,351,972\n","Model initialized successfully!\n","Device: cuda\n","Total parameters: 2,351,972\n","Trainable parameters: 2,351,972\n"]}],"source":["# Initialize and train the model\n","logger.info(\"Initializing Enhanced MobileNetV2 model\")\n","\n","model = EnhancedMobileNetV2(\n","    num_epochs=100,\n","    batch_size=128,\n","    num_classes=100,\n","    learning_rate=5e-3,\n","    use_mlflow=True\n",")\n","\n","print(\"Model initialized successfully!\")\n","print(f\"Device: {model._device}\")\n","print(f\"Total parameters: {sum(p.numel() for p in model._model.parameters()):,}\")\n","print(f\"Trainable parameters: {sum(p.numel() for p in model._model.parameters() if p.requires_grad):,}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JC5fvLRjBH8C"},"outputs":[],"source":["# Start training with comprehensive monitoring\n","print(\"\\n\" + \"=\"*50)\n","print(\" STARTING ENHANCED MOBILENETV2 TRAINING\")\n","print(\"=\"*50)\n","print(f\"Dataset: CIFAR-100 (100 classes)\")\n","print(f\"Model: MobileNetV2 (pretrained)\")\n","print(f\"Epochs: {model._num_epochs}\")\n","print(f\"Batch size: {model._batch_size}\")\n","print(f\"Learning rate: {model._learning_rate}\")\n","print(f\"MLflow tracking: {'Enabled' if model._use_mlflow else 'Disabled'}\")\n","print(f\"MLflow URI: {model.monitor.mlflow_uri}\")\n","print(\"=\"*50 + \"\\n\")\n","\n","# Start training\n","model.train(train_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3TvvXzbBz7Y"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMYZDW3c+maUFI63troF8xy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}