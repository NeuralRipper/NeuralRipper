{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wCF70rRvASrn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (3.1.1)\n",
      "Requirement already satisfied: thop in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torchvision in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (0.22.1)\n",
      "Requirement already satisfied: mlflow-skinny==3.1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: Flask<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.16.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.10.3)\n",
      "Requirement already satisfied: numpy<3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.2.6)\n",
      "Requirement already satisfied: pandas<3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.3.0)\n",
      "Requirement already satisfied: pyarrow<21,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (20.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.7.0)\n",
      "Requirement already satisfied: scipy<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.16.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.0.41)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.57.0)\n",
      "Requirement already satisfied: fastapi<1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.115.14)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (1.34.1)\n",
      "Requirement already satisfied: packaging<26 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (25.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.1)\n",
      "Requirement already satisfied: uvicorn<1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.35.0)\n",
      "Requirement already satisfied: Mako in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.40.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.46.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (0.55b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n",
      "Requirement already satisfied: torch in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from thop) (2.7.1)\n",
      "Requirement already satisfied: filelock in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from torch->thop) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from torch->thop) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from torch->thop) (3.5)\n",
      "Requirement already satisfied: fsspec in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from torch->thop) (2025.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
      "PyTorch version: 2.7.1\n",
      "Torchvision version: 0.22.1\n",
      "MLflow version: 3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow thop torchvision\n",
    "# Core imports and setup\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import numpy as np\n",
    "import psutil\n",
    "import platform\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from thop import profile\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1751928801664,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "eOnj5Ur9AVQi",
    "outputId": "4458cdf1-6416-4cf7-8bb5-54a7a4cff30d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-27 17:12:09,055 - DEBUG - 1078719332.py - PID:26817 - TID:8462606080 - Logger initialization completed\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "format_str = '%(asctime)s - %(levelname)s - %(filename)s - PID:%(process)d - TID:%(thread)d - %(message)s'\n",
    "logger = logging.getLogger(__name__ + str(time.time()))\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = False\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(logging.Formatter(format_str))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.debug(\"Logger initialization completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ObMPtBTFA8Z5"
   },
   "outputs": [],
   "source": [
    "class ComprehensiveTrainingMonitor:\n",
    "    \"\"\"Advanced training monitor with complete metrics tracking for MLflow\"\"\"\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device, model_name, dataset_name,\n",
    "                 batch_size=32, epochs=10, input_size=(3, 32, 32),\n",
    "                 mlflow_uri=\"https://neuralripper.com/mlflow/\",\n",
    "                 use_mlflow=True, **kwargs):\n",
    "        # Core components\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        # Training parameters\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.input_size = input_size\n",
    "        self.mlflow_uri = mlflow_uri\n",
    "        self.use_mlflow = use_mlflow\n",
    "\n",
    "        # Auto-extracted parameters\n",
    "        self.lr = optimizer.param_groups[0]['lr']\n",
    "        self.optimizer_name = optimizer.__class__.__name__\n",
    "        self.loss_name = criterion.__class__.__name__\n",
    "        self.weight_decay = optimizer.param_groups[0].get('weight_decay', 0)\n",
    "        self.momentum = optimizer.param_groups[0].get('momentum', 0)\n",
    "\n",
    "        # Training state\n",
    "        self.start_time = time.time()\n",
    "        self.epoch_times = []\n",
    "        self.best_metric = -1\n",
    "        self.prev_loss = None\n",
    "        self.batch_times = []\n",
    "        self.run_started = False  # Track run state\n",
    "\n",
    "        # Optional parameters\n",
    "        self.train_size = kwargs.get('train_size', 0)\n",
    "        self.val_size = kwargs.get('val_size', 0)\n",
    "        self.num_workers = kwargs.get('num_workers', 0)\n",
    "        self.use_pretrained = kwargs.get('use_pretrained', False)\n",
    "        self.random_seed = kwargs.get('random_seed', 42)\n",
    "\n",
    "        self.run_id = None  # Mlflow current run id\n",
    "\n",
    "    def setup_mlflow(self):\n",
    "        \"\"\"Setup MLflow with comprehensive parameter logging\"\"\"\n",
    "        if not self.use_mlflow or self.run_started:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Ensure any existing run is ended\n",
    "            if mlflow.active_run():\n",
    "                mlflow.end_run()\n",
    "\n",
    "            # Configure MLflow client\n",
    "            mlflow.set_tracking_uri(self.mlflow_uri)\n",
    "            mlflow.set_experiment(f\"{self.model_name}-{self.dataset_name}\")\n",
    "\n",
    "            # Start single run\n",
    "            run_name = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            mlflow.start_run(run_name=run_name)\n",
    "            self.run_id = run_name\n",
    "            self.run_started = True\n",
    "\n",
    "            # Log comprehensive parameters\n",
    "            all_params = {\n",
    "                **self._get_core_params(),\n",
    "                **self._get_model_params(),\n",
    "                **self._get_system_params(),\n",
    "                **self._get_environment_params(),\n",
    "                **self._get_data_params(),\n",
    "                **self._get_training_params(),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(all_params)\n",
    "            logger.info(f\"MLflow tracking initialized: {self.mlflow_uri}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"MLflow setup failed: {e}\")\n",
    "            self.use_mlflow = False\n",
    "\n",
    "    def _get_core_params(self):\n",
    "        \"\"\"Core training parameters\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"dataset_name\": self.dataset_name,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"learning_rate\": self.lr,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"optimizer\": self.optimizer_name,\n",
    "            \"loss_function\": self.loss_name,\n",
    "            \"device\": str(self.device),\n",
    "            \"random_seed\": self.random_seed,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"momentum\": self.momentum,\n",
    "        }\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Model architecture parameters\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "        # Model size calculation\n",
    "        param_size = sum(p.numel() * p.element_size() for p in self.model.parameters())\n",
    "        buffer_size = sum(b.numel() * b.element_size() for b in self.model.buffers())\n",
    "        model_size_mb = (param_size + buffer_size) / (1024 ** 2)\n",
    "\n",
    "        # FLOPs calculation\n",
    "        flops_m = 0\n",
    "        try:\n",
    "            sample_input = torch.randn(1, *self.input_size)\n",
    "            flops, _ = profile(self.model, inputs=(sample_input,), verbose=False)\n",
    "            flops_m = round(flops / 1e6, 2)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"FLOPs calculation failed: {e}\")\n",
    "\n",
    "        return {\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"parameters_millions\": round(total_params / 1e6, 2),\n",
    "            \"model_size_mb\": round(model_size_mb, 2),\n",
    "            \"flops_millions\": flops_m,\n",
    "            \"input_size\": str(self.input_size),\n",
    "            \"use_pretrained\": self.use_pretrained,\n",
    "            \"model_architecture\": self.model.__class__.__name__,\n",
    "        }\n",
    "\n",
    "    def _get_system_params(self):\n",
    "        \"\"\"System and hardware parameters\"\"\"\n",
    "        gpu_info = {}\n",
    "        if torch.cuda.is_available():\n",
    "            props = torch.cuda.get_device_properties(0)\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": torch.cuda.get_device_name(0),\n",
    "                \"gpu_memory_gb\": round(props.total_memory / (1024**3), 2),\n",
    "                \"cuda_version\": torch.version.cuda,\n",
    "                \"num_gpus\": torch.cuda.device_count(),\n",
    "            }\n",
    "        elif torch.backends.mps.is_available():\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": \"Apple Silicon MPS\",\n",
    "                \"device_type\": \"mps\"\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"cpu_count\": psutil.cpu_count(),\n",
    "            \"memory_total_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"python_version\": platform.python_version(),\n",
    "            \"pytorch_version\": torch.__version__,\n",
    "            **gpu_info\n",
    "        }\n",
    "\n",
    "    def _get_environment_params(self):\n",
    "        \"\"\"Environment and reproducibility parameters\"\"\"\n",
    "        git_info = {}\n",
    "        try:\n",
    "            commit = subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip()\n",
    "            branch = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD']).decode().strip()\n",
    "            git_info = {\n",
    "                \"git_commit\": commit[:8],\n",
    "                \"git_branch\": branch,\n",
    "            }\n",
    "        except:\n",
    "            git_info = {\"git_commit\": \"unknown\", \"git_branch\": \"unknown\"}\n",
    "\n",
    "        return git_info\n",
    "\n",
    "    def _get_data_params(self):\n",
    "        \"\"\"Data pipeline parameters\"\"\"\n",
    "        return {\n",
    "            \"train_size\": self.train_size,\n",
    "            \"val_size\": self.val_size,\n",
    "            \"total_samples\": self.train_size + self.val_size,\n",
    "            \"num_workers\": self.num_workers,\n",
    "        }\n",
    "\n",
    "    def _get_training_params(self):\n",
    "        \"\"\"Advanced training configuration\"\"\"\n",
    "        return {\n",
    "            \"mlflow_uri\": self.mlflow_uri,\n",
    "            \"experiment_name\": f\"{self.model_name}-{self.dataset_name}\",\n",
    "        }\n",
    "\n",
    "    def log_epoch_metrics(self, epoch, epoch_loss, epoch_acc, batch_count=None):\n",
    "        \"\"\"Comprehensive epoch metrics logging\"\"\"\n",
    "        if not self.use_mlflow or not self.run_started:\n",
    "            return {}\n",
    "\n",
    "        try:\n",
    "            current_time = time.time()\n",
    "\n",
    "            # Timing metrics\n",
    "            epoch_time = current_time - (self.start_time if epoch == 0 else self.start_time + sum(self.epoch_times))\n",
    "            self.epoch_times.append(epoch_time)\n",
    "\n",
    "            # Core metrics\n",
    "            metrics = {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": epoch_loss,\n",
    "                \"train_accuracy\": epoch_acc,\n",
    "                \"learning_rate\": self.optimizer.param_groups[0][\"lr\"],\n",
    "                \"epoch_time_seconds\": epoch_time,\n",
    "                \"total_time_seconds\": current_time - self.start_time,\n",
    "                \"avg_epoch_time\": sum(self.epoch_times) / len(self.epoch_times),\n",
    "            }\n",
    "\n",
    "            # Training dynamics\n",
    "            if self.prev_loss is not None:\n",
    "                loss_improvement = self.prev_loss - epoch_loss\n",
    "                metrics.update({\n",
    "                    \"loss_improvement\": loss_improvement,\n",
    "                    \"loss_improvement_percent\": (loss_improvement / self.prev_loss) * 100 if self.prev_loss != 0 else 0,\n",
    "                })\n",
    "            self.prev_loss = epoch_loss\n",
    "\n",
    "            # Performance metrics\n",
    "            if batch_count and epoch_time > 0:\n",
    "                samples_per_sec = (self.batch_size * batch_count) / epoch_time\n",
    "                metrics.update({\n",
    "                    \"batches_per_second\": batch_count / epoch_time,\n",
    "                    \"samples_per_second\": samples_per_sec,\n",
    "                })\n",
    "\n",
    "            # GPU/MPS metrics\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_metrics = self._get_gpu_metrics()\n",
    "                metrics.update(gpu_metrics)\n",
    "\n",
    "            # System metrics\n",
    "            system_metrics = self._get_system_metrics()\n",
    "            metrics.update(system_metrics)\n",
    "\n",
    "            mlflow.log_metrics(metrics, step=epoch)\n",
    "            return metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log epoch metrics: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _get_gpu_metrics(self):\n",
    "        \"\"\"GPU metrics for CUDA\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            return {}\n",
    "\n",
    "        allocated = torch.cuda.memory_allocated()\n",
    "        reserved = torch.cuda.memory_reserved()\n",
    "        total = torch.cuda.get_device_properties(0).total_memory\n",
    "\n",
    "        return {\n",
    "            \"gpu_memory_allocated_mb\": allocated / (1024**2),\n",
    "            \"gpu_memory_reserved_mb\": reserved / (1024**2),\n",
    "            \"gpu_memory_allocated_percent\": (allocated / total) * 100,\n",
    "            \"gpu_memory_reserved_percent\": (reserved / total) * 100,\n",
    "        }\n",
    "\n",
    "    def _get_system_metrics(self):\n",
    "        \"\"\"Real-time system resource utilization\"\"\"\n",
    "        cpu_percent = psutil.cpu_percent(interval=None)\n",
    "        memory = psutil.virtual_memory()\n",
    "\n",
    "        return {\n",
    "            \"cpu_percent\": cpu_percent,\n",
    "            \"memory_used_percent\": memory.percent,\n",
    "            \"memory_available_gb\": memory.available / (1024**3),\n",
    "        }\n",
    "\n",
    "    def should_log_model(self, current_metric, metric_name=\"accuracy\"):\n",
    "        \"\"\"Enhanced model checkpointing with improvement tracking\"\"\"\n",
    "        if current_metric > self.best_metric:\n",
    "            improvement = current_metric - self.best_metric\n",
    "            self.best_metric = current_metric\n",
    "\n",
    "            if self.use_mlflow and self.run_started:\n",
    "                try:\n",
    "                    mlflow.log_metrics({\n",
    "                        f\"best_{metric_name}\": current_metric,\n",
    "                        f\"{metric_name}_improvement\": improvement,\n",
    "                        \"checkpoint_epoch\": len(self.epoch_times),\n",
    "                    }, step=len(self.epoch_times))\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to log best model metrics: {e}\")\n",
    "\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def log_model_artifact(self, signature=None):\n",
    "        \"\"\"Log model with comprehensive metadata (metrics only, no artifacts)\"\"\"\n",
    "        if not self.use_mlflow or not self.run_started:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Log model metadata as parameters instead of artifacts to avoid GCS issues\n",
    "            model_metadata = {\n",
    "                \"best_model_architecture\": self.model.__class__.__name__,\n",
    "                \"best_model_accuracy\": self.best_metric,\n",
    "                \"best_model_training_time_hours\": (time.time() - self.start_time) / 3600,\n",
    "                \"best_model_epochs_trained\": len(self.epoch_times),\n",
    "                \"best_model_parameters_count\": sum(p.numel() for p in self.model.parameters()),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(model_metadata)\n",
    "            logger.info(f\"Model metadata logged for accuracy: {self.best_metric:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log model metadata: {e}\")\n",
    "\n",
    "    def end_run(self, status=\"FINISHED\"):\n",
    "        \"\"\"Clean up and end MLflow run\"\"\"\n",
    "        if self.use_mlflow and self.run_started:\n",
    "            try:\n",
    "                total_time = time.time() - self.start_time\n",
    "                summary = {\n",
    "                    \"final_total_training_time_minutes\": round(total_time / 60, 2),\n",
    "                    \"final_best_accuracy\": self.best_metric,\n",
    "                    \"final_epochs_completed\": len(self.epoch_times),\n",
    "                }\n",
    "                mlflow.log_params(summary)\n",
    "                mlflow.end_run(status=status)\n",
    "                self.run_started = False\n",
    "                return summary\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to end MLflow run properly: {e}\")\n",
    "                return {}\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import rerun as rr\n",
    "\n",
    "\n",
    "class RerunLogger:\n",
    "    def __init__(self, run_id: str, model_name:str, backend_url: str = \"http://localhost:8000\"):\n",
    "        self.run_id = run_id\n",
    "        self.model_name = model_name\n",
    "        self.backend_url = backend_url\n",
    "        self.gcs_bucket = \"neuralripper-mlflow-artifacts\"\n",
    "        self.viewer_url = None\n",
    "        self.internal_url = None\n",
    "        self.initialized = False\n",
    "    \n",
    "    def get_viewer_urls(self):\n",
    "        \"\"\"Get viewer URLs from backend\"\"\"\n",
    "        try:\n",
    "            res = requests.get(f\"{self.backend_url}/rerun/{self.run_id}/live\")\n",
    "            if res.status_code == 200:\n",
    "                data = res.json()\n",
    "                self.viewer_url = data[\"viewer_url\"]\n",
    "                self.internal_url = data[\"internal_url\"]\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get viewer URLs: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"Init rerun connection\"\"\"\n",
    "        if self.get_viewer_urls():\n",
    "            logger.debug(f\"internal_url: {self.internal_url}\")\n",
    "            logger.debug(f\"viewer_url: {self.viewer_url}\")\n",
    "\n",
    "            # Extract gRPC port from internal url, use for uploading recordings\n",
    "            grpc_port = self.internal_url.split(':')[-1]\n",
    "\n",
    "            # Init recording\n",
    "            rr.init(f\"{self.model_name}_{self.run_id}\", spawn=False)\n",
    "\n",
    "            # Connect to backend gRPC server(send the recordings data to backend so it can serve in viewer url)\n",
    "            rr.connect_grpc(f\"127.0.0.1:{grpc_port}\")\n",
    "            # rr.connect_grpc(grpc_port)\n",
    "            # rr.connect_grpc()\n",
    "\n",
    "            self.initialized = True\n",
    "            print(f\"Rerun live viewer: {self.viewer_url}\")\n",
    "            print(f\"Connected to gRPC: 127.0.0.1:{grpc_port}\")\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def log_training_step(self, epoch: int, step: int, loss: float, accuracy: float, \n",
    "                          lr: float, gpu_memory: dict = None, system_metrics: dict = None):\n",
    "        \"\"\"Log training metrics to rerun\"\"\"\n",
    "        if not self.initialized:\n",
    "            return\n",
    "            \n",
    "        rr.log(\"training/loss\", rr.Scalars(loss))\n",
    "        rr.log(\"training/accuracy\", rr.Scalars(accuracy))\n",
    "        rr.log(\"training/learning_rate\", rr.Scalars(lr))\n",
    "        rr.log(\"progress/epoch\", rr.Scalars(epoch))\n",
    "        rr.log(\"progress/step\", rr.Scalars(step))\n",
    "        \n",
    "        if gpu_memory:\n",
    "            rr.log(\"system/gpu_memory_mb\", rr.Scalars(gpu_memory.get('gpu_memory_allocated_mb', 0)))\n",
    "        if system_metrics:\n",
    "            rr.log(\"system/cpu_percent\", rr.Scalars(system_metrics.get('cpu_percent', 0)))\n",
    "            rr.log(\"system/memory_percent\", rr.Scalars(system_metrics.get('memory_used_percent', 0)))\n",
    "\n",
    "    def save_recording(self):\n",
    "        \"\"\"Save recording directly to GCS\"\"\"\n",
    "        if not self.initialized:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            gcs_path = f\"gs://{self.gcs_bucket}/rerun_recordings/{self.model_name}_{self.run_id}.rrd\"\n",
    "            rr.save(gcs_path)\n",
    "            print(f\"Recording saved: {gcs_path}\")\n",
    "            return gcs_path\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save recording: {e}\")\n",
    "            return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "P_kRN-fBA9Ve"
   },
   "outputs": [],
   "source": [
    "class EnhancedMobileNetV2:\n",
    "    \"\"\"MobileNetV2 with comprehensive monitoring integration\"\"\"\n",
    "\n",
    "    def __init__(self, num_epochs=10, batch_size=128, num_classes=100,\n",
    "                 learning_rate=5e-3, use_mlflow=True):\n",
    "        # Core parameters\n",
    "        self._num_classes = num_classes\n",
    "        self._use_mlflow = use_mlflow\n",
    "        self._batch_size = batch_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        # Create model components\n",
    "        self._model = self._create_model()\n",
    "        self._device = self._set_device()\n",
    "        self._model.to(self._device)\n",
    "        self._criterion = self._set_criterion()\n",
    "        self._optimizer = self._set_optimizer()\n",
    "\n",
    "        # Initialize comprehensive monitor\n",
    "        self.monitor = ComprehensiveTrainingMonitor(\n",
    "            model=self._model,\n",
    "            optimizer=self._optimizer,\n",
    "            criterion=self._criterion,\n",
    "            device=self._device,\n",
    "            model_name='MobileNetV2',\n",
    "            dataset_name='CIFAR-100',\n",
    "            batch_size=batch_size,\n",
    "            epochs=num_epochs,\n",
    "            input_size=(3, 32, 32),\n",
    "            use_mlflow=use_mlflow,\n",
    "            use_pretrained=True,\n",
    "            train_size=50000,\n",
    "            val_size=10000,\n",
    "            num_workers=0,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Model initialized on device: {self._device}\")\n",
    "        logger.info(f\"Model parameters: {sum(p.numel() for p in self._model.parameters()):,}\")\n",
    "\n",
    "        self.rerun_logger = None    # rerun logger will be init when training starts\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Create MobileNetV2 model with CIFAR-100 adaptation\"\"\"\n",
    "        model = torchvision.models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "        # Adapt classifier for CIFAR-100 (100 classes)\n",
    "        model.classifier[1] = nn.Linear(1280, self._num_classes)\n",
    "        return model\n",
    "\n",
    "    def _set_device(self):\n",
    "        \"\"\"Set appropriate device for training\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def _set_optimizer(self):\n",
    "        \"\"\"Configure SGD optimizer with momentum and weight decay\"\"\"\n",
    "        return optim.SGD(self._model.parameters(),\n",
    "                        lr=self._learning_rate,\n",
    "                        momentum=0.9,\n",
    "                        weight_decay=4e-5)\n",
    "\n",
    "    def _set_criterion(self):\n",
    "        \"\"\"Set loss function for classification\"\"\"\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    def train_epoch(self, data_loader, epoch_idx):\n",
    "        \"\"\"Enhanced training epoch with comprehensive monitoring\"\"\"\n",
    "        logger.info(f\"Starting epoch {epoch_idx+1}, total batches: {len(data_loader)}\")\n",
    "\n",
    "        self._model.train()\n",
    "        epoch_total_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "        batch_count = len(data_loader)\n",
    "\n",
    "        for idx, (images, targets) in enumerate(data_loader):\n",
    "            images = images.to(self._device)\n",
    "            targets = targets.to(self._device)\n",
    "\n",
    "            self._optimizer.zero_grad()\n",
    "            logits = self._model(images)\n",
    "            loss = self._criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            running_correct += (predictions == targets).sum().item()\n",
    "            running_total += targets.size(0)\n",
    "            running_loss += loss.item()\n",
    "            epoch_total_loss += loss.item()\n",
    "\n",
    "            # Progress logging every 10 batches\n",
    "            if idx % 10 == 9:\n",
    "                avg_loss = running_loss / 10\n",
    "                curr_acc = running_correct / running_total\n",
    "                logger.info(f\"Epoch {epoch_idx + 1} | Batch {idx + 1} | \"\n",
    "                          f\"Avg Loss: {avg_loss:.4f} | Accuracy: {curr_acc:.4f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "                # Rerun loggings\n",
    "                if self.rerun_logger:\n",
    "                    gpu_metrics = self.monitor._get_gpu_metrics()\n",
    "                    sys_metrics = self.monitor._get_system_metrics()\n",
    "\n",
    "                    self.rerun_logger.log_training_step(\n",
    "                        epoch=epoch_idx,\n",
    "                        step=(epoch_idx * len(data_loader)) + idx,\n",
    "                        loss=avg_loss,\n",
    "                        accuracy=curr_acc,\n",
    "                        lr=self._optimizer.param_groups[0]['lr'],\n",
    "                        gpu_memory=gpu_metrics,\n",
    "                        system_metrics=sys_metrics\n",
    "                    )\n",
    "\n",
    "\n",
    "        epoch_loss = epoch_total_loss / batch_count\n",
    "        epoch_acc = running_correct / running_total\n",
    "\n",
    "        logger.info(f\"Epoch {epoch_idx + 1} completed - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "        return epoch_loss, epoch_acc, batch_count\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        \"\"\"Enhanced training with comprehensive monitoring\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Starting training for {self._num_epochs} epochs on {self._device}\")\n",
    "\n",
    "            # Setup MLflow once at the beginning\n",
    "            self.monitor.setup_mlflow()\n",
    "\n",
    "            # Init RerunLogger\n",
    "            if self.monitor.run_id:\n",
    "                self.rerun_logger = RerunLogger(self.monitor.run_id, \"MobileNetV2\")\n",
    "                self.rerun_logger.initialize()\n",
    "\n",
    "            for epoch in range(self._num_epochs):\n",
    "                epoch_loss, epoch_acc, batch_count = self.train_epoch(train_loader, epoch)\n",
    "\n",
    "                # Log comprehensive epoch metrics\n",
    "                metrics = self.monitor.log_epoch_metrics(epoch, epoch_loss, epoch_acc, batch_count)\n",
    "\n",
    "                # Model checkpointing for best performance (metadata only)\n",
    "                if self.monitor.should_log_model(epoch_acc):\n",
    "                    self.monitor.log_model_artifact()\n",
    "                    logger.info(f\"New best model metadata saved with accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "                # Enhanced progress display\n",
    "                print(f\"Epoch {epoch+1}/{self._num_epochs}: \"\n",
    "                      f\"Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | \"\n",
    "                      f\"Time: {metrics.get('epoch_time_seconds', 0):.1f}s | \"\n",
    "                      f\"LR: {metrics.get('learning_rate', 0):.2e} | \"\n",
    "                      f\"Memory: {metrics.get('memory_used_percent', 0):.1f}%\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training failed: {e}\")\n",
    "            self.monitor.end_run(status=\"FAILED\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Save rerun recording after training\n",
    "            if self.rerun_logger:\n",
    "                self.rerun_logger.save_recording()\n",
    "\n",
    "            summary = self.monitor.end_run()\n",
    "            logger.info(f\"Training completed. Summary: {summary}\")\n",
    "            print(f\"\\nTraining Summary:\")\n",
    "            print(f\"Total time: {summary.get('final_total_training_time_minutes', 0):.1f} minutes\")\n",
    "            print(f\"Best accuracy: {summary.get('final_best_accuracy', 0):.4f}\")\n",
    "            print(f\"Epochs completed: {summary.get('final_epochs_completed', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11683,
     "status": "ok",
     "timestamp": 1751928813456,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "rUkj617FBnqH",
    "outputId": "55448d5e-64b9-4cdc-d046-816cda95c31d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169M/169M [00:06<00:00, 25.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Number of classes: 100\n",
      "Class names (first 10): ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']\n",
      "Subset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Data transforms for CIFAR-100\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Data augmentation\n",
    "    transforms.RandomHorizontalFlip(0.5),   # Random horizontal flip\n",
    "    transforms.ToTensor(),                  # Convert to tensor\n",
    "    transforms.Normalize(                   # Normalize with ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "train_ds = datasets.CIFAR100(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_tf\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# only use first 10000 images for local training\n",
    "train_subset = Subset(train_ds, range(10000))\n",
    "\n",
    "print(f\"Training dataset size: {len(train_ds)}\")\n",
    "print(f\"Number of classes: {len(train_ds.classes)}\")\n",
    "print(f\"Class names (first 10): {train_ds.classes[:10]}\")\n",
    "print(f\"Subset size: {len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Bll8T_8uBEc_"
   },
   "outputs": [],
   "source": [
    "# Optional: Visualize a sample of the data\n",
    "def visualize_samples(dataset, num_samples=16):\n",
    "    \"\"\"Visualize a sample of images from the dataset\"\"\"\n",
    "    # Create subset for visualization\n",
    "    sample_indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img_tensor, class_idx = dataset[idx]\n",
    "\n",
    "        # Denormalize image for display\n",
    "        img = img_tensor.permute(1, 2, 0)\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Class: {dataset.classes[class_idx]}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to visualize samples\n",
    "# visualize_samples(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1751928813518,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "wDN0WcGZBFLy",
    "outputId": "4d82f86c-3795-41ac-bcec-973b28770326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per epoch: 391\n",
      "Total samples per epoch: 50048\n"
     ]
    }
   ],
   "source": [
    "# Create data loader\n",
    "train_loader = DataLoader(\n",
    "    # train_subset,       # subset for local test, change to original ds for production\n",
    "    train_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,      # Set to 0 for MPS compatibility\n",
    "    pin_memory=False    # Disable for MPS\n",
    ")\n",
    "\n",
    "print(f\"Number of batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Total samples per epoch: {len(train_loader) * 128}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 866,
     "status": "ok",
     "timestamp": 1751928814386,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "i-3WhL4dBGlf",
    "outputId": "d6eaf687-a862-4a30-b913-0f39bd0dade8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-27 17:15:07,839 - INFO - 2346846570.py - PID:26817 - TID:8462606080 - Initializing Enhanced MobileNetV2 model\n",
      "2025-07-27 17:15:08,024 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Model initialized on device: mps\n",
      "2025-07-27 17:15:08,025 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Model parameters: 2,351,972\n",
      "Model initialized successfully!\n",
      "Device: mps\n",
      "Total parameters: 2,351,972\n",
      "Trainable parameters: 2,351,972\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "logger.info(\"Initializing Enhanced MobileNetV2 model\")\n",
    "\n",
    "model = EnhancedMobileNetV2(\n",
    "    num_epochs=5,\n",
    "    batch_size=128,\n",
    "    num_classes=100,\n",
    "    learning_rate=3e-3,\n",
    "    use_mlflow=True\n",
    ")\n",
    "\n",
    "print(\"Model initialized successfully!\")\n",
    "print(f\"Device: {model._device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model._model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model._model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JC5fvLRjBH8C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " STARTING ENHANCED MOBILENETV2 TRAINING\n",
      "==================================================\n",
      "Dataset: CIFAR-100 (100 classes)\n",
      "Model: MobileNetV2 (pretrained)\n",
      "Epochs: 5\n",
      "Batch size: 128\n",
      "Learning rate: 0.003\n",
      "MLflow tracking: Enabled\n",
      "MLflow URI: https://neuralripper.com/mlflow/\n",
      "==================================================\n",
      "\n",
      "2025-07-27 17:15:09,964 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting training for 5 epochs on mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 17:15:10 INFO mlflow.tracking.fluent: Experiment with name 'MobileNetV2-CIFAR-100' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-27 17:15:13,411 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - FLOPs calculation failed: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device\n",
      "2025-07-27 17:15:13,656 - INFO - 1236875293.py - PID:26817 - TID:8462606080 - MLflow tracking initialized: https://neuralripper.com/mlflow/\n",
      "2025-07-27 17:15:13,682 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 1, total batches: 391\n",
      "2025-07-27 17:15:17,500 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 10 | Avg Loss: 4.6650 | Accuracy: 0.0164\n",
      "2025-07-27 17:15:18,005 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 20 | Avg Loss: 4.6640 | Accuracy: 0.0145\n",
      "2025-07-27 17:15:18,513 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 30 | Avg Loss: 4.6218 | Accuracy: 0.0138\n",
      "2025-07-27 17:15:19,019 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 40 | Avg Loss: 4.5864 | Accuracy: 0.0148\n",
      "2025-07-27 17:15:19,528 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 50 | Avg Loss: 4.5575 | Accuracy: 0.0177\n",
      "2025-07-27 17:15:20,039 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 60 | Avg Loss: 4.5501 | Accuracy: 0.0202\n",
      "2025-07-27 17:15:20,546 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 70 | Avg Loss: 4.5430 | Accuracy: 0.0219\n",
      "2025-07-27 17:15:21,057 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 80 | Avg Loss: 4.4849 | Accuracy: 0.0244\n",
      "2025-07-27 17:15:21,566 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 90 | Avg Loss: 4.4568 | Accuracy: 0.0266\n",
      "2025-07-27 17:15:22,075 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 100 | Avg Loss: 4.4584 | Accuracy: 0.0278\n",
      "2025-07-27 17:15:22,583 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 110 | Avg Loss: 4.3902 | Accuracy: 0.0311\n",
      "2025-07-27 17:15:23,107 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 120 | Avg Loss: 4.3636 | Accuracy: 0.0337\n",
      "2025-07-27 17:15:23,656 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 130 | Avg Loss: 4.3391 | Accuracy: 0.0361\n",
      "2025-07-27 17:15:24,161 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 140 | Avg Loss: 4.2533 | Accuracy: 0.0394\n",
      "2025-07-27 17:15:24,668 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 150 | Avg Loss: 4.1958 | Accuracy: 0.0426\n",
      "2025-07-27 17:15:25,174 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 160 | Avg Loss: 4.1769 | Accuracy: 0.0457\n",
      "2025-07-27 17:15:25,680 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 170 | Avg Loss: 4.1189 | Accuracy: 0.0492\n",
      "2025-07-27 17:15:26,183 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 180 | Avg Loss: 4.0760 | Accuracy: 0.0528\n",
      "2025-07-27 17:15:26,691 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 190 | Avg Loss: 4.0561 | Accuracy: 0.0550\n",
      "2025-07-27 17:15:27,198 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 200 | Avg Loss: 3.9738 | Accuracy: 0.0584\n",
      "2025-07-27 17:15:27,702 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 210 | Avg Loss: 3.9801 | Accuracy: 0.0609\n",
      "2025-07-27 17:15:28,205 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 220 | Avg Loss: 3.9073 | Accuracy: 0.0645\n",
      "2025-07-27 17:15:28,830 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 230 | Avg Loss: 3.7861 | Accuracy: 0.0686\n",
      "2025-07-27 17:15:29,475 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 240 | Avg Loss: 3.7985 | Accuracy: 0.0719\n",
      "2025-07-27 17:15:30,015 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 250 | Avg Loss: 3.7273 | Accuracy: 0.0758\n",
      "2025-07-27 17:15:30,591 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 260 | Avg Loss: 3.7575 | Accuracy: 0.0786\n",
      "2025-07-27 17:15:31,107 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 270 | Avg Loss: 3.6262 | Accuracy: 0.0824\n",
      "2025-07-27 17:15:31,678 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 280 | Avg Loss: 3.6179 | Accuracy: 0.0859\n",
      "2025-07-27 17:15:32,289 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 290 | Avg Loss: 3.5875 | Accuracy: 0.0893\n",
      "2025-07-27 17:15:32,795 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 300 | Avg Loss: 3.5867 | Accuracy: 0.0922\n",
      "2025-07-27 17:15:33,362 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 310 | Avg Loss: 3.5513 | Accuracy: 0.0952\n",
      "2025-07-27 17:15:33,950 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 320 | Avg Loss: 3.5049 | Accuracy: 0.0985\n",
      "2025-07-27 17:15:34,548 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 330 | Avg Loss: 3.4322 | Accuracy: 0.1020\n",
      "2025-07-27 17:15:35,209 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 340 | Avg Loss: 3.3850 | Accuracy: 0.1051\n",
      "2025-07-27 17:15:35,850 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 350 | Avg Loss: 3.4055 | Accuracy: 0.1077\n",
      "2025-07-27 17:15:36,514 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 360 | Avg Loss: 3.2995 | Accuracy: 0.1109\n",
      "2025-07-27 17:15:37,162 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 370 | Avg Loss: 3.3884 | Accuracy: 0.1134\n",
      "2025-07-27 17:15:37,832 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 380 | Avg Loss: 3.3534 | Accuracy: 0.1158\n",
      "2025-07-27 17:15:38,503 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 390 | Avg Loss: 3.2018 | Accuracy: 0.1190\n",
      "2025-07-27 17:15:39,823 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 completed - Loss: 3.9836, Accuracy: 0.1191\n",
      "2025-07-27 17:15:44,137 - INFO - 1236875293.py - PID:26817 - TID:8462606080 - Model metadata logged for accuracy: 0.1191\n",
      "2025-07-27 17:15:44,138 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.1191\n",
      "Epoch 1/5: Loss: 3.9836 | Acc: 0.1191 | Time: 31.8s | LR: 3.00e-03 | Memory: 82.3%\n",
      "2025-07-27 17:15:44,139 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 2, total batches: 391\n",
      "2025-07-27 17:15:44,734 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 10 | Avg Loss: 3.1966 | Accuracy: 0.2406\n",
      "2025-07-27 17:15:45,433 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 20 | Avg Loss: 3.2022 | Accuracy: 0.2449\n",
      "2025-07-27 17:15:46,055 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 30 | Avg Loss: 3.1621 | Accuracy: 0.2466\n",
      "2025-07-27 17:15:46,601 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 40 | Avg Loss: 3.1667 | Accuracy: 0.2463\n",
      "2025-07-27 17:15:47,219 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 50 | Avg Loss: 3.1440 | Accuracy: 0.2484\n",
      "2025-07-27 17:15:47,792 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 60 | Avg Loss: 3.0715 | Accuracy: 0.2499\n",
      "2025-07-27 17:15:48,305 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 70 | Avg Loss: 3.0730 | Accuracy: 0.2546\n",
      "2025-07-27 17:15:48,843 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 80 | Avg Loss: 2.9767 | Accuracy: 0.2577\n",
      "2025-07-27 17:15:49,381 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 90 | Avg Loss: 3.0268 | Accuracy: 0.2569\n",
      "2025-07-27 17:15:49,934 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 100 | Avg Loss: 3.0799 | Accuracy: 0.2570\n",
      "2025-07-27 17:15:50,517 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 110 | Avg Loss: 2.9756 | Accuracy: 0.2586\n",
      "2025-07-27 17:15:51,029 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 120 | Avg Loss: 3.0100 | Accuracy: 0.2581\n",
      "2025-07-27 17:15:51,544 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 130 | Avg Loss: 3.0172 | Accuracy: 0.2595\n",
      "2025-07-27 17:15:52,058 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 140 | Avg Loss: 2.9561 | Accuracy: 0.2613\n",
      "2025-07-27 17:15:52,570 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 150 | Avg Loss: 2.9021 | Accuracy: 0.2624\n",
      "2025-07-27 17:15:53,088 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 160 | Avg Loss: 2.9025 | Accuracy: 0.2626\n",
      "2025-07-27 17:15:53,635 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 170 | Avg Loss: 2.9462 | Accuracy: 0.2631\n",
      "2025-07-27 17:15:54,194 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 180 | Avg Loss: 2.8915 | Accuracy: 0.2643\n",
      "2025-07-27 17:15:54,818 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 190 | Avg Loss: 2.8549 | Accuracy: 0.2660\n",
      "2025-07-27 17:15:55,409 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 200 | Avg Loss: 2.9722 | Accuracy: 0.2664\n",
      "2025-07-27 17:15:55,956 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 210 | Avg Loss: 2.8355 | Accuracy: 0.2676\n",
      "2025-07-27 17:15:56,468 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 220 | Avg Loss: 2.7969 | Accuracy: 0.2691\n",
      "2025-07-27 17:15:56,995 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 230 | Avg Loss: 2.7820 | Accuracy: 0.2707\n",
      "2025-07-27 17:15:57,559 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 240 | Avg Loss: 2.7922 | Accuracy: 0.2721\n",
      "2025-07-27 17:15:58,118 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 250 | Avg Loss: 2.7991 | Accuracy: 0.2732\n",
      "2025-07-27 17:15:58,641 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 260 | Avg Loss: 2.7665 | Accuracy: 0.2747\n",
      "2025-07-27 17:15:59,153 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 270 | Avg Loss: 2.7782 | Accuracy: 0.2753\n",
      "2025-07-27 17:15:59,715 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 280 | Avg Loss: 2.7632 | Accuracy: 0.2766\n",
      "2025-07-27 17:16:00,265 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 290 | Avg Loss: 2.7687 | Accuracy: 0.2776\n",
      "2025-07-27 17:16:00,853 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 300 | Avg Loss: 2.6808 | Accuracy: 0.2796\n",
      "2025-07-27 17:16:01,414 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 310 | Avg Loss: 2.7084 | Accuracy: 0.2812\n",
      "2025-07-27 17:16:01,986 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 320 | Avg Loss: 2.6836 | Accuracy: 0.2828\n",
      "2025-07-27 17:16:02,576 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 330 | Avg Loss: 2.6374 | Accuracy: 0.2844\n",
      "2025-07-27 17:16:03,164 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 340 | Avg Loss: 2.6793 | Accuracy: 0.2852\n",
      "2025-07-27 17:16:03,761 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 350 | Avg Loss: 2.7696 | Accuracy: 0.2855\n",
      "2025-07-27 17:16:04,370 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 360 | Avg Loss: 2.6205 | Accuracy: 0.2870\n",
      "2025-07-27 17:16:04,990 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 370 | Avg Loss: 2.6558 | Accuracy: 0.2886\n",
      "2025-07-27 17:16:05,612 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 380 | Avg Loss: 2.5933 | Accuracy: 0.2897\n",
      "2025-07-27 17:16:06,249 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 390 | Avg Loss: 2.5601 | Accuracy: 0.2911\n",
      "2025-07-27 17:16:06,304 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 completed - Loss: 2.8761, Accuracy: 0.2912\n",
      "2025-07-27 17:16:07,397 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11912', 'new_value': '0.29118'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009970732000139024', 'new_value': '0.016445740858713784'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '2'}]' for run ID='ec892d7e077545d0bc2aa9012811b37c'.\n",
      "2025-07-27 17:16:07,397 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.2912\n",
      "Epoch 2/5: Loss: 2.8761 | Acc: 0.2912 | Time: 26.5s | LR: 3.00e-03 | Memory: 82.5%\n",
      "2025-07-27 17:16:07,398 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 3, total batches: 391\n",
      "2025-07-27 17:16:07,938 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 10 | Avg Loss: 2.5503 | Accuracy: 0.3352\n",
      "2025-07-27 17:16:08,449 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 20 | Avg Loss: 2.4493 | Accuracy: 0.3551\n",
      "2025-07-27 17:16:08,958 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 30 | Avg Loss: 2.3997 | Accuracy: 0.3604\n",
      "2025-07-27 17:16:09,468 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 40 | Avg Loss: 2.4493 | Accuracy: 0.3602\n",
      "2025-07-27 17:16:09,976 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 50 | Avg Loss: 2.4750 | Accuracy: 0.3617\n",
      "2025-07-27 17:16:10,484 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 60 | Avg Loss: 2.4670 | Accuracy: 0.3612\n",
      "2025-07-27 17:16:11,029 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 70 | Avg Loss: 2.5006 | Accuracy: 0.3606\n",
      "2025-07-27 17:16:11,540 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 80 | Avg Loss: 2.5084 | Accuracy: 0.3609\n",
      "2025-07-27 17:16:12,047 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 90 | Avg Loss: 2.5191 | Accuracy: 0.3589\n",
      "2025-07-27 17:16:12,553 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 100 | Avg Loss: 2.5380 | Accuracy: 0.3556\n",
      "2025-07-27 17:16:13,060 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 110 | Avg Loss: 2.4770 | Accuracy: 0.3562\n",
      "2025-07-27 17:16:13,572 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 120 | Avg Loss: 2.3874 | Accuracy: 0.3580\n",
      "2025-07-27 17:16:14,078 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 130 | Avg Loss: 2.3990 | Accuracy: 0.3591\n",
      "2025-07-27 17:16:14,585 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 140 | Avg Loss: 2.4216 | Accuracy: 0.3594\n",
      "2025-07-27 17:16:15,095 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 150 | Avg Loss: 2.3919 | Accuracy: 0.3598\n",
      "2025-07-27 17:16:15,601 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 160 | Avg Loss: 2.4001 | Accuracy: 0.3606\n",
      "2025-07-27 17:16:16,108 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 170 | Avg Loss: 2.4011 | Accuracy: 0.3614\n",
      "2025-07-27 17:16:16,616 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 180 | Avg Loss: 2.3262 | Accuracy: 0.3626\n",
      "2025-07-27 17:16:17,122 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 190 | Avg Loss: 2.3541 | Accuracy: 0.3646\n",
      "2025-07-27 17:16:17,628 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 200 | Avg Loss: 2.3820 | Accuracy: 0.3649\n",
      "2025-07-27 17:16:18,136 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 210 | Avg Loss: 2.3157 | Accuracy: 0.3667\n",
      "2025-07-27 17:16:18,647 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 220 | Avg Loss: 2.3623 | Accuracy: 0.3674\n",
      "2025-07-27 17:16:19,152 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 230 | Avg Loss: 2.3822 | Accuracy: 0.3684\n",
      "2025-07-27 17:16:19,661 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 240 | Avg Loss: 2.3760 | Accuracy: 0.3684\n",
      "2025-07-27 17:16:20,169 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 250 | Avg Loss: 2.3863 | Accuracy: 0.3688\n",
      "2025-07-27 17:16:20,675 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 260 | Avg Loss: 2.3060 | Accuracy: 0.3700\n",
      "2025-07-27 17:16:21,181 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 270 | Avg Loss: 2.3967 | Accuracy: 0.3703\n",
      "2025-07-27 17:16:21,702 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 280 | Avg Loss: 2.3036 | Accuracy: 0.3712\n",
      "2025-07-27 17:16:22,205 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 290 | Avg Loss: 2.4269 | Accuracy: 0.3708\n",
      "2025-07-27 17:16:22,711 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 300 | Avg Loss: 2.2883 | Accuracy: 0.3724\n",
      "2025-07-27 17:16:23,216 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 310 | Avg Loss: 2.3395 | Accuracy: 0.3731\n",
      "2025-07-27 17:16:23,759 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 320 | Avg Loss: 2.3453 | Accuracy: 0.3738\n",
      "2025-07-27 17:16:24,321 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 330 | Avg Loss: 2.3218 | Accuracy: 0.3743\n",
      "2025-07-27 17:16:24,908 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 340 | Avg Loss: 2.2730 | Accuracy: 0.3751\n",
      "2025-07-27 17:16:25,578 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 350 | Avg Loss: 2.3518 | Accuracy: 0.3750\n",
      "2025-07-27 17:16:26,216 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 360 | Avg Loss: 2.3393 | Accuracy: 0.3757\n",
      "2025-07-27 17:16:26,877 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 370 | Avg Loss: 2.3739 | Accuracy: 0.3753\n",
      "2025-07-27 17:16:27,547 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 380 | Avg Loss: 2.3349 | Accuracy: 0.3758\n",
      "2025-07-27 17:16:28,219 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 390 | Avg Loss: 2.2697 | Accuracy: 0.3764\n",
      "2025-07-27 17:16:28,269 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 completed - Loss: 2.3921, Accuracy: 0.3765\n",
      "2025-07-27 17:17:42,484 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11912', 'new_value': '0.37652'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009970732000139024', 'new_value': '0.04285160866048601'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '3'}]' for run ID='ec892d7e077545d0bc2aa9012811b37c'.\n",
      "2025-07-27 17:17:42,485 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.3765\n",
      "Epoch 3/5: Loss: 2.3921 | Acc: 0.3765 | Time: 22.0s | LR: 3.00e-03 | Memory: 81.9%\n",
      "2025-07-27 17:17:42,486 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 4, total batches: 391\n",
      "2025-07-27 17:17:43,124 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 10 | Avg Loss: 2.1899 | Accuracy: 0.3977\n",
      "2025-07-27 17:17:43,632 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 20 | Avg Loss: 2.2763 | Accuracy: 0.4035\n",
      "2025-07-27 17:17:44,135 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 30 | Avg Loss: 2.2427 | Accuracy: 0.4094\n",
      "2025-07-27 17:17:44,642 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 40 | Avg Loss: 2.0540 | Accuracy: 0.4184\n",
      "2025-07-27 17:17:45,149 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 50 | Avg Loss: 2.0917 | Accuracy: 0.4206\n",
      "2025-07-27 17:17:45,654 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 60 | Avg Loss: 2.2046 | Accuracy: 0.4208\n",
      "2025-07-27 17:17:46,162 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 70 | Avg Loss: 2.1097 | Accuracy: 0.4246\n",
      "2025-07-27 17:17:46,667 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 80 | Avg Loss: 2.1180 | Accuracy: 0.4265\n",
      "2025-07-27 17:17:47,169 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 90 | Avg Loss: 2.1248 | Accuracy: 0.4277\n",
      "2025-07-27 17:17:47,682 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 100 | Avg Loss: 2.1252 | Accuracy: 0.4264\n",
      "2025-07-27 17:17:48,187 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 110 | Avg Loss: 2.2186 | Accuracy: 0.4267\n",
      "2025-07-27 17:17:48,693 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 120 | Avg Loss: 2.2079 | Accuracy: 0.4254\n",
      "2025-07-27 17:17:49,198 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 130 | Avg Loss: 2.2010 | Accuracy: 0.4257\n",
      "2025-07-27 17:17:49,707 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 140 | Avg Loss: 2.1292 | Accuracy: 0.4262\n",
      "2025-07-27 17:17:50,212 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 150 | Avg Loss: 2.1650 | Accuracy: 0.4260\n",
      "2025-07-27 17:17:50,717 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 160 | Avg Loss: 2.1607 | Accuracy: 0.4267\n",
      "2025-07-27 17:17:51,222 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 170 | Avg Loss: 2.1998 | Accuracy: 0.4258\n",
      "2025-07-27 17:17:51,728 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 180 | Avg Loss: 2.1876 | Accuracy: 0.4247\n",
      "2025-07-27 17:17:52,235 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 190 | Avg Loss: 2.1823 | Accuracy: 0.4234\n",
      "2025-07-27 17:17:52,740 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 200 | Avg Loss: 2.2237 | Accuracy: 0.4225\n",
      "2025-07-27 17:17:53,246 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 210 | Avg Loss: 2.0843 | Accuracy: 0.4233\n",
      "2025-07-27 17:17:53,751 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 220 | Avg Loss: 2.0731 | Accuracy: 0.4238\n",
      "2025-07-27 17:17:54,259 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 230 | Avg Loss: 2.1190 | Accuracy: 0.4237\n",
      "2025-07-27 17:17:54,819 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 240 | Avg Loss: 2.0939 | Accuracy: 0.4243\n",
      "2025-07-27 17:17:55,325 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 250 | Avg Loss: 2.1110 | Accuracy: 0.4247\n",
      "2025-07-27 17:17:55,834 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 260 | Avg Loss: 2.0693 | Accuracy: 0.4258\n",
      "2025-07-27 17:17:56,337 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 270 | Avg Loss: 2.1339 | Accuracy: 0.4256\n",
      "2025-07-27 17:17:56,844 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 280 | Avg Loss: 2.1809 | Accuracy: 0.4255\n",
      "2025-07-27 17:17:57,349 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 290 | Avg Loss: 2.1157 | Accuracy: 0.4262\n",
      "2025-07-27 17:17:57,855 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 300 | Avg Loss: 2.0254 | Accuracy: 0.4265\n",
      "2025-07-27 17:17:58,363 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 310 | Avg Loss: 2.1286 | Accuracy: 0.4270\n",
      "2025-07-27 17:17:58,916 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 320 | Avg Loss: 2.1615 | Accuracy: 0.4271\n",
      "2025-07-27 17:17:59,484 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 330 | Avg Loss: 2.1464 | Accuracy: 0.4273\n",
      "2025-07-27 17:18:00,075 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 340 | Avg Loss: 2.1158 | Accuracy: 0.4276\n",
      "2025-07-27 17:18:00,682 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 350 | Avg Loss: 2.1166 | Accuracy: 0.4275\n",
      "2025-07-27 17:18:01,314 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 360 | Avg Loss: 2.1580 | Accuracy: 0.4271\n",
      "2025-07-27 17:18:01,962 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 370 | Avg Loss: 2.1345 | Accuracy: 0.4276\n",
      "2025-07-27 17:18:02,634 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 380 | Avg Loss: 2.0580 | Accuracy: 0.4280\n",
      "2025-07-27 17:18:03,307 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 390 | Avg Loss: 2.0674 | Accuracy: 0.4288\n",
      "2025-07-27 17:18:03,358 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 completed - Loss: 2.1415, Accuracy: 0.4288\n",
      "2025-07-27 17:18:10,186 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11912', 'new_value': '0.42878'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009970732000139024', 'new_value': '0.050535901983579'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '4'}]' for run ID='ec892d7e077545d0bc2aa9012811b37c'.\n",
      "2025-07-27 17:18:10,186 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.4288\n",
      "Epoch 4/5: Loss: 2.1415 | Acc: 0.4288 | Time: 95.1s | LR: 3.00e-03 | Memory: 80.8%\n",
      "2025-07-27 17:18:10,187 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 5, total batches: 391\n",
      "2025-07-27 17:18:10,727 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 10 | Avg Loss: 2.0359 | Accuracy: 0.4578\n",
      "2025-07-27 17:18:11,232 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 20 | Avg Loss: 2.0322 | Accuracy: 0.4523\n",
      "2025-07-27 17:18:11,735 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 30 | Avg Loss: 2.0222 | Accuracy: 0.4526\n",
      "2025-07-27 17:18:12,252 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 40 | Avg Loss: 1.9204 | Accuracy: 0.4586\n",
      "2025-07-27 17:18:12,759 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 50 | Avg Loss: 2.0288 | Accuracy: 0.4547\n",
      "2025-07-27 17:18:13,322 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 60 | Avg Loss: 1.9653 | Accuracy: 0.4574\n",
      "2025-07-27 17:18:13,885 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 70 | Avg Loss: 2.0180 | Accuracy: 0.4579\n",
      "2025-07-27 17:18:14,446 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 80 | Avg Loss: 2.0288 | Accuracy: 0.4586\n",
      "2025-07-27 17:18:14,999 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 90 | Avg Loss: 2.0236 | Accuracy: 0.4580\n",
      "2025-07-27 17:18:15,606 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 100 | Avg Loss: 2.0129 | Accuracy: 0.4575\n",
      "2025-07-27 17:18:16,128 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 110 | Avg Loss: 2.0679 | Accuracy: 0.4566\n",
      "2025-07-27 17:18:16,636 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 120 | Avg Loss: 1.9854 | Accuracy: 0.4577\n",
      "2025-07-27 17:18:17,144 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 130 | Avg Loss: 1.9841 | Accuracy: 0.4582\n",
      "2025-07-27 17:18:17,653 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 140 | Avg Loss: 1.9723 | Accuracy: 0.4588\n",
      "2025-07-27 17:18:18,180 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 150 | Avg Loss: 1.9690 | Accuracy: 0.4586\n",
      "2025-07-27 17:18:18,691 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 160 | Avg Loss: 2.1062 | Accuracy: 0.4577\n",
      "2025-07-27 17:18:19,211 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 170 | Avg Loss: 2.0122 | Accuracy: 0.4566\n",
      "2025-07-27 17:18:19,719 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 180 | Avg Loss: 2.0106 | Accuracy: 0.4571\n",
      "2025-07-27 17:18:20,228 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 190 | Avg Loss: 1.9397 | Accuracy: 0.4589\n",
      "2025-07-27 17:18:20,767 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 200 | Avg Loss: 1.9285 | Accuracy: 0.4605\n",
      "2025-07-27 17:18:21,300 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 210 | Avg Loss: 1.9372 | Accuracy: 0.4617\n",
      "2025-07-27 17:18:22,078 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 220 | Avg Loss: 1.9229 | Accuracy: 0.4629\n",
      "2025-07-27 17:18:22,594 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 230 | Avg Loss: 2.0127 | Accuracy: 0.4630\n",
      "2025-07-27 17:18:23,096 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 240 | Avg Loss: 1.9307 | Accuracy: 0.4630\n",
      "2025-07-27 17:18:23,605 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 250 | Avg Loss: 1.9461 | Accuracy: 0.4636\n",
      "2025-07-27 17:18:24,107 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 260 | Avg Loss: 1.8592 | Accuracy: 0.4642\n",
      "2025-07-27 17:18:24,611 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 270 | Avg Loss: 1.9639 | Accuracy: 0.4640\n",
      "2025-07-27 17:18:25,112 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 280 | Avg Loss: 1.9337 | Accuracy: 0.4642\n",
      "2025-07-27 17:18:25,613 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 290 | Avg Loss: 1.9852 | Accuracy: 0.4642\n",
      "2025-07-27 17:18:26,113 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 300 | Avg Loss: 1.9828 | Accuracy: 0.4641\n",
      "2025-07-27 17:18:26,667 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 310 | Avg Loss: 1.9833 | Accuracy: 0.4640\n",
      "2025-07-27 17:18:27,226 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 320 | Avg Loss: 2.0093 | Accuracy: 0.4642\n",
      "2025-07-27 17:18:27,814 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 330 | Avg Loss: 1.9680 | Accuracy: 0.4640\n",
      "2025-07-27 17:18:28,431 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 340 | Avg Loss: 1.9244 | Accuracy: 0.4644\n",
      "2025-07-27 17:18:29,055 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 350 | Avg Loss: 2.0123 | Accuracy: 0.4642\n",
      "2025-07-27 17:18:29,690 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 360 | Avg Loss: 1.8777 | Accuracy: 0.4650\n",
      "2025-07-27 17:18:30,350 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 370 | Avg Loss: 2.0130 | Accuracy: 0.4650\n",
      "2025-07-27 17:18:31,016 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 380 | Avg Loss: 1.9381 | Accuracy: 0.4654\n",
      "2025-07-27 17:18:31,686 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 390 | Avg Loss: 1.9892 | Accuracy: 0.4654\n",
      "2025-07-27 17:18:31,734 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 completed - Loss: 1.9802, Accuracy: 0.4655\n",
      "2025-07-27 17:18:33,189 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11912', 'new_value': '0.46548'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009970732000139024', 'new_value': '0.05693570117155711'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '5'}]' for run ID='ec892d7e077545d0bc2aa9012811b37c'.\n",
      "2025-07-27 17:18:33,190 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.4655\n",
      "Epoch 5/5: Loss: 1.9802 | Acc: 0.4655 | Time: 28.4s | LR: 3.00e-03 | Memory: 79.9%\n",
      "🏃 View run 20250727_171510 at: https://neuralripper.com/mlflow/#/experiments/1/runs/ec892d7e077545d0bc2aa9012811b37c\n",
      "🧪 View experiment at: https://neuralripper.com/mlflow/#/experiments/1\n",
      "2025-07-27 17:18:33,768 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Training completed. Summary: {'final_total_training_time_minutes': 3.42, 'final_best_accuracy': 0.46548, 'final_epochs_completed': 5}\n",
      "\n",
      "Training Summary:\n",
      "Total time: 3.4 minutes\n",
      "Best accuracy: 0.4655\n",
      "Epochs completed: 5\n"
     ]
    }
   ],
   "source": [
    "# Start training with comprehensive monitoring\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" STARTING ENHANCED MOBILENETV2 TRAINING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset: CIFAR-100 (100 classes)\")\n",
    "print(f\"Model: MobileNetV2 (pretrained)\")\n",
    "print(f\"Epochs: {model._num_epochs}\")\n",
    "print(f\"Batch size: {model._batch_size}\")\n",
    "print(f\"Learning rate: {model._learning_rate}\")\n",
    "print(f\"MLflow tracking: {'Enabled' if model._use_mlflow else 'Disabled'}\")\n",
    "print(f\"MLflow URI: {model.monitor.mlflow_uri}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Start training\n",
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3TvvXzbBz7Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMYZDW3c+maUFI63troF8xy",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ripper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
