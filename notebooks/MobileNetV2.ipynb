{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wCF70rRvASrn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(31643) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (3.1.1)\n",
      "Requirement already satisfied: thop in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torchvision in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (0.22.1)\n",
      "Requirement already satisfied: mlflow-skinny==3.1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: Flask<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.16.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.10.3)\n",
      "Requirement already satisfied: numpy<3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.2.6)\n",
      "Requirement already satisfied: pandas<3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.3.0)\n",
      "Requirement already satisfied: pyarrow<21,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (20.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.7.0)\n",
      "Requirement already satisfied: scipy<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.16.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.0.41)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.57.0)\n",
      "Requirement already satisfied: fastapi<1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.115.14)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (1.34.1)\n",
      "Requirement already satisfied: packaging<26 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (25.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.1)\n",
      "Requirement already satisfied: uvicorn<1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.35.0)\n",
      "Requirement already satisfied: Mako in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.40.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.46.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.7.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (0.55b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n",
      "Requirement already satisfied: torch in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from thop) (2.7.1)\n",
      "Requirement already satisfied: filelock in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from torch->thop) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from torch->thop) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from torch->thop) (3.5)\n",
      "Requirement already satisfied: fsspec in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from torch->thop) (2025.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
      "PyTorch version: 2.7.1\n",
      "Torchvision version: 0.22.1\n",
      "MLflow version: 3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow thop torchvision\n",
    "# Core imports and setup\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import numpy as np\n",
    "import psutil\n",
    "import platform\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from thop import profile\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1751928801664,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "eOnj5Ur9AVQi",
    "outputId": "4458cdf1-6416-4cf7-8bb5-54a7a4cff30d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 20:34:56,412 - DEBUG - 1078719332.py - PID:26817 - TID:8462606080 - Logger initialization completed\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "format_str = '%(asctime)s - %(levelname)s - %(filename)s - PID:%(process)d - TID:%(thread)d - %(message)s'\n",
    "logger = logging.getLogger(__name__ + str(time.time()))\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = False\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(logging.Formatter(format_str))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.debug(\"Logger initialization completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ObMPtBTFA8Z5"
   },
   "outputs": [],
   "source": [
    "class ComprehensiveTrainingMonitor:\n",
    "    \"\"\"Advanced training monitor with complete metrics tracking for MLflow\"\"\"\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device, model_name, dataset_name,\n",
    "                 batch_size=32, epochs=10, input_size=(3, 32, 32),\n",
    "                 mlflow_uri=\"https://neuralripper.com/mlflow/\",\n",
    "                 use_mlflow=True, **kwargs):\n",
    "        # Core components\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        # Training parameters\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.input_size = input_size\n",
    "        self.mlflow_uri = mlflow_uri\n",
    "        self.use_mlflow = use_mlflow\n",
    "\n",
    "        # Auto-extracted parameters\n",
    "        self.lr = optimizer.param_groups[0]['lr']\n",
    "        self.optimizer_name = optimizer.__class__.__name__\n",
    "        self.loss_name = criterion.__class__.__name__\n",
    "        self.weight_decay = optimizer.param_groups[0].get('weight_decay', 0)\n",
    "        self.momentum = optimizer.param_groups[0].get('momentum', 0)\n",
    "\n",
    "        # Training state\n",
    "        self.start_time = time.time()\n",
    "        self.epoch_times = []\n",
    "        self.best_metric = -1\n",
    "        self.prev_loss = None\n",
    "        self.batch_times = []\n",
    "        self.run_started = False  # Track run state\n",
    "\n",
    "        # Optional parameters\n",
    "        self.train_size = kwargs.get('train_size', 0)\n",
    "        self.val_size = kwargs.get('val_size', 0)\n",
    "        self.num_workers = kwargs.get('num_workers', 0)\n",
    "        self.use_pretrained = kwargs.get('use_pretrained', False)\n",
    "        self.random_seed = kwargs.get('random_seed', 42)\n",
    "\n",
    "        self.run_id = None  # Mlflow current run id\n",
    "\n",
    "    def setup_mlflow(self):\n",
    "        \"\"\"Setup MLflow with comprehensive parameter logging\"\"\"\n",
    "        if not self.use_mlflow or self.run_started:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Ensure any existing run is ended\n",
    "            if mlflow.active_run():\n",
    "                mlflow.end_run()\n",
    "\n",
    "            # Configure MLflow client\n",
    "            mlflow.set_tracking_uri(self.mlflow_uri)\n",
    "            mlflow.set_experiment(f\"{self.model_name}-{self.dataset_name}\")\n",
    "\n",
    "            # Start single run\n",
    "            run_name = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            mlflow.start_run(run_name=run_name)\n",
    "            self.run_id = run_name\n",
    "            self.run_started = True\n",
    "\n",
    "            # Log comprehensive parameters\n",
    "            all_params = {\n",
    "                **self._get_core_params(),\n",
    "                **self._get_model_params(),\n",
    "                **self._get_system_params(),\n",
    "                **self._get_environment_params(),\n",
    "                **self._get_data_params(),\n",
    "                **self._get_training_params(),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(all_params)\n",
    "            logger.info(f\"MLflow tracking initialized: {self.mlflow_uri}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"MLflow setup failed: {e}\")\n",
    "            self.use_mlflow = False\n",
    "\n",
    "    def _get_core_params(self):\n",
    "        \"\"\"Core training parameters\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"dataset_name\": self.dataset_name,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"learning_rate\": self.lr,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"optimizer\": self.optimizer_name,\n",
    "            \"loss_function\": self.loss_name,\n",
    "            \"device\": str(self.device),\n",
    "            \"random_seed\": self.random_seed,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"momentum\": self.momentum,\n",
    "        }\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Model architecture parameters\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "        # Model size calculation\n",
    "        param_size = sum(p.numel() * p.element_size() for p in self.model.parameters())\n",
    "        buffer_size = sum(b.numel() * b.element_size() for b in self.model.buffers())\n",
    "        model_size_mb = (param_size + buffer_size) / (1024 ** 2)\n",
    "\n",
    "        # FLOPs calculation\n",
    "        flops_m = 0\n",
    "        try:\n",
    "            sample_input = torch.randn(1, *self.input_size)\n",
    "            flops, _ = profile(self.model, inputs=(sample_input,), verbose=False)\n",
    "            flops_m = round(flops / 1e6, 2)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"FLOPs calculation failed: {e}\")\n",
    "\n",
    "        return {\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"parameters_millions\": round(total_params / 1e6, 2),\n",
    "            \"model_size_mb\": round(model_size_mb, 2),\n",
    "            \"flops_millions\": flops_m,\n",
    "            \"input_size\": str(self.input_size),\n",
    "            \"use_pretrained\": self.use_pretrained,\n",
    "            \"model_architecture\": self.model.__class__.__name__,\n",
    "        }\n",
    "\n",
    "    def _get_system_params(self):\n",
    "        \"\"\"System and hardware parameters\"\"\"\n",
    "        gpu_info = {}\n",
    "        if torch.cuda.is_available():\n",
    "            props = torch.cuda.get_device_properties(0)\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": torch.cuda.get_device_name(0),\n",
    "                \"gpu_memory_gb\": round(props.total_memory / (1024**3), 2),\n",
    "                \"cuda_version\": torch.version.cuda,\n",
    "                \"num_gpus\": torch.cuda.device_count(),\n",
    "            }\n",
    "        elif torch.backends.mps.is_available():\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": \"Apple Silicon MPS\",\n",
    "                \"device_type\": \"mps\"\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"cpu_count\": psutil.cpu_count(),\n",
    "            \"memory_total_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"python_version\": platform.python_version(),\n",
    "            \"pytorch_version\": torch.__version__,\n",
    "            **gpu_info\n",
    "        }\n",
    "\n",
    "    def _get_environment_params(self):\n",
    "        \"\"\"Environment and reproducibility parameters\"\"\"\n",
    "        git_info = {}\n",
    "        try:\n",
    "            commit = subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip()\n",
    "            branch = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD']).decode().strip()\n",
    "            git_info = {\n",
    "                \"git_commit\": commit[:8],\n",
    "                \"git_branch\": branch,\n",
    "            }\n",
    "        except:\n",
    "            git_info = {\"git_commit\": \"unknown\", \"git_branch\": \"unknown\"}\n",
    "\n",
    "        return git_info\n",
    "\n",
    "    def _get_data_params(self):\n",
    "        \"\"\"Data pipeline parameters\"\"\"\n",
    "        return {\n",
    "            \"train_size\": self.train_size,\n",
    "            \"val_size\": self.val_size,\n",
    "            \"total_samples\": self.train_size + self.val_size,\n",
    "            \"num_workers\": self.num_workers,\n",
    "        }\n",
    "\n",
    "    def _get_training_params(self):\n",
    "        \"\"\"Advanced training configuration\"\"\"\n",
    "        return {\n",
    "            \"mlflow_uri\": self.mlflow_uri,\n",
    "            \"experiment_name\": f\"{self.model_name}-{self.dataset_name}\",\n",
    "        }\n",
    "\n",
    "    def log_epoch_metrics(self, epoch, epoch_loss, epoch_acc, batch_count=None):\n",
    "        \"\"\"Comprehensive epoch metrics logging\"\"\"\n",
    "        if not self.use_mlflow or not self.run_started:\n",
    "            return {}\n",
    "\n",
    "        try:\n",
    "            current_time = time.time()\n",
    "\n",
    "            # Timing metrics\n",
    "            epoch_time = current_time - (self.start_time if epoch == 0 else self.start_time + sum(self.epoch_times))\n",
    "            self.epoch_times.append(epoch_time)\n",
    "\n",
    "            # Core metrics\n",
    "            metrics = {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": epoch_loss,\n",
    "                \"train_accuracy\": epoch_acc,\n",
    "                \"learning_rate\": self.optimizer.param_groups[0][\"lr\"],\n",
    "                \"epoch_time_seconds\": epoch_time,\n",
    "                \"total_time_seconds\": current_time - self.start_time,\n",
    "                \"avg_epoch_time\": sum(self.epoch_times) / len(self.epoch_times),\n",
    "            }\n",
    "\n",
    "            # Training dynamics\n",
    "            if self.prev_loss is not None:\n",
    "                loss_improvement = self.prev_loss - epoch_loss\n",
    "                metrics.update({\n",
    "                    \"loss_improvement\": loss_improvement,\n",
    "                    \"loss_improvement_percent\": (loss_improvement / self.prev_loss) * 100 if self.prev_loss != 0 else 0,\n",
    "                })\n",
    "            self.prev_loss = epoch_loss\n",
    "\n",
    "            # Performance metrics\n",
    "            if batch_count and epoch_time > 0:\n",
    "                samples_per_sec = (self.batch_size * batch_count) / epoch_time\n",
    "                metrics.update({\n",
    "                    \"batches_per_second\": batch_count / epoch_time,\n",
    "                    \"samples_per_second\": samples_per_sec,\n",
    "                })\n",
    "\n",
    "            # GPU/MPS metrics\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_metrics = self._get_gpu_metrics()\n",
    "                metrics.update(gpu_metrics)\n",
    "\n",
    "            # System metrics\n",
    "            system_metrics = self._get_system_metrics()\n",
    "            metrics.update(system_metrics)\n",
    "\n",
    "            mlflow.log_metrics(metrics, step=epoch)\n",
    "            return metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log epoch metrics: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _get_gpu_metrics(self):\n",
    "        \"\"\"GPU metrics for CUDA\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            return {}\n",
    "\n",
    "        allocated = torch.cuda.memory_allocated()\n",
    "        reserved = torch.cuda.memory_reserved()\n",
    "        total = torch.cuda.get_device_properties(0).total_memory\n",
    "\n",
    "        return {\n",
    "            \"gpu_memory_allocated_mb\": allocated / (1024**2),\n",
    "            \"gpu_memory_reserved_mb\": reserved / (1024**2),\n",
    "            \"gpu_memory_allocated_percent\": (allocated / total) * 100,\n",
    "            \"gpu_memory_reserved_percent\": (reserved / total) * 100,\n",
    "        }\n",
    "\n",
    "    def _get_system_metrics(self):\n",
    "        \"\"\"Real-time system resource utilization\"\"\"\n",
    "        cpu_percent = psutil.cpu_percent(interval=None)\n",
    "        memory = psutil.virtual_memory()\n",
    "\n",
    "        return {\n",
    "            \"cpu_percent\": cpu_percent,\n",
    "            \"memory_used_percent\": memory.percent,\n",
    "            \"memory_available_gb\": memory.available / (1024**3),\n",
    "        }\n",
    "\n",
    "    def should_log_model(self, current_metric, metric_name=\"accuracy\"):\n",
    "        \"\"\"Enhanced model checkpointing with improvement tracking\"\"\"\n",
    "        if current_metric > self.best_metric:\n",
    "            improvement = current_metric - self.best_metric\n",
    "            self.best_metric = current_metric\n",
    "\n",
    "            if self.use_mlflow and self.run_started:\n",
    "                try:\n",
    "                    mlflow.log_metrics({\n",
    "                        f\"best_{metric_name}\": current_metric,\n",
    "                        f\"{metric_name}_improvement\": improvement,\n",
    "                        \"checkpoint_epoch\": len(self.epoch_times),\n",
    "                    }, step=len(self.epoch_times))\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to log best model metrics: {e}\")\n",
    "\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def log_model_artifact(self, signature=None):\n",
    "        \"\"\"Log model with comprehensive metadata (metrics only, no artifacts)\"\"\"\n",
    "        if not self.use_mlflow or not self.run_started:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Log model metadata as parameters instead of artifacts to avoid GCS issues\n",
    "            model_metadata = {\n",
    "                \"best_model_architecture\": self.model.__class__.__name__,\n",
    "                \"best_model_accuracy\": self.best_metric,\n",
    "                \"best_model_training_time_hours\": (time.time() - self.start_time) / 3600,\n",
    "                \"best_model_epochs_trained\": len(self.epoch_times),\n",
    "                \"best_model_parameters_count\": sum(p.numel() for p in self.model.parameters()),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(model_metadata)\n",
    "            logger.info(f\"Model metadata logged for accuracy: {self.best_metric:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log model metadata: {e}\")\n",
    "\n",
    "    def end_run(self, status=\"FINISHED\"):\n",
    "        \"\"\"Clean up and end MLflow run\"\"\"\n",
    "        if self.use_mlflow and self.run_started:\n",
    "            try:\n",
    "                total_time = time.time() - self.start_time\n",
    "                summary = {\n",
    "                    \"final_total_training_time_minutes\": round(total_time / 60, 2),\n",
    "                    \"final_best_accuracy\": self.best_metric,\n",
    "                    \"final_epochs_completed\": len(self.epoch_times),\n",
    "                }\n",
    "                mlflow.log_params(summary)\n",
    "                mlflow.end_run(status=status)\n",
    "                self.run_started = False\n",
    "                return summary\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to end MLflow run properly: {e}\")\n",
    "                return {}\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import rerun as rr\n",
    "\n",
    "\n",
    "class RerunLogger:\n",
    "    def __init__(self, run_id: str, model_name:str, backend_url: str = \"http://localhost:8000\"):\n",
    "        self.run_id = run_id\n",
    "        self.model_name = model_name\n",
    "        self.backend_url = backend_url\n",
    "        self.gcs_bucket = \"neuralripper-mlflow-artifacts\"\n",
    "        self.viewer_url = None\n",
    "        self.internal_url = None\n",
    "        self.initialized = False\n",
    "    \n",
    "    def get_viewer_urls(self):\n",
    "        \"\"\"Get viewer URLs from backend\"\"\"\n",
    "        try:\n",
    "            res = requests.get(f\"{self.backend_url}/rerun/{self.run_id}/live\")\n",
    "            if res.status_code == 200:\n",
    "                data = res.json()\n",
    "                self.viewer_url = data[\"viewer_url\"]\n",
    "                self.internal_url = data[\"internal_url\"]\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get viewer URLs: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"Init rerun connection\"\"\"\n",
    "        if self.get_viewer_urls():\n",
    "            logger.debug(f\"internal_url: {self.internal_url}\")\n",
    "            logger.debug(f\"viewer_url: {self.viewer_url}\")\n",
    "\n",
    "            # Extract gRPC port from internal url, use for uploading recordings\n",
    "            grpc_port = self.internal_url.split(':')[-1]\n",
    "\n",
    "            # Init recording\n",
    "            rr.init(f\"{self.model_name}_{self.run_id}\", spawn=False)\n",
    "\n",
    "            # Connect to backend gRPC server(send the recordings data to backend so it can serve in viewer url)\n",
    "            rr.connect_grpc(f\"127.0.0.1:{grpc_port}\")\n",
    "            # rr.connect_grpc(grpc_port)\n",
    "            # rr.connect_grpc()\n",
    "\n",
    "            self.initialized = True\n",
    "            print(f\"Rerun live viewer: {self.viewer_url}\")\n",
    "            print(f\"Connected to gRPC: 127.0.0.1:{grpc_port}\")\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def log_training_step(self, epoch: int, step: int, loss: float, accuracy: float, \n",
    "                          lr: float, gpu_memory: dict = None, system_metrics: dict = None):\n",
    "        \"\"\"Log training metrics to rerun\"\"\"\n",
    "        if not self.initialized:\n",
    "            return\n",
    "            \n",
    "        rr.log(\"training/loss\", rr.Scalars(loss))\n",
    "        rr.log(\"training/accuracy\", rr.Scalars(accuracy))\n",
    "        rr.log(\"training/learning_rate\", rr.Scalars(lr))\n",
    "        rr.log(\"progress/epoch\", rr.Scalars(epoch))\n",
    "        rr.log(\"progress/step\", rr.Scalars(step))\n",
    "        \n",
    "        if gpu_memory:\n",
    "            rr.log(\"system/gpu_memory_mb\", rr.Scalars(gpu_memory.get('gpu_memory_allocated_mb', 0)))\n",
    "        if system_metrics:\n",
    "            rr.log(\"system/cpu_percent\", rr.Scalars(system_metrics.get('cpu_percent', 0)))\n",
    "            rr.log(\"system/memory_percent\", rr.Scalars(system_metrics.get('memory_used_percent', 0)))\n",
    "\n",
    "    def save_recording(self):\n",
    "        \"\"\"Save recording directly to GCS\"\"\"\n",
    "        if not self.initialized:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            gcs_path = f\"gs://{self.gcs_bucket}/rerun_recordings/{self.model_name}_{self.run_id}.rrd\"\n",
    "            rr.save(gcs_path)\n",
    "            print(f\"Recording saved: {gcs_path}\")\n",
    "            return gcs_path\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save recording: {e}\")\n",
    "            return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "P_kRN-fBA9Ve"
   },
   "outputs": [],
   "source": [
    "class EnhancedMobileNetV2:\n",
    "    \"\"\"MobileNetV2 with comprehensive monitoring integration\"\"\"\n",
    "\n",
    "    def __init__(self, num_epochs=10, batch_size=128, num_classes=100,\n",
    "                 learning_rate=5e-3, use_mlflow=True):\n",
    "        # Core parameters\n",
    "        self._num_classes = num_classes\n",
    "        self._use_mlflow = use_mlflow\n",
    "        self._batch_size = batch_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        # Create model components\n",
    "        self._model = self._create_model()\n",
    "        self._device = self._set_device()\n",
    "        self._model.to(self._device)\n",
    "        self._criterion = self._set_criterion()\n",
    "        self._optimizer = self._set_optimizer()\n",
    "\n",
    "        # Initialize comprehensive monitor\n",
    "        self.monitor = ComprehensiveTrainingMonitor(\n",
    "            model=self._model,\n",
    "            optimizer=self._optimizer,\n",
    "            criterion=self._criterion,\n",
    "            device=self._device,\n",
    "            model_name='MobileNetV2',\n",
    "            dataset_name='CIFAR-100',\n",
    "            batch_size=batch_size,\n",
    "            epochs=num_epochs,\n",
    "            input_size=(3, 32, 32),\n",
    "            use_mlflow=use_mlflow,\n",
    "            use_pretrained=True,\n",
    "            train_size=50000,\n",
    "            val_size=10000,\n",
    "            num_workers=0,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Model initialized on device: {self._device}\")\n",
    "        logger.info(f\"Model parameters: {sum(p.numel() for p in self._model.parameters()):,}\")\n",
    "\n",
    "        self.rerun_logger = None    # rerun logger will be init when training starts\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Create MobileNetV2 model with CIFAR-100 adaptation\"\"\"\n",
    "        model = torchvision.models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "        # Adapt classifier for CIFAR-100 (100 classes)\n",
    "        model.classifier[1] = nn.Linear(1280, self._num_classes)\n",
    "        return model\n",
    "\n",
    "    def _set_device(self):\n",
    "        \"\"\"Set appropriate device for training\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def _set_optimizer(self):\n",
    "        \"\"\"Configure SGD optimizer with momentum and weight decay\"\"\"\n",
    "        return optim.SGD(self._model.parameters(),\n",
    "                        lr=self._learning_rate,\n",
    "                        momentum=0.9,\n",
    "                        weight_decay=4e-5)\n",
    "\n",
    "    def _set_criterion(self):\n",
    "        \"\"\"Set loss function for classification\"\"\"\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    def train_epoch(self, data_loader, epoch_idx):\n",
    "        \"\"\"Enhanced training epoch with comprehensive monitoring\"\"\"\n",
    "        logger.info(f\"Starting epoch {epoch_idx+1}, total batches: {len(data_loader)}\")\n",
    "\n",
    "        self._model.train()\n",
    "        epoch_total_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "        batch_count = len(data_loader)\n",
    "\n",
    "        for idx, (images, targets) in enumerate(data_loader):\n",
    "            images = images.to(self._device)\n",
    "            targets = targets.to(self._device)\n",
    "\n",
    "            self._optimizer.zero_grad()\n",
    "            logits = self._model(images)\n",
    "            loss = self._criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            running_correct += (predictions == targets).sum().item()\n",
    "            running_total += targets.size(0)\n",
    "            running_loss += loss.item()\n",
    "            epoch_total_loss += loss.item()\n",
    "\n",
    "            # Progress logging every 10 batches\n",
    "            if idx % 10 == 9:\n",
    "                avg_loss = running_loss / 10\n",
    "                curr_acc = running_correct / running_total\n",
    "                logger.info(f\"Epoch {epoch_idx + 1} | Batch {idx + 1} | \"\n",
    "                          f\"Avg Loss: {avg_loss:.4f} | Accuracy: {curr_acc:.4f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "                # Rerun loggings\n",
    "                if self.rerun_logger:\n",
    "                    gpu_metrics = self.monitor._get_gpu_metrics()\n",
    "                    sys_metrics = self.monitor._get_system_metrics()\n",
    "\n",
    "                    self.rerun_logger.log_training_step(\n",
    "                        epoch=epoch_idx,\n",
    "                        step=(epoch_idx * len(data_loader)) + idx,\n",
    "                        loss=avg_loss,\n",
    "                        accuracy=curr_acc,\n",
    "                        lr=self._optimizer.param_groups[0]['lr'],\n",
    "                        gpu_memory=gpu_metrics,\n",
    "                        system_metrics=sys_metrics\n",
    "                    )\n",
    "\n",
    "\n",
    "        epoch_loss = epoch_total_loss / batch_count\n",
    "        epoch_acc = running_correct / running_total\n",
    "\n",
    "        logger.info(f\"Epoch {epoch_idx + 1} completed - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "        return epoch_loss, epoch_acc, batch_count\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        \"\"\"Enhanced training with comprehensive monitoring\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Starting training for {self._num_epochs} epochs on {self._device}\")\n",
    "\n",
    "            # Setup MLflow once at the beginning\n",
    "            self.monitor.setup_mlflow()\n",
    "\n",
    "            # Init RerunLogger\n",
    "            if self.monitor.run_id:\n",
    "                self.rerun_logger = RerunLogger(self.monitor.run_id, \"MobileNetV2\")\n",
    "                self.rerun_logger.initialize()\n",
    "\n",
    "            for epoch in range(self._num_epochs):\n",
    "                epoch_loss, epoch_acc, batch_count = self.train_epoch(train_loader, epoch)\n",
    "\n",
    "                # Log comprehensive epoch metrics\n",
    "                metrics = self.monitor.log_epoch_metrics(epoch, epoch_loss, epoch_acc, batch_count)\n",
    "\n",
    "                # Model checkpointing for best performance (metadata only)\n",
    "                if self.monitor.should_log_model(epoch_acc):\n",
    "                    self.monitor.log_model_artifact()\n",
    "                    logger.info(f\"New best model metadata saved with accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "                # Enhanced progress display\n",
    "                print(f\"Epoch {epoch+1}/{self._num_epochs}: \"\n",
    "                      f\"Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | \"\n",
    "                      f\"Time: {metrics.get('epoch_time_seconds', 0):.1f}s | \"\n",
    "                      f\"LR: {metrics.get('learning_rate', 0):.2e} | \"\n",
    "                      f\"Memory: {metrics.get('memory_used_percent', 0):.1f}%\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training failed: {e}\")\n",
    "            self.monitor.end_run(status=\"FAILED\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Save rerun recording after training\n",
    "            if self.rerun_logger:\n",
    "                self.rerun_logger.save_recording()\n",
    "\n",
    "            summary = self.monitor.end_run()\n",
    "            logger.info(f\"Training completed. Summary: {summary}\")\n",
    "            print(f\"\\nTraining Summary:\")\n",
    "            print(f\"Total time: {summary.get('final_total_training_time_minutes', 0):.1f} minutes\")\n",
    "            print(f\"Best accuracy: {summary.get('final_best_accuracy', 0):.4f}\")\n",
    "            print(f\"Epochs completed: {summary.get('final_epochs_completed', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11683,
     "status": "ok",
     "timestamp": 1751928813456,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "rUkj617FBnqH",
    "outputId": "55448d5e-64b9-4cdc-d046-816cda95c31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Number of classes: 100\n",
      "Class names (first 10): ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']\n",
      "Subset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Data transforms for CIFAR-100\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Data augmentation\n",
    "    transforms.RandomHorizontalFlip(0.5),   # Random horizontal flip\n",
    "    transforms.ToTensor(),                  # Convert to tensor\n",
    "    transforms.Normalize(                   # Normalize with ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "train_ds = datasets.CIFAR100(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_tf\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# only use first 10000 images for local training\n",
    "train_subset = Subset(train_ds, range(10000))\n",
    "\n",
    "print(f\"Training dataset size: {len(train_ds)}\")\n",
    "print(f\"Number of classes: {len(train_ds.classes)}\")\n",
    "print(f\"Class names (first 10): {train_ds.classes[:10]}\")\n",
    "print(f\"Subset size: {len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Bll8T_8uBEc_"
   },
   "outputs": [],
   "source": [
    "# Optional: Visualize a sample of the data\n",
    "def visualize_samples(dataset, num_samples=16):\n",
    "    \"\"\"Visualize a sample of images from the dataset\"\"\"\n",
    "    # Create subset for visualization\n",
    "    sample_indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img_tensor, class_idx = dataset[idx]\n",
    "\n",
    "        # Denormalize image for display\n",
    "        img = img_tensor.permute(1, 2, 0)\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Class: {dataset.classes[class_idx]}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to visualize samples\n",
    "# visualize_samples(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1751928813518,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "wDN0WcGZBFLy",
    "outputId": "4d82f86c-3795-41ac-bcec-973b28770326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per epoch: 391\n",
      "Total samples per epoch: 50048\n"
     ]
    }
   ],
   "source": [
    "# Create data loader\n",
    "train_loader = DataLoader(\n",
    "    # train_subset,       # subset for local test, change to original ds for production\n",
    "    train_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,      # Set to 0 for MPS compatibility\n",
    "    pin_memory=False    # Disable for MPS\n",
    ")\n",
    "\n",
    "print(f\"Number of batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Total samples per epoch: {len(train_loader) * 128}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 866,
     "status": "ok",
     "timestamp": 1751928814386,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "i-3WhL4dBGlf",
    "outputId": "d6eaf687-a862-4a30-b913-0f39bd0dade8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 20:35:11,897 - INFO - 4209569591.py - PID:26817 - TID:8462606080 - Initializing Enhanced MobileNetV2 model\n",
      "2025-08-02 20:35:12,479 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Model initialized on device: mps\n",
      "2025-08-02 20:35:12,480 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Model parameters: 2,351,972\n",
      "Model initialized successfully!\n",
      "Device: mps\n",
      "Total parameters: 2,351,972\n",
      "Trainable parameters: 2,351,972\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "logger.info(\"Initializing Enhanced MobileNetV2 model\")\n",
    "\n",
    "model = EnhancedMobileNetV2(\n",
    "    num_epochs=10,\n",
    "    batch_size=128,\n",
    "    num_classes=100,\n",
    "    learning_rate=3e-3,\n",
    "    use_mlflow=True\n",
    ")\n",
    "\n",
    "print(\"Model initialized successfully!\")\n",
    "print(f\"Device: {model._device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model._model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model._model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JC5fvLRjBH8C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " STARTING ENHANCED MOBILENETV2 TRAINING\n",
      "==================================================\n",
      "Dataset: CIFAR-100 (100 classes)\n",
      "Model: MobileNetV2 (pretrained)\n",
      "Epochs: 10\n",
      "Batch size: 128\n",
      "Learning rate: 0.003\n",
      "MLflow tracking: Enabled\n",
      "MLflow URI: https://neuralripper.com/mlflow/\n",
      "==================================================\n",
      "\n",
      "2025-08-02 20:35:20,372 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting training for 10 epochs on mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/02 20:35:21 INFO mlflow.tracking.fluent: Experiment with name 'MobileNetV2-CIFAR-100' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 20:35:21,274 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - FLOPs calculation failed: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(31768) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 20:35:21,372 - INFO - 1236875293.py - PID:26817 - TID:8462606080 - MLflow tracking initialized: https://neuralripper.com/mlflow/\n",
      "2025-08-02 20:35:21,397 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 1, total batches: 391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(31769) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 20:35:23,004 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 10 | Avg Loss: 4.6834 | Accuracy: 0.0063\n",
      "2025-08-02 20:35:23,510 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 20 | Avg Loss: 4.6646 | Accuracy: 0.0066\n",
      "2025-08-02 20:35:24,014 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 30 | Avg Loss: 4.6241 | Accuracy: 0.0089\n",
      "2025-08-02 20:35:24,521 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 40 | Avg Loss: 4.5996 | Accuracy: 0.0115\n",
      "2025-08-02 20:35:25,024 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 50 | Avg Loss: 4.5811 | Accuracy: 0.0152\n",
      "2025-08-02 20:35:25,529 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 60 | Avg Loss: 4.5382 | Accuracy: 0.0187\n",
      "2025-08-02 20:35:26,032 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 70 | Avg Loss: 4.5073 | Accuracy: 0.0217\n",
      "2025-08-02 20:35:26,633 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 80 | Avg Loss: 4.4856 | Accuracy: 0.0243\n",
      "2025-08-02 20:35:27,230 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 90 | Avg Loss: 4.4699 | Accuracy: 0.0264\n",
      "2025-08-02 20:35:28,091 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 100 | Avg Loss: 4.3691 | Accuracy: 0.0305\n",
      "2025-08-02 20:35:28,899 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 110 | Avg Loss: 4.3456 | Accuracy: 0.0339\n",
      "2025-08-02 20:35:29,432 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 120 | Avg Loss: 4.2924 | Accuracy: 0.0378\n",
      "2025-08-02 20:35:30,038 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 130 | Avg Loss: 4.2130 | Accuracy: 0.0422\n",
      "2025-08-02 20:35:30,622 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 140 | Avg Loss: 4.2049 | Accuracy: 0.0457\n",
      "2025-08-02 20:35:31,192 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 150 | Avg Loss: 4.1589 | Accuracy: 0.0483\n",
      "2025-08-02 20:35:31,752 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 160 | Avg Loss: 4.1524 | Accuracy: 0.0507\n",
      "2025-08-02 20:35:32,354 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 170 | Avg Loss: 4.0649 | Accuracy: 0.0538\n",
      "2025-08-02 20:35:32,921 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 180 | Avg Loss: 4.0541 | Accuracy: 0.0570\n",
      "2025-08-02 20:35:33,426 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 190 | Avg Loss: 4.0318 | Accuracy: 0.0597\n",
      "2025-08-02 20:35:33,933 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 200 | Avg Loss: 3.9863 | Accuracy: 0.0628\n",
      "2025-08-02 20:35:34,440 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 210 | Avg Loss: 3.8987 | Accuracy: 0.0668\n",
      "2025-08-02 20:35:35,066 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 220 | Avg Loss: 3.9101 | Accuracy: 0.0699\n",
      "2025-08-02 20:35:35,840 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 230 | Avg Loss: 3.8693 | Accuracy: 0.0728\n",
      "2025-08-02 20:35:36,704 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 240 | Avg Loss: 3.7973 | Accuracy: 0.0754\n",
      "2025-08-02 20:35:37,332 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 250 | Avg Loss: 3.8236 | Accuracy: 0.0783\n",
      "2025-08-02 20:35:37,888 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 260 | Avg Loss: 3.7669 | Accuracy: 0.0812\n",
      "2025-08-02 20:35:38,403 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 270 | Avg Loss: 3.6850 | Accuracy: 0.0848\n",
      "2025-08-02 20:35:39,055 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 280 | Avg Loss: 3.6998 | Accuracy: 0.0872\n",
      "2025-08-02 20:35:39,682 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 290 | Avg Loss: 3.6531 | Accuracy: 0.0897\n",
      "2025-08-02 20:35:40,260 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 300 | Avg Loss: 3.6904 | Accuracy: 0.0925\n",
      "2025-08-02 20:35:40,795 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 310 | Avg Loss: 3.6249 | Accuracy: 0.0954\n",
      "2025-08-02 20:35:41,316 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 320 | Avg Loss: 3.5336 | Accuracy: 0.0981\n",
      "2025-08-02 20:35:41,828 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 330 | Avg Loss: 3.5514 | Accuracy: 0.1005\n",
      "2025-08-02 20:35:42,334 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 340 | Avg Loss: 3.4356 | Accuracy: 0.1035\n",
      "2025-08-02 20:35:42,955 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 350 | Avg Loss: 3.4756 | Accuracy: 0.1065\n",
      "2025-08-02 20:35:43,622 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 360 | Avg Loss: 3.4728 | Accuracy: 0.1089\n",
      "2025-08-02 20:35:44,338 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 370 | Avg Loss: 3.4477 | Accuracy: 0.1114\n",
      "2025-08-02 20:35:45,083 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 380 | Avg Loss: 3.4000 | Accuracy: 0.1138\n",
      "2025-08-02 20:35:45,905 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 | Batch 390 | Avg Loss: 3.3401 | Accuracy: 0.1161\n",
      "2025-08-02 20:35:46,045 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 1 completed - Loss: 4.0015, Accuracy: 0.1163\n",
      "2025-08-02 20:35:46,590 - INFO - 1236875293.py - PID:26817 - TID:8462606080 - Model metadata logged for accuracy: 0.1163\n",
      "2025-08-02 20:35:46,591 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.1163\n",
      "Epoch 1/10: Loss: 4.0015 | Acc: 0.1163 | Time: 33.6s | LR: 3.00e-03 | Memory: 81.3%\n",
      "2025-08-02 20:35:46,592 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 2, total batches: 391\n",
      "2025-08-02 20:35:47,128 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 10 | Avg Loss: 3.3469 | Accuracy: 0.2180\n",
      "2025-08-02 20:35:47,670 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 20 | Avg Loss: 3.3026 | Accuracy: 0.2156\n",
      "2025-08-02 20:35:48,174 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 30 | Avg Loss: 3.2540 | Accuracy: 0.2250\n",
      "2025-08-02 20:35:48,674 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 40 | Avg Loss: 3.2471 | Accuracy: 0.2271\n",
      "2025-08-02 20:35:49,207 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 50 | Avg Loss: 3.2952 | Accuracy: 0.2261\n",
      "2025-08-02 20:35:49,705 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 60 | Avg Loss: 3.1595 | Accuracy: 0.2303\n",
      "2025-08-02 20:35:50,232 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 70 | Avg Loss: 3.1976 | Accuracy: 0.2316\n",
      "2025-08-02 20:35:50,740 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 80 | Avg Loss: 3.1542 | Accuracy: 0.2323\n",
      "2025-08-02 20:35:51,238 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 90 | Avg Loss: 3.1005 | Accuracy: 0.2342\n",
      "2025-08-02 20:35:51,770 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 100 | Avg Loss: 3.0662 | Accuracy: 0.2373\n",
      "2025-08-02 20:35:52,279 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 110 | Avg Loss: 2.9743 | Accuracy: 0.2409\n",
      "2025-08-02 20:35:52,780 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 120 | Avg Loss: 3.0621 | Accuracy: 0.2427\n",
      "2025-08-02 20:35:53,306 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 130 | Avg Loss: 3.0324 | Accuracy: 0.2444\n",
      "2025-08-02 20:35:53,806 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 140 | Avg Loss: 3.0840 | Accuracy: 0.2450\n",
      "2025-08-02 20:35:54,305 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 150 | Avg Loss: 2.9686 | Accuracy: 0.2467\n",
      "2025-08-02 20:35:54,830 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 160 | Avg Loss: 2.9281 | Accuracy: 0.2491\n",
      "2025-08-02 20:35:55,332 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 170 | Avg Loss: 2.9633 | Accuracy: 0.2505\n",
      "2025-08-02 20:35:55,859 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 180 | Avg Loss: 2.9029 | Accuracy: 0.2522\n",
      "2025-08-02 20:35:56,363 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 190 | Avg Loss: 2.8678 | Accuracy: 0.2539\n",
      "2025-08-02 20:35:56,863 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 200 | Avg Loss: 2.8824 | Accuracy: 0.2562\n",
      "2025-08-02 20:35:57,373 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 210 | Avg Loss: 2.9327 | Accuracy: 0.2582\n",
      "2025-08-02 20:35:57,897 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 220 | Avg Loss: 2.9211 | Accuracy: 0.2592\n",
      "2025-08-02 20:35:58,399 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 230 | Avg Loss: 2.8564 | Accuracy: 0.2606\n",
      "2025-08-02 20:35:58,922 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 240 | Avg Loss: 2.8905 | Accuracy: 0.2621\n",
      "2025-08-02 20:35:59,436 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 250 | Avg Loss: 2.8656 | Accuracy: 0.2639\n",
      "2025-08-02 20:35:59,942 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 260 | Avg Loss: 2.8046 | Accuracy: 0.2656\n",
      "2025-08-02 20:36:00,463 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 270 | Avg Loss: 2.7461 | Accuracy: 0.2676\n",
      "2025-08-02 20:36:00,986 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 280 | Avg Loss: 2.8208 | Accuracy: 0.2688\n",
      "2025-08-02 20:36:01,493 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 290 | Avg Loss: 2.7870 | Accuracy: 0.2696\n",
      "2025-08-02 20:36:01,999 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 300 | Avg Loss: 2.8215 | Accuracy: 0.2707\n",
      "2025-08-02 20:36:02,521 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 310 | Avg Loss: 2.8142 | Accuracy: 0.2717\n",
      "2025-08-02 20:36:03,026 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 320 | Avg Loss: 2.7428 | Accuracy: 0.2731\n",
      "2025-08-02 20:36:03,557 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 330 | Avg Loss: 2.7676 | Accuracy: 0.2739\n",
      "2025-08-02 20:36:04,063 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 340 | Avg Loss: 2.7461 | Accuracy: 0.2748\n",
      "2025-08-02 20:36:04,567 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 350 | Avg Loss: 2.6308 | Accuracy: 0.2765\n",
      "2025-08-02 20:36:05,092 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 360 | Avg Loss: 2.5812 | Accuracy: 0.2782\n",
      "2025-08-02 20:36:05,589 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 370 | Avg Loss: 2.6387 | Accuracy: 0.2793\n",
      "2025-08-02 20:36:06,115 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 380 | Avg Loss: 2.6363 | Accuracy: 0.2805\n",
      "2025-08-02 20:36:06,622 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 | Batch 390 | Avg Loss: 2.6396 | Accuracy: 0.2815\n",
      "2025-08-02 20:36:06,670 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 2 completed - Loss: 2.9326, Accuracy: 0.2818\n",
      "2025-08-02 20:36:07,093 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11626', 'new_value': '0.2818'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009460911419656541', 'new_value': '0.015159402754571703'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '2'}]' for run ID='72ec208748df4965918f25d169edab35'.\n",
      "2025-08-02 20:36:07,094 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.2818\n",
      "Epoch 2/10: Loss: 2.9326 | Acc: 0.2818 | Time: 20.6s | LR: 3.00e-03 | Memory: 81.0%\n",
      "2025-08-02 20:36:07,095 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 3, total batches: 391\n",
      "2025-08-02 20:36:07,673 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 10 | Avg Loss: 2.5190 | Accuracy: 0.3680\n",
      "2025-08-02 20:36:08,176 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 20 | Avg Loss: 2.6969 | Accuracy: 0.3445\n",
      "2025-08-02 20:36:08,704 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 30 | Avg Loss: 2.4988 | Accuracy: 0.3503\n",
      "2025-08-02 20:36:09,212 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 40 | Avg Loss: 2.4618 | Accuracy: 0.3543\n",
      "2025-08-02 20:36:09,743 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 50 | Avg Loss: 2.5453 | Accuracy: 0.3528\n",
      "2025-08-02 20:36:10,299 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 60 | Avg Loss: 2.5734 | Accuracy: 0.3522\n",
      "2025-08-02 20:36:10,865 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 70 | Avg Loss: 2.4870 | Accuracy: 0.3541\n",
      "2025-08-02 20:36:11,425 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 80 | Avg Loss: 2.5030 | Accuracy: 0.3568\n",
      "2025-08-02 20:36:12,001 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 90 | Avg Loss: 2.5192 | Accuracy: 0.3561\n",
      "2025-08-02 20:36:12,544 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 100 | Avg Loss: 2.5772 | Accuracy: 0.3535\n",
      "2025-08-02 20:36:13,272 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 110 | Avg Loss: 2.5287 | Accuracy: 0.3534\n",
      "2025-08-02 20:36:14,011 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 120 | Avg Loss: 2.6197 | Accuracy: 0.3509\n",
      "2025-08-02 20:36:14,659 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 130 | Avg Loss: 2.4696 | Accuracy: 0.3511\n",
      "2025-08-02 20:36:15,299 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 140 | Avg Loss: 2.4396 | Accuracy: 0.3522\n",
      "2025-08-02 20:36:16,062 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 150 | Avg Loss: 2.4112 | Accuracy: 0.3542\n",
      "2025-08-02 20:36:16,692 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 160 | Avg Loss: 2.4528 | Accuracy: 0.3548\n",
      "2025-08-02 20:36:17,316 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 170 | Avg Loss: 2.3759 | Accuracy: 0.3570\n",
      "2025-08-02 20:36:18,182 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 180 | Avg Loss: 2.3821 | Accuracy: 0.3574\n",
      "2025-08-02 20:36:19,039 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 190 | Avg Loss: 2.3872 | Accuracy: 0.3586\n",
      "2025-08-02 20:36:19,593 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 200 | Avg Loss: 2.4383 | Accuracy: 0.3599\n",
      "2025-08-02 20:36:20,410 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 210 | Avg Loss: 2.3772 | Accuracy: 0.3610\n",
      "2025-08-02 20:36:20,960 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 220 | Avg Loss: 2.4164 | Accuracy: 0.3612\n",
      "2025-08-02 20:36:21,473 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 230 | Avg Loss: 2.4720 | Accuracy: 0.3606\n",
      "2025-08-02 20:36:21,978 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 240 | Avg Loss: 2.4203 | Accuracy: 0.3618\n",
      "2025-08-02 20:36:22,516 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 250 | Avg Loss: 2.3506 | Accuracy: 0.3628\n",
      "2025-08-02 20:36:23,062 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 260 | Avg Loss: 2.4594 | Accuracy: 0.3630\n",
      "2025-08-02 20:36:23,603 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 270 | Avg Loss: 2.4611 | Accuracy: 0.3628\n",
      "2025-08-02 20:36:24,143 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 280 | Avg Loss: 2.4126 | Accuracy: 0.3628\n",
      "2025-08-02 20:36:24,929 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 290 | Avg Loss: 2.3979 | Accuracy: 0.3628\n",
      "2025-08-02 20:36:25,467 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 300 | Avg Loss: 2.3957 | Accuracy: 0.3629\n",
      "2025-08-02 20:36:26,032 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 310 | Avg Loss: 2.3396 | Accuracy: 0.3640\n",
      "2025-08-02 20:36:26,612 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 320 | Avg Loss: 2.2700 | Accuracy: 0.3655\n",
      "2025-08-02 20:36:27,227 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 330 | Avg Loss: 2.2858 | Accuracy: 0.3672\n",
      "2025-08-02 20:36:27,823 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 340 | Avg Loss: 2.3797 | Accuracy: 0.3675\n",
      "2025-08-02 20:36:28,487 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 350 | Avg Loss: 2.3701 | Accuracy: 0.3677\n",
      "2025-08-02 20:36:29,218 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 360 | Avg Loss: 2.3401 | Accuracy: 0.3683\n",
      "2025-08-02 20:36:29,991 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 370 | Avg Loss: 2.2888 | Accuracy: 0.3690\n",
      "2025-08-02 20:36:30,777 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 380 | Avg Loss: 2.3532 | Accuracy: 0.3695\n",
      "2025-08-02 20:36:31,595 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 | Batch 390 | Avg Loss: 2.2608 | Accuracy: 0.3705\n",
      "2025-08-02 20:36:31,654 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 3 completed - Loss: 2.4342, Accuracy: 0.3705\n",
      "2025-08-02 20:36:32,063 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11626', 'new_value': '0.37048'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009460911419656541', 'new_value': '0.02209611799981859'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '3'}]' for run ID='72ec208748df4965918f25d169edab35'.\n",
      "2025-08-02 20:36:32,064 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.3705\n",
      "Epoch 3/10: Loss: 2.4342 | Acc: 0.3705 | Time: 25.0s | LR: 3.00e-03 | Memory: 80.3%\n",
      "2025-08-02 20:36:32,065 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 4, total batches: 391\n",
      "2025-08-02 20:36:33,034 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 10 | Avg Loss: 2.1772 | Accuracy: 0.4203\n",
      "2025-08-02 20:36:33,926 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 20 | Avg Loss: 2.2821 | Accuracy: 0.4086\n",
      "2025-08-02 20:36:34,810 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 30 | Avg Loss: 2.2877 | Accuracy: 0.4042\n",
      "2025-08-02 20:36:35,725 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 40 | Avg Loss: 2.2688 | Accuracy: 0.4023\n",
      "2025-08-02 20:36:36,609 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 50 | Avg Loss: 2.2298 | Accuracy: 0.4072\n",
      "2025-08-02 20:36:37,526 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 60 | Avg Loss: 2.2196 | Accuracy: 0.4077\n",
      "2025-08-02 20:36:38,487 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 70 | Avg Loss: 2.1953 | Accuracy: 0.4102\n",
      "2025-08-02 20:36:39,487 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 80 | Avg Loss: 2.1795 | Accuracy: 0.4102\n",
      "2025-08-02 20:36:40,510 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 90 | Avg Loss: 2.2264 | Accuracy: 0.4085\n",
      "2025-08-02 20:36:41,504 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 100 | Avg Loss: 2.3017 | Accuracy: 0.4068\n",
      "2025-08-02 20:36:42,488 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 110 | Avg Loss: 2.2032 | Accuracy: 0.4082\n",
      "2025-08-02 20:36:43,489 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 120 | Avg Loss: 2.2230 | Accuracy: 0.4091\n",
      "2025-08-02 20:36:44,427 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 130 | Avg Loss: 2.2022 | Accuracy: 0.4097\n",
      "2025-08-02 20:36:45,323 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 140 | Avg Loss: 2.1765 | Accuracy: 0.4100\n",
      "2025-08-02 20:36:46,208 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 150 | Avg Loss: 2.1787 | Accuracy: 0.4103\n",
      "2025-08-02 20:36:47,101 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 160 | Avg Loss: 2.0975 | Accuracy: 0.4126\n",
      "2025-08-02 20:36:48,030 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 170 | Avg Loss: 2.1490 | Accuracy: 0.4140\n",
      "2025-08-02 20:36:49,023 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 180 | Avg Loss: 2.2259 | Accuracy: 0.4126\n",
      "2025-08-02 20:36:49,980 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 190 | Avg Loss: 2.1342 | Accuracy: 0.4138\n",
      "2025-08-02 20:36:50,946 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 200 | Avg Loss: 2.1797 | Accuracy: 0.4145\n",
      "2025-08-02 20:36:51,953 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 210 | Avg Loss: 2.2456 | Accuracy: 0.4144\n",
      "2025-08-02 20:36:52,945 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 220 | Avg Loss: 2.2012 | Accuracy: 0.4151\n",
      "2025-08-02 20:36:53,947 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 230 | Avg Loss: 2.2321 | Accuracy: 0.4144\n",
      "2025-08-02 20:36:54,972 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 240 | Avg Loss: 2.1536 | Accuracy: 0.4148\n",
      "2025-08-02 20:36:55,889 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 250 | Avg Loss: 2.2269 | Accuracy: 0.4140\n",
      "2025-08-02 20:36:56,835 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 260 | Avg Loss: 2.1476 | Accuracy: 0.4150\n",
      "2025-08-02 20:36:57,763 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 270 | Avg Loss: 2.1734 | Accuracy: 0.4150\n",
      "2025-08-02 20:36:58,715 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 280 | Avg Loss: 2.1937 | Accuracy: 0.4155\n",
      "2025-08-02 20:36:59,739 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 290 | Avg Loss: 2.1607 | Accuracy: 0.4152\n",
      "2025-08-02 20:37:00,741 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 300 | Avg Loss: 2.1968 | Accuracy: 0.4155\n",
      "2025-08-02 20:37:01,746 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 310 | Avg Loss: 2.2085 | Accuracy: 0.4158\n",
      "2025-08-02 20:37:02,744 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 320 | Avg Loss: 2.0206 | Accuracy: 0.4174\n",
      "2025-08-02 20:37:03,738 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 330 | Avg Loss: 2.1670 | Accuracy: 0.4177\n",
      "2025-08-02 20:37:04,757 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 340 | Avg Loss: 2.0080 | Accuracy: 0.4186\n",
      "2025-08-02 20:37:05,749 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 350 | Avg Loss: 2.1450 | Accuracy: 0.4192\n",
      "2025-08-02 20:37:06,787 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 360 | Avg Loss: 2.1283 | Accuracy: 0.4198\n",
      "2025-08-02 20:37:07,786 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 370 | Avg Loss: 2.2051 | Accuracy: 0.4200\n",
      "2025-08-02 20:37:08,808 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 380 | Avg Loss: 2.1322 | Accuracy: 0.4202\n",
      "2025-08-02 20:37:09,834 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 | Batch 390 | Avg Loss: 2.1361 | Accuracy: 0.4206\n",
      "2025-08-02 20:37:09,905 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 4 completed - Loss: 2.1857, Accuracy: 0.4206\n",
      "2025-08-02 20:37:10,227 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11626', 'new_value': '0.42056'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009460911419656541', 'new_value': '0.032696772747569616'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '4'}]' for run ID='72ec208748df4965918f25d169edab35'.\n",
      "2025-08-02 20:37:10,228 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.4206\n",
      "Epoch 4/10: Loss: 2.1857 | Acc: 0.4206 | Time: 38.3s | LR: 3.00e-03 | Memory: 80.3%\n",
      "2025-08-02 20:37:10,229 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 5, total batches: 391\n",
      "2025-08-02 20:37:10,850 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 10 | Avg Loss: 2.0316 | Accuracy: 0.4352\n",
      "2025-08-02 20:37:11,696 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 20 | Avg Loss: 2.1639 | Accuracy: 0.4266\n",
      "2025-08-02 20:37:12,265 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 30 | Avg Loss: 2.1055 | Accuracy: 0.4318\n",
      "2025-08-02 20:37:12,838 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 40 | Avg Loss: 2.0938 | Accuracy: 0.4348\n",
      "2025-08-02 20:37:13,338 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 50 | Avg Loss: 2.0323 | Accuracy: 0.4386\n",
      "2025-08-02 20:37:13,847 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 60 | Avg Loss: 2.0557 | Accuracy: 0.4402\n",
      "2025-08-02 20:37:14,384 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 70 | Avg Loss: 2.0792 | Accuracy: 0.4392\n",
      "2025-08-02 20:37:14,985 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 80 | Avg Loss: 2.1478 | Accuracy: 0.4393\n",
      "2025-08-02 20:37:15,525 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 90 | Avg Loss: 2.1525 | Accuracy: 0.4386\n",
      "2025-08-02 20:37:16,166 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 100 | Avg Loss: 2.0440 | Accuracy: 0.4382\n",
      "2025-08-02 20:37:16,704 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 110 | Avg Loss: 2.0787 | Accuracy: 0.4381\n",
      "2025-08-02 20:37:17,252 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 120 | Avg Loss: 2.1231 | Accuracy: 0.4370\n",
      "2025-08-02 20:37:17,755 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 130 | Avg Loss: 2.0219 | Accuracy: 0.4384\n",
      "2025-08-02 20:37:18,349 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 140 | Avg Loss: 2.1195 | Accuracy: 0.4392\n",
      "2025-08-02 20:37:18,885 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 150 | Avg Loss: 1.9862 | Accuracy: 0.4419\n",
      "2025-08-02 20:37:19,387 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 160 | Avg Loss: 2.0374 | Accuracy: 0.4422\n",
      "2025-08-02 20:37:19,976 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 170 | Avg Loss: 2.0648 | Accuracy: 0.4432\n",
      "2025-08-02 20:37:20,489 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 180 | Avg Loss: 1.9846 | Accuracy: 0.4436\n",
      "2025-08-02 20:37:20,996 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 190 | Avg Loss: 1.9739 | Accuracy: 0.4448\n",
      "2025-08-02 20:37:21,527 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 200 | Avg Loss: 1.9925 | Accuracy: 0.4462\n",
      "2025-08-02 20:37:22,033 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 210 | Avg Loss: 2.0007 | Accuracy: 0.4475\n",
      "2025-08-02 20:37:22,546 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 220 | Avg Loss: 2.0069 | Accuracy: 0.4478\n",
      "2025-08-02 20:37:23,074 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 230 | Avg Loss: 2.0209 | Accuracy: 0.4483\n",
      "2025-08-02 20:37:23,580 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 240 | Avg Loss: 2.0977 | Accuracy: 0.4480\n",
      "2025-08-02 20:37:24,085 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 250 | Avg Loss: 2.0523 | Accuracy: 0.4482\n",
      "2025-08-02 20:37:24,618 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 260 | Avg Loss: 2.0368 | Accuracy: 0.4479\n",
      "2025-08-02 20:37:25,127 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 270 | Avg Loss: 2.0124 | Accuracy: 0.4484\n",
      "2025-08-02 20:37:25,664 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 280 | Avg Loss: 2.0735 | Accuracy: 0.4484\n",
      "2025-08-02 20:37:26,174 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 290 | Avg Loss: 1.9671 | Accuracy: 0.4495\n",
      "2025-08-02 20:37:26,683 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 300 | Avg Loss: 1.9365 | Accuracy: 0.4498\n",
      "2025-08-02 20:37:27,188 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 310 | Avg Loss: 2.0011 | Accuracy: 0.4499\n",
      "2025-08-02 20:37:27,721 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 320 | Avg Loss: 1.9296 | Accuracy: 0.4503\n",
      "2025-08-02 20:37:28,231 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 330 | Avg Loss: 2.0238 | Accuracy: 0.4504\n",
      "2025-08-02 20:37:28,770 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 340 | Avg Loss: 1.9611 | Accuracy: 0.4511\n",
      "2025-08-02 20:37:29,271 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 350 | Avg Loss: 2.0281 | Accuracy: 0.4511\n",
      "2025-08-02 20:37:29,771 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 360 | Avg Loss: 2.0976 | Accuracy: 0.4506\n",
      "2025-08-02 20:37:30,349 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 370 | Avg Loss: 2.0220 | Accuracy: 0.4507\n",
      "2025-08-02 20:37:30,966 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 380 | Avg Loss: 2.1030 | Accuracy: 0.4504\n",
      "2025-08-02 20:37:31,640 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 | Batch 390 | Avg Loss: 2.0321 | Accuracy: 0.4506\n",
      "2025-08-02 20:37:31,691 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 5 completed - Loss: 2.0431, Accuracy: 0.4507\n",
      "2025-08-02 20:37:32,004 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11626', 'new_value': '0.45074'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009460911419656541', 'new_value': '0.03874593887064192'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '5'}]' for run ID='72ec208748df4965918f25d169edab35'.\n",
      "2025-08-02 20:37:32,005 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.4507\n",
      "Epoch 5/10: Loss: 2.0431 | Acc: 0.4507 | Time: 21.8s | LR: 3.00e-03 | Memory: 80.3%\n",
      "2025-08-02 20:37:32,006 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 6, total batches: 391\n",
      "2025-08-02 20:37:32,534 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 10 | Avg Loss: 1.8679 | Accuracy: 0.4945\n",
      "2025-08-02 20:37:33,037 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 20 | Avg Loss: 1.9679 | Accuracy: 0.4766\n",
      "2025-08-02 20:37:33,569 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 30 | Avg Loss: 1.8814 | Accuracy: 0.4763\n",
      "2025-08-02 20:37:34,075 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 40 | Avg Loss: 1.9610 | Accuracy: 0.4748\n",
      "2025-08-02 20:37:34,580 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 50 | Avg Loss: 1.9671 | Accuracy: 0.4719\n",
      "2025-08-02 20:37:35,084 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 60 | Avg Loss: 1.9647 | Accuracy: 0.4706\n",
      "2025-08-02 20:37:35,581 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 70 | Avg Loss: 1.8828 | Accuracy: 0.4730\n",
      "2025-08-02 20:37:36,098 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 80 | Avg Loss: 1.8858 | Accuracy: 0.4741\n",
      "2025-08-02 20:37:36,636 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 90 | Avg Loss: 1.9056 | Accuracy: 0.4732\n",
      "2025-08-02 20:37:37,142 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 100 | Avg Loss: 2.0182 | Accuracy: 0.4706\n",
      "2025-08-02 20:37:37,685 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 110 | Avg Loss: 1.9515 | Accuracy: 0.4719\n",
      "2025-08-02 20:37:38,421 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 120 | Avg Loss: 1.9959 | Accuracy: 0.4707\n",
      "2025-08-02 20:37:39,009 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 130 | Avg Loss: 1.9310 | Accuracy: 0.4713\n",
      "2025-08-02 20:37:39,522 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 140 | Avg Loss: 1.8854 | Accuracy: 0.4714\n",
      "2025-08-02 20:37:40,098 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 150 | Avg Loss: 1.9952 | Accuracy: 0.4706\n",
      "2025-08-02 20:37:40,603 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 160 | Avg Loss: 1.9665 | Accuracy: 0.4698\n",
      "2025-08-02 20:37:41,260 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 170 | Avg Loss: 1.9026 | Accuracy: 0.4705\n",
      "2025-08-02 20:37:41,833 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 180 | Avg Loss: 1.8630 | Accuracy: 0.4718\n",
      "2025-08-02 20:37:42,468 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 190 | Avg Loss: 1.8816 | Accuracy: 0.4721\n",
      "2025-08-02 20:37:43,114 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 200 | Avg Loss: 1.9035 | Accuracy: 0.4732\n",
      "2025-08-02 20:37:43,756 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 210 | Avg Loss: 1.9966 | Accuracy: 0.4723\n",
      "2025-08-02 20:37:44,417 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 220 | Avg Loss: 1.9719 | Accuracy: 0.4727\n",
      "2025-08-02 20:37:45,080 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 230 | Avg Loss: 1.8825 | Accuracy: 0.4730\n",
      "2025-08-02 20:37:45,748 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 240 | Avg Loss: 2.0040 | Accuracy: 0.4725\n",
      "2025-08-02 20:37:46,436 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 250 | Avg Loss: 1.9275 | Accuracy: 0.4724\n",
      "2025-08-02 20:37:47,102 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 260 | Avg Loss: 1.8772 | Accuracy: 0.4727\n",
      "2025-08-02 20:37:47,710 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 270 | Avg Loss: 1.9666 | Accuracy: 0.4726\n",
      "2025-08-02 20:37:48,215 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 280 | Avg Loss: 1.9104 | Accuracy: 0.4725\n",
      "2025-08-02 20:37:48,721 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 290 | Avg Loss: 1.9622 | Accuracy: 0.4730\n",
      "2025-08-02 20:37:49,226 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 300 | Avg Loss: 2.0255 | Accuracy: 0.4718\n",
      "2025-08-02 20:37:49,734 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 310 | Avg Loss: 1.8584 | Accuracy: 0.4727\n",
      "2025-08-02 20:37:50,236 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 320 | Avg Loss: 1.8279 | Accuracy: 0.4737\n",
      "2025-08-02 20:37:50,738 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 330 | Avg Loss: 1.8468 | Accuracy: 0.4741\n",
      "2025-08-02 20:37:51,238 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 340 | Avg Loss: 1.9473 | Accuracy: 0.4740\n",
      "2025-08-02 20:37:51,738 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 350 | Avg Loss: 1.9245 | Accuracy: 0.4746\n",
      "2025-08-02 20:37:52,366 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 360 | Avg Loss: 2.0142 | Accuracy: 0.4740\n",
      "2025-08-02 20:37:53,024 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 370 | Avg Loss: 1.9013 | Accuracy: 0.4742\n",
      "2025-08-02 20:37:53,701 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 380 | Avg Loss: 1.9012 | Accuracy: 0.4749\n",
      "2025-08-02 20:37:54,424 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 | Batch 390 | Avg Loss: 1.7754 | Accuracy: 0.4758\n",
      "2025-08-02 20:37:54,478 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 6 completed - Loss: 1.9261, Accuracy: 0.4757\n",
      "2025-08-02 20:37:54,792 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11626', 'new_value': '0.47572'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009460911419656541', 'new_value': '0.04507608579264747'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '6'}]' for run ID='72ec208748df4965918f25d169edab35'.\n",
      "2025-08-02 20:37:54,793 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.4757\n",
      "Epoch 6/10: Loss: 1.9261 | Acc: 0.4757 | Time: 22.8s | LR: 3.00e-03 | Memory: 80.2%\n",
      "2025-08-02 20:37:54,794 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 7, total batches: 391\n",
      "2025-08-02 20:37:55,331 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 10 | Avg Loss: 1.8535 | Accuracy: 0.4727\n",
      "2025-08-02 20:37:55,829 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 20 | Avg Loss: 1.8327 | Accuracy: 0.4816\n",
      "2025-08-02 20:37:56,358 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 30 | Avg Loss: 1.7955 | Accuracy: 0.4836\n",
      "2025-08-02 20:37:56,863 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 40 | Avg Loss: 1.8398 | Accuracy: 0.4881\n",
      "2025-08-02 20:37:57,380 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 50 | Avg Loss: 1.8209 | Accuracy: 0.4878\n",
      "2025-08-02 20:37:57,908 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 60 | Avg Loss: 1.7945 | Accuracy: 0.4917\n",
      "2025-08-02 20:37:58,476 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 70 | Avg Loss: 1.8532 | Accuracy: 0.4903\n",
      "2025-08-02 20:37:58,979 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 80 | Avg Loss: 1.8063 | Accuracy: 0.4921\n",
      "2025-08-02 20:37:59,477 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 90 | Avg Loss: 1.8939 | Accuracy: 0.4898\n",
      "2025-08-02 20:37:59,981 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 100 | Avg Loss: 1.8520 | Accuracy: 0.4916\n",
      "2025-08-02 20:38:00,481 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 110 | Avg Loss: 1.7865 | Accuracy: 0.4920\n",
      "2025-08-02 20:38:00,980 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 120 | Avg Loss: 1.8810 | Accuracy: 0.4919\n",
      "2025-08-02 20:38:01,478 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 130 | Avg Loss: 1.8757 | Accuracy: 0.4910\n",
      "2025-08-02 20:38:01,979 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 140 | Avg Loss: 1.8023 | Accuracy: 0.4921\n",
      "2025-08-02 20:38:02,508 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 150 | Avg Loss: 1.8059 | Accuracy: 0.4938\n",
      "2025-08-02 20:38:03,163 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 160 | Avg Loss: 1.8159 | Accuracy: 0.4938\n",
      "2025-08-02 20:38:03,824 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 170 | Avg Loss: 1.8039 | Accuracy: 0.4944\n",
      "2025-08-02 20:38:04,531 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 180 | Avg Loss: 1.8024 | Accuracy: 0.4946\n",
      "2025-08-02 20:38:05,052 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 190 | Avg Loss: 1.7539 | Accuracy: 0.4955\n",
      "2025-08-02 20:38:05,555 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 200 | Avg Loss: 1.8691 | Accuracy: 0.4955\n",
      "2025-08-02 20:38:06,057 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 210 | Avg Loss: 1.8249 | Accuracy: 0.4956\n",
      "2025-08-02 20:38:06,557 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 220 | Avg Loss: 1.8675 | Accuracy: 0.4951\n",
      "2025-08-02 20:38:07,064 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 230 | Avg Loss: 1.9155 | Accuracy: 0.4938\n",
      "2025-08-02 20:38:07,573 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 240 | Avg Loss: 1.8093 | Accuracy: 0.4943\n",
      "2025-08-02 20:38:08,079 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 250 | Avg Loss: 1.8040 | Accuracy: 0.4949\n",
      "2025-08-02 20:38:08,581 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 260 | Avg Loss: 1.7602 | Accuracy: 0.4953\n",
      "2025-08-02 20:38:09,085 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 270 | Avg Loss: 1.8684 | Accuracy: 0.4946\n",
      "2025-08-02 20:38:09,590 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 280 | Avg Loss: 1.7773 | Accuracy: 0.4955\n",
      "2025-08-02 20:38:10,091 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 290 | Avg Loss: 1.8500 | Accuracy: 0.4962\n",
      "2025-08-02 20:38:10,597 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 300 | Avg Loss: 1.8324 | Accuracy: 0.4966\n",
      "2025-08-02 20:38:11,099 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 310 | Avg Loss: 1.8136 | Accuracy: 0.4968\n",
      "2025-08-02 20:38:11,604 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 320 | Avg Loss: 1.7792 | Accuracy: 0.4973\n",
      "2025-08-02 20:38:12,114 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 330 | Avg Loss: 1.7208 | Accuracy: 0.4975\n",
      "2025-08-02 20:38:12,618 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 340 | Avg Loss: 1.7784 | Accuracy: 0.4977\n",
      "2025-08-02 20:38:13,126 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 350 | Avg Loss: 1.8294 | Accuracy: 0.4978\n",
      "2025-08-02 20:38:13,636 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 360 | Avg Loss: 1.7971 | Accuracy: 0.4982\n",
      "2025-08-02 20:38:14,141 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 370 | Avg Loss: 1.7879 | Accuracy: 0.4983\n",
      "2025-08-02 20:38:14,647 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 380 | Avg Loss: 1.7973 | Accuracy: 0.4984\n",
      "2025-08-02 20:38:15,342 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 | Batch 390 | Avg Loss: 1.7812 | Accuracy: 0.4984\n",
      "2025-08-02 20:38:15,410 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 7 completed - Loss: 1.8187, Accuracy: 0.4984\n",
      "2025-08-02 20:38:15,725 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11626', 'new_value': '0.49842'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009460911419656541', 'new_value': '0.05089057193862068'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '7'}]' for run ID='72ec208748df4965918f25d169edab35'.\n",
      "2025-08-02 20:38:15,726 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.4984\n",
      "Epoch 7/10: Loss: 1.8187 | Acc: 0.4984 | Time: 20.9s | LR: 3.00e-03 | Memory: 80.4%\n",
      "2025-08-02 20:38:15,727 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 8, total batches: 391\n",
      "2025-08-02 20:38:16,359 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 10 | Avg Loss: 1.7994 | Accuracy: 0.5094\n",
      "2025-08-02 20:38:16,935 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 20 | Avg Loss: 1.7984 | Accuracy: 0.5086\n",
      "2025-08-02 20:38:17,561 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 30 | Avg Loss: 1.7990 | Accuracy: 0.5049\n",
      "2025-08-02 20:38:18,094 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 40 | Avg Loss: 1.7708 | Accuracy: 0.5082\n",
      "2025-08-02 20:38:18,721 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 50 | Avg Loss: 1.8125 | Accuracy: 0.5078\n",
      "2025-08-02 20:38:19,256 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 60 | Avg Loss: 1.8694 | Accuracy: 0.5055\n",
      "2025-08-02 20:38:19,915 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 70 | Avg Loss: 1.7682 | Accuracy: 0.5075\n",
      "2025-08-02 20:38:20,473 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 80 | Avg Loss: 1.7161 | Accuracy: 0.5058\n",
      "2025-08-02 20:38:21,004 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 90 | Avg Loss: 1.7922 | Accuracy: 0.5056\n",
      "2025-08-02 20:38:21,687 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 100 | Avg Loss: 1.7381 | Accuracy: 0.5059\n",
      "2025-08-02 20:38:22,307 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 110 | Avg Loss: 1.7098 | Accuracy: 0.5075\n",
      "2025-08-02 20:38:23,012 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 120 | Avg Loss: 1.7662 | Accuracy: 0.5084\n",
      "2025-08-02 20:38:23,988 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 130 | Avg Loss: 1.7562 | Accuracy: 0.5079\n",
      "2025-08-02 20:38:24,529 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 140 | Avg Loss: 1.6905 | Accuracy: 0.5097\n",
      "2025-08-02 20:38:25,062 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 150 | Avg Loss: 1.7830 | Accuracy: 0.5098\n",
      "2025-08-02 20:38:25,587 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 160 | Avg Loss: 1.7012 | Accuracy: 0.5115\n",
      "2025-08-02 20:38:26,142 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 170 | Avg Loss: 1.7326 | Accuracy: 0.5116\n",
      "2025-08-02 20:38:26,708 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 180 | Avg Loss: 1.7394 | Accuracy: 0.5122\n",
      "2025-08-02 20:38:27,280 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 190 | Avg Loss: 1.7214 | Accuracy: 0.5129\n",
      "2025-08-02 20:38:27,876 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 200 | Avg Loss: 1.6922 | Accuracy: 0.5136\n",
      "2025-08-02 20:38:28,597 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 210 | Avg Loss: 1.8287 | Accuracy: 0.5125\n",
      "2025-08-02 20:38:29,279 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 220 | Avg Loss: 1.6246 | Accuracy: 0.5145\n",
      "2025-08-02 20:38:29,880 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 230 | Avg Loss: 1.7707 | Accuracy: 0.5151\n",
      "2025-08-02 20:38:30,524 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 240 | Avg Loss: 1.8128 | Accuracy: 0.5148\n",
      "2025-08-02 20:38:31,205 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 250 | Avg Loss: 1.6398 | Accuracy: 0.5158\n",
      "2025-08-02 20:38:32,001 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 260 | Avg Loss: 1.6735 | Accuracy: 0.5165\n",
      "2025-08-02 20:38:32,667 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 270 | Avg Loss: 1.7550 | Accuracy: 0.5163\n",
      "2025-08-02 20:38:33,238 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 280 | Avg Loss: 1.7008 | Accuracy: 0.5169\n",
      "2025-08-02 20:38:33,842 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 290 | Avg Loss: 1.8028 | Accuracy: 0.5157\n",
      "2025-08-02 20:38:34,459 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 300 | Avg Loss: 1.6759 | Accuracy: 0.5161\n",
      "2025-08-02 20:38:35,169 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 310 | Avg Loss: 1.7047 | Accuracy: 0.5167\n",
      "2025-08-02 20:38:35,908 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 320 | Avg Loss: 1.7410 | Accuracy: 0.5165\n",
      "2025-08-02 20:38:36,705 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 330 | Avg Loss: 1.7054 | Accuracy: 0.5168\n",
      "2025-08-02 20:38:37,392 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 340 | Avg Loss: 1.7341 | Accuracy: 0.5168\n",
      "2025-08-02 20:38:38,133 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 350 | Avg Loss: 1.7447 | Accuracy: 0.5172\n",
      "2025-08-02 20:38:38,979 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 360 | Avg Loss: 1.7337 | Accuracy: 0.5171\n",
      "2025-08-02 20:38:39,859 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 370 | Avg Loss: 1.7692 | Accuracy: 0.5171\n",
      "2025-08-02 20:38:40,709 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 380 | Avg Loss: 1.6800 | Accuracy: 0.5168\n",
      "2025-08-02 20:38:41,665 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 | Batch 390 | Avg Loss: 1.6642 | Accuracy: 0.5174\n",
      "2025-08-02 20:38:41,747 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 8 completed - Loss: 1.7420, Accuracy: 0.5174\n",
      "2025-08-02 20:38:42,056 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11626', 'new_value': '0.51744'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009460911419656541', 'new_value': '0.05820496638615926'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '8'}]' for run ID='72ec208748df4965918f25d169edab35'.\n",
      "2025-08-02 20:38:42,056 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.5174\n",
      "Epoch 8/10: Loss: 1.7420 | Acc: 0.5174 | Time: 26.3s | LR: 3.00e-03 | Memory: 79.5%\n",
      "2025-08-02 20:38:42,056 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 9, total batches: 391\n",
      "2025-08-02 20:38:42,793 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 10 | Avg Loss: 1.7040 | Accuracy: 0.5336\n",
      "2025-08-02 20:38:43,475 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 20 | Avg Loss: 1.5231 | Accuracy: 0.5551\n",
      "2025-08-02 20:38:44,080 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 30 | Avg Loss: 1.7231 | Accuracy: 0.5411\n",
      "2025-08-02 20:38:44,765 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 40 | Avg Loss: 1.6531 | Accuracy: 0.5447\n",
      "2025-08-02 20:38:45,409 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 50 | Avg Loss: 1.6134 | Accuracy: 0.5483\n",
      "2025-08-02 20:38:46,101 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 60 | Avg Loss: 1.6367 | Accuracy: 0.5473\n",
      "2025-08-02 20:38:46,821 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 70 | Avg Loss: 1.7316 | Accuracy: 0.5435\n",
      "2025-08-02 20:38:47,464 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 80 | Avg Loss: 1.6198 | Accuracy: 0.5466\n",
      "2025-08-02 20:38:48,053 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 90 | Avg Loss: 1.6559 | Accuracy: 0.5447\n",
      "2025-08-02 20:38:48,602 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 100 | Avg Loss: 1.6137 | Accuracy: 0.5455\n",
      "2025-08-02 20:38:49,327 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 110 | Avg Loss: 1.6354 | Accuracy: 0.5453\n",
      "2025-08-02 20:38:49,925 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 120 | Avg Loss: 1.6492 | Accuracy: 0.5462\n",
      "2025-08-02 20:38:50,541 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 130 | Avg Loss: 1.6511 | Accuracy: 0.5447\n",
      "2025-08-02 20:38:51,146 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 140 | Avg Loss: 1.6441 | Accuracy: 0.5436\n",
      "2025-08-02 20:38:51,694 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 150 | Avg Loss: 1.7075 | Accuracy: 0.5411\n",
      "2025-08-02 20:38:52,239 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 160 | Avg Loss: 1.6099 | Accuracy: 0.5417\n",
      "2025-08-02 20:38:52,895 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 170 | Avg Loss: 1.6565 | Accuracy: 0.5415\n",
      "2025-08-02 20:38:53,444 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 180 | Avg Loss: 1.5800 | Accuracy: 0.5424\n",
      "2025-08-02 20:38:53,981 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 190 | Avg Loss: 1.6566 | Accuracy: 0.5418\n",
      "2025-08-02 20:38:54,529 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 200 | Avg Loss: 1.6960 | Accuracy: 0.5409\n",
      "2025-08-02 20:38:55,078 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 210 | Avg Loss: 1.6781 | Accuracy: 0.5407\n",
      "2025-08-02 20:38:55,633 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 220 | Avg Loss: 1.6374 | Accuracy: 0.5406\n",
      "2025-08-02 20:38:56,171 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 230 | Avg Loss: 1.6935 | Accuracy: 0.5403\n",
      "2025-08-02 20:38:56,779 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 240 | Avg Loss: 1.5781 | Accuracy: 0.5410\n",
      "2025-08-02 20:38:57,478 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 250 | Avg Loss: 1.6573 | Accuracy: 0.5413\n",
      "2025-08-02 20:38:58,055 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 260 | Avg Loss: 1.6513 | Accuracy: 0.5415\n",
      "2025-08-02 20:38:58,606 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 270 | Avg Loss: 1.6762 | Accuracy: 0.5417\n",
      "2025-08-02 20:38:59,205 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 280 | Avg Loss: 1.6910 | Accuracy: 0.5411\n",
      "2025-08-02 20:38:59,812 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 290 | Avg Loss: 1.6519 | Accuracy: 0.5411\n",
      "2025-08-02 20:39:00,386 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 300 | Avg Loss: 1.6772 | Accuracy: 0.5405\n",
      "2025-08-02 20:39:00,965 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 310 | Avg Loss: 1.6483 | Accuracy: 0.5409\n",
      "2025-08-02 20:39:01,516 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 320 | Avg Loss: 1.5898 | Accuracy: 0.5413\n",
      "2025-08-02 20:39:02,063 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 330 | Avg Loss: 1.7542 | Accuracy: 0.5400\n",
      "2025-08-02 20:39:02,724 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 340 | Avg Loss: 1.6778 | Accuracy: 0.5398\n",
      "2025-08-02 20:39:03,373 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 350 | Avg Loss: 1.6274 | Accuracy: 0.5397\n",
      "2025-08-02 20:39:04,074 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 360 | Avg Loss: 1.7251 | Accuracy: 0.5395\n",
      "2025-08-02 20:39:04,773 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 370 | Avg Loss: 1.6035 | Accuracy: 0.5400\n",
      "2025-08-02 20:39:05,641 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 380 | Avg Loss: 1.6152 | Accuracy: 0.5402\n",
      "2025-08-02 20:39:07,014 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 | Batch 390 | Avg Loss: 1.6022 | Accuracy: 0.5408\n",
      "2025-08-02 20:39:07,093 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 9 completed - Loss: 1.6530, Accuracy: 0.5406\n",
      "2025-08-02 20:39:07,404 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11626', 'new_value': '0.54056'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009460911419656541', 'new_value': '0.0652468427684572'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '9'}]' for run ID='72ec208748df4965918f25d169edab35'.\n",
      "2025-08-02 20:39:07,405 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.5406\n",
      "Epoch 9/10: Loss: 1.6530 | Acc: 0.5406 | Time: 25.3s | LR: 3.00e-03 | Memory: 78.9%\n",
      "2025-08-02 20:39:07,405 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Starting epoch 10, total batches: 391\n",
      "2025-08-02 20:39:07,946 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 10 | Avg Loss: 1.5511 | Accuracy: 0.5547\n",
      "2025-08-02 20:39:08,448 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 20 | Avg Loss: 1.5956 | Accuracy: 0.5570\n",
      "2025-08-02 20:39:08,957 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 30 | Avg Loss: 1.5973 | Accuracy: 0.5529\n",
      "2025-08-02 20:39:09,469 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 40 | Avg Loss: 1.6395 | Accuracy: 0.5467\n",
      "2025-08-02 20:39:09,984 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 50 | Avg Loss: 1.5553 | Accuracy: 0.5478\n",
      "2025-08-02 20:39:10,508 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 60 | Avg Loss: 1.6236 | Accuracy: 0.5495\n",
      "2025-08-02 20:39:11,032 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 70 | Avg Loss: 1.5753 | Accuracy: 0.5507\n",
      "2025-08-02 20:39:11,603 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 80 | Avg Loss: 1.5470 | Accuracy: 0.5514\n",
      "2025-08-02 20:39:12,257 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 90 | Avg Loss: 1.5436 | Accuracy: 0.5511\n",
      "2025-08-02 20:39:12,807 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 100 | Avg Loss: 1.6130 | Accuracy: 0.5516\n",
      "2025-08-02 20:39:13,940 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 110 | Avg Loss: 1.5790 | Accuracy: 0.5533\n",
      "2025-08-02 20:39:14,537 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 120 | Avg Loss: 1.6354 | Accuracy: 0.5531\n",
      "2025-08-02 20:39:15,249 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 130 | Avg Loss: 1.6091 | Accuracy: 0.5530\n",
      "2025-08-02 20:39:16,032 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 140 | Avg Loss: 1.6089 | Accuracy: 0.5522\n",
      "2025-08-02 20:39:16,988 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 150 | Avg Loss: 1.5878 | Accuracy: 0.5516\n",
      "2025-08-02 20:39:17,765 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 160 | Avg Loss: 1.6277 | Accuracy: 0.5501\n",
      "2025-08-02 20:39:18,660 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 170 | Avg Loss: 1.6430 | Accuracy: 0.5493\n",
      "2025-08-02 20:39:19,337 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 180 | Avg Loss: 1.5726 | Accuracy: 0.5502\n",
      "2025-08-02 20:39:20,475 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 190 | Avg Loss: 1.5879 | Accuracy: 0.5497\n",
      "2025-08-02 20:39:21,381 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 200 | Avg Loss: 1.6083 | Accuracy: 0.5500\n",
      "2025-08-02 20:39:22,381 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 210 | Avg Loss: 1.5107 | Accuracy: 0.5515\n",
      "2025-08-02 20:39:23,264 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 220 | Avg Loss: 1.5498 | Accuracy: 0.5515\n",
      "2025-08-02 20:39:24,038 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 230 | Avg Loss: 1.5777 | Accuracy: 0.5514\n",
      "2025-08-02 20:39:24,850 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 240 | Avg Loss: 1.5165 | Accuracy: 0.5525\n",
      "2025-08-02 20:39:25,638 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 250 | Avg Loss: 1.5946 | Accuracy: 0.5525\n",
      "2025-08-02 20:39:26,345 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 260 | Avg Loss: 1.5732 | Accuracy: 0.5519\n",
      "2025-08-02 20:39:27,091 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 270 | Avg Loss: 1.5705 | Accuracy: 0.5521\n",
      "2025-08-02 20:39:27,862 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 280 | Avg Loss: 1.6005 | Accuracy: 0.5519\n",
      "2025-08-02 20:39:28,538 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 290 | Avg Loss: 1.6755 | Accuracy: 0.5516\n",
      "2025-08-02 20:39:29,300 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 300 | Avg Loss: 1.6738 | Accuracy: 0.5517\n",
      "2025-08-02 20:39:30,112 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 310 | Avg Loss: 1.6212 | Accuracy: 0.5512\n",
      "2025-08-02 20:39:30,840 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 320 | Avg Loss: 1.6651 | Accuracy: 0.5505\n",
      "2025-08-02 20:39:31,551 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 330 | Avg Loss: 1.6681 | Accuracy: 0.5502\n",
      "2025-08-02 20:39:32,365 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 340 | Avg Loss: 1.6344 | Accuracy: 0.5494\n",
      "2025-08-02 20:39:33,134 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 350 | Avg Loss: 1.5439 | Accuracy: 0.5497\n",
      "2025-08-02 20:39:33,869 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 360 | Avg Loss: 1.6370 | Accuracy: 0.5495\n",
      "2025-08-02 20:39:34,698 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 370 | Avg Loss: 1.5924 | Accuracy: 0.5497\n",
      "2025-08-02 20:39:35,522 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 380 | Avg Loss: 1.5306 | Accuracy: 0.5498\n",
      "2025-08-02 20:39:36,251 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 | Batch 390 | Avg Loss: 1.6058 | Accuracy: 0.5503\n",
      "2025-08-02 20:39:36,325 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Epoch 10 completed - Loss: 1.5961, Accuracy: 0.5501\n",
      "2025-08-02 20:39:36,636 - WARNING - 1236875293.py - PID:26817 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_model_accuracy', 'old_value': '0.11626', 'new_value': '0.55008'}, {'key': 'best_model_training_time_hours', 'old_value': '0.009460911419656541', 'new_value': '0.07336704300509558'}, {'key': 'best_model_epochs_trained', 'old_value': '1', 'new_value': '10'}]' for run ID='72ec208748df4965918f25d169edab35'.\n",
      "2025-08-02 20:39:36,637 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - New best model metadata saved with accuracy: 0.5501\n",
      "Epoch 10/10: Loss: 1.5961 | Acc: 0.5501 | Time: 29.2s | LR: 3.00e-03 | Memory: 79.4%\n",
      " View run 20250802_203521 at: https://neuralripper.com/mlflow/#/experiments/1/runs/72ec208748df4965918f25d169edab35\n",
      " View experiment at: https://neuralripper.com/mlflow/#/experiments/1\n",
      "2025-08-02 20:39:36,772 - INFO - 3724282253.py - PID:26817 - TID:8462606080 - Training completed. Summary: {'final_total_training_time_minutes': 4.4, 'final_best_accuracy': 0.55008, 'final_epochs_completed': 10}\n",
      "\n",
      "Training Summary:\n",
      "Total time: 4.4 minutes\n",
      "Best accuracy: 0.5501\n",
      "Epochs completed: 10\n"
     ]
    }
   ],
   "source": [
    "# Start training with comprehensive monitoring\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" STARTING ENHANCED MOBILENETV2 TRAINING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset: CIFAR-100 (100 classes)\")\n",
    "print(f\"Model: MobileNetV2 (pretrained)\")\n",
    "print(f\"Epochs: {model._num_epochs}\")\n",
    "print(f\"Batch size: {model._batch_size}\")\n",
    "print(f\"Learning rate: {model._learning_rate}\")\n",
    "print(f\"MLflow tracking: {'Enabled' if model._use_mlflow else 'Disabled'}\")\n",
    "print(f\"MLflow URI: {model.monitor.mlflow_uri}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Start training\n",
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3TvvXzbBz7Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMYZDW3c+maUFI63troF8xy",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ripper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
