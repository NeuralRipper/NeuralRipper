{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T00:10:30.826229Z",
     "start_time": "2025-06-20T00:10:30.504937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.modules.module import T\n",
    "# Step 1: Data Pipeline, Preprocessing the data\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "data_root = project_root / \"data\"\n",
    "\n",
    "# Transform of data, resize, normalize, etc\n",
    "# Compose accept a list of instance\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize(224),  # upsample the CIFAR from 32x32 to 224x224, the EfficientNet expects this\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.Normalize([0.48, 0.45, 0.40], [0.23, 0.22, 0.22])\n",
    "])\n",
    "\n",
    "# Dataset and pytorch Dataloader\n",
    "train_ds = CIFAR100(\n",
    "    root=data_root,         # the path stores actual data\n",
    "    train=True,             # create dataset from training set, otherwise from testset\n",
    "    transform=train_tf\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {len(train_ds)}\")"
   ],
   "id": "9699ba139611dd5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T03:07:32.031313Z",
     "start_time": "2025-06-20T03:07:32.018421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.backends.mps\n",
    "\n",
    "# Step 2: Model definition\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "class MyEfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Complexity is lowest for B0\n",
    "    \"Model\",\"ϕ\\phiϕ\",\"Resolution\",\"Parameters (M)\",\"FLOPs (B)\",\"Top-1 Accuracy (ImageNet)\"\n",
    "    \"EfficientNet-B0\",\"0\",\"224x224\",\"5.3\",\"0.39\",\"~77.1%\"\n",
    "    \"EfficientNet-B1\",\"1\",\"240x240\",\"7.8\",\"0.70\",\"~79.1%\"\n",
    "    \"EfficientNet-B2\",\"2\",\"260x260\",\"9.2\",\"1.0\",\"~80.1%\"\n",
    "    \"EfficientNet-B3\",\"3\",\"300x300\",\"12\",\"1.8\",\"~81.6%\"\n",
    "    \"EfficientNet-B4\",\"4\",\"380x380\",\"19\",\"4.2\",\"~82.9%\"\n",
    "    \"EfficientNet-B5\",\"5\",\"456x456\",\"30\",\"9.9\",\"~83.7%\"\n",
    "    \"EfficientNet-B6\",\"6\",\"528x528\",\"43\",\"19\",\"~84.0%\"\n",
    "    \"EfficientNet-B7\",\"7\",\"600x600\",\"66\",\"37\",\"~84.3%\"\n",
    "    # fine-tuning with pretrained weights, use lr=1e-4, too big is not good for fine-tuning\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size=32, num_epochs=10, num_classes=100, learning_rate=1e-4, use_mlflow=True):\n",
    "        super().__init__()\n",
    "        self._num_classes = num_classes\n",
    "        self._use_mlflow = use_mlflow\n",
    "        self._best_acc = -1\n",
    "\n",
    "        # Model Skeleton\n",
    "        # train from scratch: no pretrained weights\n",
    "        # models.efficientnet_b0(num_classes=self._num_classes, weights=None)\n",
    "        # Here we use pretrained weights as it's too costly and slow to train this, no num classes needed\n",
    "        self._model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # IMAGENET classifier\n",
    "        # Sequential((0): Dropout(p=0.2, inplace=True)\n",
    "        #            (1): Linear(in_features=1280, out_features=1000, bias=True))\n",
    "        # replace to 100 classes to fit CIFAR100\n",
    "        self._model.classifier[1] = nn.Linear(1280, 100)\n",
    "        self._device = self._set_device()\n",
    "        # set it to device setup; by default, model weights are on CPU, and input data is on MPS device\n",
    "        self._model.to(self._device)\n",
    "        self._num_classes = num_classes\n",
    "\n",
    "\n",
    "\n",
    "        # Hyperparameters\n",
    "        self._batch_size = batch_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        # Loss function & Optimizer\n",
    "        self._criterion = self._set_criterion()\n",
    "        self._optimizer = self._set_optimizer()\n",
    "\n",
    "    def _set_device(self):\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    def _set_optimizer(self):\n",
    "        return optim.Adam(self._model.parameters(), lr=self._learning_rate)\n",
    "\n",
    "    def _set_criterion(self):\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Define computation in forward(), call via model(X), pytorch auto calls model.forward(X)\n",
    "        Return:\n",
    "            Logits vector, the inference results\n",
    "        \"\"\"\n",
    "        return self.model(X)\n",
    "\n",
    "    # Train Epoch for 1 Loop\n",
    "    def train_epoch(self, data_loader, epoch_idx):\n",
    "        \"\"\"\n",
    "        1. Prediction: tensor([20, 58, 76, 61, 44, 44, 92, 60, 51, 87, 18, 51, 60, 87, 12, 75, 64, 10, 63, 26, 64, 70, 76, 66, 81, 20, 90, 76, 93, 42, 23, 13], device='mps:0')\n",
    "        Original tensor: [32, 100], 32 samples in one batch, 100 classes in each sample\n",
    "        2. Mask: tensor([False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], device='mps:0')\n",
    "        3. Mask tensor is boolean tenser in [32, 100], True/False\n",
    "        4. Use argmax column direction, we get [32, 1], the index of the largest probability in each sample\n",
    "        5. All the prediction, targets, loss, are tensor objects\n",
    "\n",
    "        Args:\n",
    "            loader: pytorch DataLoader instance for image iteration\n",
    "        Return:\n",
    "            epoch_loss: the average loss for current epoch: total loss / total batches\n",
    "            epoch_acc: the average accuracy for current epoch: total correct prediction / total true labels\n",
    "        \"\"\"\n",
    "        # Set model mode to train, so the Dropout, BatchNorm are up to work\n",
    "        self._model.train()\n",
    "        epoch_total_loss = 0.0  # Track full epoch\n",
    "        running_loss = 0.0      # Track 10-batch average\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        for idx, (images, targets) in enumerate(data_loader):\n",
    "            images = images.to(self._device)\n",
    "            # labels represented in int, not one-hot encoding\n",
    "            targets = targets.to(self._device)\n",
    "            # Clears(Reset) accumulated gradients from the previous iteration\n",
    "            self._optimizer.zero_grad()\n",
    "            # inference result from the model, it will auto call forward(images)\n",
    "            logits = self._model(images)\n",
    "            # Calculate the loss, compare Inference Prediction vs. True Labels\n",
    "            loss = self._criterion(logits, targets)\n",
    "            # backtrack to update the gradients\n",
    "            loss.backward()\n",
    "            # Update weights and parameters using latest gradients from backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            predictions = logits.argmax(dim=1)\n",
    "\n",
    "            # how many predictions match true labels\n",
    "            running_correct += (predictions == targets).sum().item()\n",
    "            # total number of the true labels\n",
    "            running_total += targets.size(0)\n",
    "            running_loss += loss.item()\n",
    "            epoch_total_loss += loss.item()\n",
    "\n",
    "            # print out progress every 10 batches\n",
    "            if idx % 10 == 9:\n",
    "                avg_loss = running_loss / 10\n",
    "                curr_acc = running_correct / running_total\n",
    "                print(f\"Epoch {epoch_idx + 1}| Batch {idx + 1} | Avg Loss {avg_loss: .4f} | Accuracy: {curr_acc:.4f}\")\n",
    "                running_loss = 0.0      # reset for every 10 batches\n",
    "\n",
    "        # return loss and accuracy for current training epoch\n",
    "        epoch_loss = epoch_total_loss / len(data_loader)     # total loss / total batches\n",
    "        epoch_acc = running_correct / running_total     # total correct prediction / total true labels\n",
    "        print(epoch_loss, epoch_acc)\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    # MLFlow Setup\n",
    "    def _setup_mlflow(self):\n",
    "        \"\"\"Initialize Mlflow experiment and log parameters\"\"\"\n",
    "        mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "        # setup name of experiment\n",
    "        mlflow.set_experiment(\"EfficientNet-B0-CIFAR100\")\n",
    "        # this will start a global state for all the mflow.log_*()\n",
    "        mlflow.start_run(run_name=datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "        mlflow.log_params({\n",
    "            \"model\": \"EfficientNet-B0\",\n",
    "            \"dataset\": \"CIFAR-100\",\n",
    "            \"batch_size\": self._batch_size,\n",
    "            \"learning_rate\": self._learning_rate,\n",
    "            \"epochs\": self._num_epochs,\n",
    "            \"device\": self._device.type,\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"num_classes\": self._num_classes\n",
    "        })\n",
    "\n",
    "    def _log_metrics(self, epoch, epoch_loss, epoch_acc):\n",
    "        \"\"\"Log metrics to Mlflow\"\"\"\n",
    "        if not self._use_mlflow:\n",
    "            return\n",
    "\n",
    "        metrics = {\n",
    "            \"train_loss\": epoch_loss,\n",
    "            \"train_accuracy\": epoch_acc,\n",
    "            \"learning_rate\": self._optimizer.param_groups[0][\"lr\"]\n",
    "        }\n",
    "\n",
    "        mlflow.log_metrics(metrics, step=epoch)\n",
    "\n",
    "    def _log_best_model(self, epoch_acc):\n",
    "        \"\"\"Log model if it's the best so far\"\"\"\n",
    "        if not self._use_mlflow:\n",
    "            return\n",
    "\n",
    "        # Only log current model if the accuracy is better\n",
    "        if epoch_acc <= self._best_acc:\n",
    "            return\n",
    "        # update to better accuracy\n",
    "        self._best_acc = epoch_acc\n",
    "\n",
    "        # TODO: understand this\n",
    "        sample_input = torch.randn(1, 3, 224, 224).to(self._device)\n",
    "        signature = infer_signature(\n",
    "                sample_input.cpu().numpy(),\n",
    "                self._model(sample_input).detach().cpu().numpy()\n",
    "        )\n",
    "\n",
    "        # Log the model, the first one will always log, then keep overriding for better ones\n",
    "        mlflow.pytorch.log_model(\n",
    "            self._model,\n",
    "            artifact_path=\"best_model\",\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        \"\"\"Main training loop with Mlflow integration\"\"\"\n",
    "        print(f\"Training {self._num_epochs} epochs on {self._device}\")\n",
    "        # init mlflow, new run & experiment\n",
    "        if self._use_mlflow:\n",
    "            self._setup_mlflow()\n",
    "\n",
    "        for epoch in range(self._num_epochs):\n",
    "            epoch_loss, epoch_acc = self.train_epoch(train_loader, epoch)\n",
    "            print(f\"Epoch {epoch + 1}/{self._num_epochs}: Avg Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "            # log metrics to mlflow\n",
    "            if self._use_mlflow:\n",
    "                self._log_metrics(epoch, epoch_loss, epoch_acc)\n",
    "\n",
    "            # update current best model to gcs\n",
    "            self._log_best_model(epoch_acc)\n",
    "\n"
   ],
   "id": "23dae7e494455dfc",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-20T03:08:05.960518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "m = MyEfficientNet()\n",
    "m.train(train_loader)"
   ],
   "id": "30652f01ff5c0e95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 10 epochs on mps\n",
      "Epoch 1| Batch 10 | Avg Loss  4.7456 | Accuracy: 0.0141\n",
      "Epoch 1| Batch 20 | Avg Loss  4.7258 | Accuracy: 0.0125\n",
      "Epoch 1| Batch 30 | Avg Loss  4.7079 | Accuracy: 0.0104\n",
      "Epoch 1| Batch 40 | Avg Loss  4.7405 | Accuracy: 0.0096\n",
      "Epoch 1| Batch 50 | Avg Loss  4.7180 | Accuracy: 0.0100\n",
      "Epoch 1| Batch 60 | Avg Loss  4.7022 | Accuracy: 0.0108\n",
      "Epoch 1| Batch 70 | Avg Loss  4.6790 | Accuracy: 0.0106\n",
      "Epoch 1| Batch 80 | Avg Loss  4.6644 | Accuracy: 0.0104\n",
      "Epoch 1| Batch 90 | Avg Loss  4.6611 | Accuracy: 0.0110\n",
      "Epoch 1| Batch 100 | Avg Loss  4.6538 | Accuracy: 0.0111\n",
      "Epoch 1| Batch 110 | Avg Loss  4.6555 | Accuracy: 0.0112\n",
      "Epoch 1| Batch 120 | Avg Loss  4.6201 | Accuracy: 0.0114\n",
      "Epoch 1| Batch 130 | Avg Loss  4.6528 | Accuracy: 0.0113\n",
      "Epoch 1| Batch 140 | Avg Loss  4.6436 | Accuracy: 0.0116\n",
      "Epoch 1| Batch 150 | Avg Loss  4.6219 | Accuracy: 0.0118\n",
      "Epoch 1| Batch 160 | Avg Loss  4.6340 | Accuracy: 0.0123\n",
      "Epoch 1| Batch 170 | Avg Loss  4.6357 | Accuracy: 0.0127\n",
      "Epoch 1| Batch 180 | Avg Loss  4.6114 | Accuracy: 0.0136\n",
      "Epoch 1| Batch 190 | Avg Loss  4.5776 | Accuracy: 0.0140\n",
      "Epoch 1| Batch 200 | Avg Loss  4.5808 | Accuracy: 0.0143\n",
      "Epoch 1| Batch 210 | Avg Loss  4.6044 | Accuracy: 0.0148\n",
      "Epoch 1| Batch 220 | Avg Loss  4.5799 | Accuracy: 0.0152\n",
      "Epoch 1| Batch 230 | Avg Loss  4.6017 | Accuracy: 0.0153\n",
      "Epoch 1| Batch 240 | Avg Loss  4.5836 | Accuracy: 0.0154\n",
      "Epoch 1| Batch 250 | Avg Loss  4.5639 | Accuracy: 0.0160\n",
      "Epoch 1| Batch 260 | Avg Loss  4.5815 | Accuracy: 0.0163\n",
      "Epoch 1| Batch 270 | Avg Loss  4.5407 | Accuracy: 0.0167\n",
      "Epoch 1| Batch 280 | Avg Loss  4.5640 | Accuracy: 0.0169\n",
      "Epoch 1| Batch 290 | Avg Loss  4.5417 | Accuracy: 0.0172\n",
      "Epoch 1| Batch 300 | Avg Loss  4.5445 | Accuracy: 0.0176\n",
      "Epoch 1| Batch 310 | Avg Loss  4.5298 | Accuracy: 0.0179\n",
      "Epoch 1| Batch 320 | Avg Loss  4.5424 | Accuracy: 0.0183\n",
      "Epoch 1| Batch 330 | Avg Loss  4.5312 | Accuracy: 0.0186\n",
      "Epoch 1| Batch 340 | Avg Loss  4.5225 | Accuracy: 0.0190\n",
      "Epoch 1| Batch 350 | Avg Loss  4.5373 | Accuracy: 0.0193\n",
      "Epoch 1| Batch 360 | Avg Loss  4.4978 | Accuracy: 0.0197\n",
      "Epoch 1| Batch 370 | Avg Loss  4.5032 | Accuracy: 0.0201\n",
      "Epoch 1| Batch 380 | Avg Loss  4.4836 | Accuracy: 0.0206\n",
      "Epoch 1| Batch 390 | Avg Loss  4.4624 | Accuracy: 0.0209\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T03:08:01.007985Z",
     "start_time": "2025-06-20T03:08:00.751160Z"
    }
   },
   "cell_type": "code",
   "source": "mlflow.end_run()",
   "id": "997643800eba045b",
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_DOES_NOT_EXIST: Run with id=3ff331b2f7c4469bbc19702f3ff71cf5 not found",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRestException\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[69]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmlflow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mend_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspaces/NeuralRipper/backend/.venv/lib/python3.11/site-packages/mlflow/tracking/fluent.py:519\u001B[39m, in \u001B[36mend_run\u001B[39m\u001B[34m(status)\u001B[39m\n\u001B[32m    517\u001B[39m last_active_run_id = run.info.run_id\n\u001B[32m    518\u001B[39m _last_active_run_id.set(last_active_run_id)\n\u001B[32m--> \u001B[39m\u001B[32m519\u001B[39m \u001B[43mMlflowClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mset_terminated\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlast_active_run_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    520\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m last_active_run_id \u001B[38;5;129;01min\u001B[39;00m run_id_to_system_metrics_monitor:\n\u001B[32m    521\u001B[39m     system_metrics_monitor = run_id_to_system_metrics_monitor.pop(last_active_run_id)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspaces/NeuralRipper/backend/.venv/lib/python3.11/site-packages/mlflow/tracking/client.py:3355\u001B[39m, in \u001B[36mMlflowClient.set_terminated\u001B[39m\u001B[34m(self, run_id, status, end_time)\u001B[39m\n\u001B[32m   3310\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mset_terminated\u001B[39m(\n\u001B[32m   3311\u001B[39m     \u001B[38;5;28mself\u001B[39m, run_id: \u001B[38;5;28mstr\u001B[39m, status: Optional[\u001B[38;5;28mstr\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m, end_time: Optional[\u001B[38;5;28mint\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   3312\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   3313\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Set a run's status to terminated.\u001B[39;00m\n\u001B[32m   3314\u001B[39m \n\u001B[32m   3315\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   3353\u001B[39m \n\u001B[32m   3354\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3355\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_tracking_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mset_terminated\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspaces/NeuralRipper/backend/.venv/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:1034\u001B[39m, in \u001B[36mTrackingServiceClient.set_terminated\u001B[39m\u001B[34m(self, run_id, status, end_time)\u001B[39m\n\u001B[32m   1030\u001B[39m \u001B[38;5;66;03m# Tell the store to stop async logging: stop accepting new data and log already enqueued\u001B[39;00m\n\u001B[32m   1031\u001B[39m \u001B[38;5;66;03m# data in the background. This call is making sure every async logging data has been\u001B[39;00m\n\u001B[32m   1032\u001B[39m \u001B[38;5;66;03m# submitted for logging, but not necessarily finished logging.\u001B[39;00m\n\u001B[32m   1033\u001B[39m \u001B[38;5;28mself\u001B[39m.store.shut_down_async_logging()\n\u001B[32m-> \u001B[39m\u001B[32m1034\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_log_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1035\u001B[39m \u001B[38;5;28mself\u001B[39m.store.update_run_info(\n\u001B[32m   1036\u001B[39m     run_id,\n\u001B[32m   1037\u001B[39m     run_status=RunStatus.from_string(status),\n\u001B[32m   1038\u001B[39m     end_time=end_time,\n\u001B[32m   1039\u001B[39m     run_name=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1040\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspaces/NeuralRipper/backend/.venv/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:1008\u001B[39m, in \u001B[36mTrackingServiceClient._log_url\u001B[39m\u001B[34m(self, run_id)\u001B[39m\n\u001B[32m   1006\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m host_url \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1007\u001B[39m     host_url = \u001B[38;5;28mself\u001B[39m.store.get_host_creds().host.rstrip(\u001B[33m\"\u001B[39m\u001B[33m/\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1008\u001B[39m run_info = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstore\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m.info\n\u001B[32m   1009\u001B[39m experiment_id = run_info.experiment_id\n\u001B[32m   1010\u001B[39m run_name = run_info.run_name\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspaces/NeuralRipper/backend/.venv/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:177\u001B[39m, in \u001B[36mRestStore.get_run\u001B[39m\u001B[34m(self, run_id)\u001B[39m\n\u001B[32m    167\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    168\u001B[39m \u001B[33;03mFetch the run from backend store\u001B[39;00m\n\u001B[32m    169\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    174\u001B[39m \u001B[33;03m    A single Run object if it exists, otherwise raises an Exception\u001B[39;00m\n\u001B[32m    175\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    176\u001B[39m req_body = message_to_json(GetRun(run_uuid=run_id, run_id=run_id))\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m response_proto = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_endpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mGetRun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq_body\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m Run.from_proto(response_proto.run)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspaces/NeuralRipper/backend/.venv/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:90\u001B[39m, in \u001B[36mRestStore._call_endpoint\u001B[39m\u001B[34m(self, api, json_body, endpoint)\u001B[39m\n\u001B[32m     88\u001B[39m     endpoint, method = _METHOD_TO_INFO[api]\n\u001B[32m     89\u001B[39m response_proto = api.Response()\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_endpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_host_creds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_proto\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspaces/NeuralRipper/backend/.venv/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:402\u001B[39m, in \u001B[36mcall_endpoint\u001B[39m\u001B[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001B[39m\n\u001B[32m    399\u001B[39m     call_kwargs[\u001B[33m\"\u001B[39m\u001B[33mjson\u001B[39m\u001B[33m\"\u001B[39m] = json_body\n\u001B[32m    400\u001B[39m     response = http_request(**call_kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m402\u001B[39m response = \u001B[43mverify_rest_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    403\u001B[39m response_to_parse = response.text\n\u001B[32m    404\u001B[39m js_dict = json.loads(response_to_parse)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspaces/NeuralRipper/backend/.venv/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:259\u001B[39m, in \u001B[36mverify_rest_response\u001B[39m\u001B[34m(response, endpoint)\u001B[39m\n\u001B[32m    257\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m response.status_code != \u001B[32m200\u001B[39m:\n\u001B[32m    258\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response.text):\n\u001B[32m--> \u001B[39m\u001B[32m259\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m RestException(json.loads(response.text))\n\u001B[32m    260\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    261\u001B[39m         base_msg = (\n\u001B[32m    262\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAPI request to endpoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    263\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfailed with error code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse.status_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m != 200\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    264\u001B[39m         )\n",
      "\u001B[31mRestException\u001B[39m: RESOURCE_DOES_NOT_EXIST: Run with id=3ff331b2f7c4469bbc19702f3ff71cf5 not found"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f7e6c6d373d8f8a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
