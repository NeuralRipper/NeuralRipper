{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-header",
   "metadata": {},
   "source": [
    "# GPT-2 Daily Dialog Training\n",
    "\n",
    "**Refactored notebook using training_lib**\n",
    "\n",
    "Text generation training with comprehensive MLflow tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training library\n",
    "import sys\n",
    "sys.path.append('./training_lib')\n",
    "\n",
    "from training_lib import (\n",
    "    create_model, get_conversational_data, create_conversational_dataloader,\n",
    "    UniversalTrainer, get_experiment_logger, print_model_summary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 Configuration\n",
    "CONFIG = {\n",
    "    'model_name': 'gpt2',\n",
    "    'dataset': 'blended_skill_talk',\n",
    "    'epochs': 10,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 5e-5,\n",
    "    'max_conversations': 1000,\n",
    "    'max_length': 512,\n",
    "    'use_mlflow': True\n",
    "}\n",
    "\n",
    "print(\"GPT-2 Training Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize experiment logger\n",
    "logger = get_experiment_logger(\"GPT2\", \"Conversational\")\n",
    "logger.experiment_start()\n",
    "\n",
    "# Create GPT-2 model and tokenizer\n",
    "model, tokenizer = create_model(CONFIG['model_name'], pretrained=True)\n",
    "print_model_summary(model, CONFIG['model_name'])\n",
    "\n",
    "# Load conversational data\n",
    "logger.info(\"Loading conversational dataset...\")\n",
    "conversations = get_conversational_data(\n",
    "    CONFIG['dataset'], \n",
    "    max_conversations=CONFIG['max_conversations']\n",
    ")\n",
    "\n",
    "# Create data loader\n",
    "train_loader = create_conversational_dataloader(\n",
    "    conversations,\n",
    "    tokenizer,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    max_length=CONFIG['max_length']\n",
    ")\n",
    "\n",
    "logger.data_loaded(len(conversations))\n",
    "print(f\"\\nDataset: {len(conversations):,} conversations, {len(train_loader)} batches\")\n",
    "if conversations:\n",
    "    print(f\"Sample: {conversations[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer for text generation\n",
    "trainer = UniversalTrainer(\n",
    "    model=model,\n",
    "    model_name=\"GPT2\",\n",
    "    dataset_name=\"Conversational\",\n",
    "    epochs=CONFIG['epochs'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    optimizer_name=\"AdamW\",\n",
    "    use_mlflow=CONFIG['use_mlflow'],\n",
    "    tokenizer=tokenizer,\n",
    "    input_size='max_length_512',\n",
    "    use_pretrained=True,\n",
    "    train_size=len(conversations)\n",
    ")\n",
    "\n",
    "# Start training\n",
    "logger.info(\"Starting GPT-2 conversational training...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" STARTING GPT-2 TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = trainer.train(train_loader)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" GPT-2 TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "if summary:\n",
    "    print(\"\\nGPT-2 TRAINING SUMMARY:\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Status: {summary.get('status', 'Unknown')}\")\n",
    "    print(f\"Total Time: {summary.get('total_time_minutes', 0):.1f} minutes\")\n",
    "    print(f\"Best Token Accuracy: {summary.get('best_accuracy', 0):.4f}\")\n",
    "    print(f\"Best Loss: {summary.get('best_loss', float('inf')):.4f}\")\n",
    "    print(f\"Epochs: {summary.get('epochs_completed', 0)}/{CONFIG['epochs']}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "logger.info(\"GPT-2 conversational training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuralRipper (GPU)",
   "language": "python",
   "name": "neuralripper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
