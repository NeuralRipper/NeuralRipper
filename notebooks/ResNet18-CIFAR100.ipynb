{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ggWf9vEG2G-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28384,
     "status": "ok",
     "timestamp": 1752032437012,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "2ggWf9vEG2G-",
    "outputId": "6805092d-2ea7-47b2-d4a8-79216c2b2d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (3.1.1)\n",
      "Requirement already satisfied: mlflow-skinny==3.1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: Flask<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.16.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.10.3)\n",
      "Requirement already satisfied: numpy<3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.2.6)\n",
      "Requirement already satisfied: pandas<3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.3.0)\n",
      "Requirement already satisfied: pyarrow<21,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (20.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.7.0)\n",
      "Requirement already satisfied: scipy<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.16.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.0.41)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.57.0)\n",
      "Requirement already satisfied: fastapi<1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.115.14)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (1.34.1)\n",
      "Requirement already satisfied: packaging<26 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (25.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.1)\n",
      "Requirement already satisfied: uvicorn<1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.35.0)\n",
      "Requirement already satisfied: Mako in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.40.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.46.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (0.55b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import platform\n",
    "import psutil\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "urSU2kGpG2Ev",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752032437016,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "urSU2kGpG2Ev"
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "format = '%(asctime)s - %(levelname)s - %(filename)s - PID:%(process)d - TID:%(thread)d - %(message)s'\n",
    "logger = logging.getLogger(__name__ + str(time.time()))\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False\n",
    "\n",
    "# Add handler if none exists\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(format))\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ybWcfyuG2Co",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10335,
     "status": "ok",
     "timestamp": 1752032447352,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "1ybWcfyuG2Co",
    "outputId": "e9cd40a4-1969-4734-d3c4-79aeaeb3c2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Number of classes: 100\n",
      "Class names (first 10): ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']\n"
     ]
    }
   ],
   "source": [
    "# Data transforms for CIFAR-100\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Data augmentation\n",
    "    transforms.RandomHorizontalFlip(0.5),   # Random horizontal flip\n",
    "    transforms.ToTensor(),                  # Convert to tensor\n",
    "    transforms.Normalize(                   # Normalize with ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "train_ds = datasets.CIFAR100(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_tf\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {len(train_ds)}\")\n",
    "print(f\"Number of classes: {len(train_ds.classes)}\")\n",
    "print(f\"Class names (first 10): {train_ds.classes[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "FFBn09-QG2AV",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752032447356,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "FFBn09-QG2AV"
   },
   "outputs": [],
   "source": [
    "# Optional: Visualize a sample of the data\n",
    "def visualize_samples(dataset, num_samples=16):\n",
    "    \"\"\"Visualize a sample of images from the dataset\"\"\"\n",
    "    # Create subset for visualization\n",
    "    sample_indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img_tensor, class_idx = dataset[idx]\n",
    "\n",
    "        # Denormalize image for display\n",
    "        img = img_tensor.permute(1, 2, 0)\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Class: {dataset.classes[class_idx]}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to visualize samples\n",
    "# visualize_samples(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oMNMArItG1-A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752032447361,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "oMNMArItG1-A",
    "outputId": "ec25a78f-703e-4e58-8381-3576f5798d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per epoch: 391\n",
      "Total samples per epoch: 50048\n"
     ]
    }
   ],
   "source": [
    "# Create data loader\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,      # Set to 0 for MPS compatibility\n",
    "    pin_memory=False    # Disable for MPS\n",
    ")\n",
    "\n",
    "print(f\"Number of batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Total samples per epoch: {len(train_loader) * 128}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3pz1kG53G170",
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1752032447485,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "3pz1kG53G170"
   },
   "outputs": [],
   "source": [
    "class ComprehensiveTrainingMonitor:\n",
    "    \"\"\"Enhanced training monitor with MLflow integration and comprehensive metrics\"\"\"\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device, model_name='ResNet18',\n",
    "                 dataset_name='CIFAR-100', batch_size=128, epochs=100,\n",
    "                 input_size=(3, 32, 32), use_mlflow=True,\n",
    "                 learning_rate=5e-3, use_pretrained=True, train_size=50000,\n",
    "                 val_size=10000, num_workers=0):\n",
    "\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        self.dataset_name = dataset_name\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.input_size = input_size\n",
    "        self.use_mlflow = use_mlflow\n",
    "        self.learning_rate = learning_rate\n",
    "        self.use_pretrained = use_pretrained\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        # Tracking variables\n",
    "        self.best_metric = float('-inf')\n",
    "        self.epoch_times = []\n",
    "        self.start_time = time.time()\n",
    "        self.run_started = False\n",
    "\n",
    "        # MLflow configuration\n",
    "        self.mlflow_uri = \"https://neuralripper.com/mlflow/\"\n",
    "        self.gcs_bucket = \"gs://neuralripper-mlflow-artifacts\"\n",
    "\n",
    "        if self.use_mlflow:\n",
    "            self._initialize_mlflow()\n",
    "\n",
    "    def _initialize_mlflow(self):\n",
    "        \"\"\"Initialize MLflow with comprehensive experiment tracking\"\"\"\n",
    "        try:\n",
    "            mlflow.set_tracking_uri(self.mlflow_uri)\n",
    "            mlflow.set_experiment(f\"{self.model_name}-{self.dataset_name}\")\n",
    "\n",
    "            # Start run with timestamp\n",
    "            run_name = f\"{self.model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "            mlflow.start_run(run_name=run_name)\n",
    "            self.run_started = True\n",
    "\n",
    "            # Log all parameters\n",
    "            params = {\n",
    "                **self._get_model_params(),\n",
    "                **self._get_system_params(),\n",
    "                **self._get_environment_params(),\n",
    "                **self._get_data_params(),\n",
    "                **self._get_training_params(),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(params)\n",
    "            logger.info(f\"MLflow run started: {run_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to initialize MLflow: {e}\")\n",
    "            self.use_mlflow = False\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Model architecture and hyperparameters\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"model_type\": \"classification\",\n",
    "            \"pretrained\": self.use_pretrained,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"optimizer\": self.optimizer.__class__.__name__,\n",
    "            \"criterion\": self.criterion.__class__.__name__,\n",
    "            \"input_channels\": self.input_size[0],\n",
    "            \"input_height\": self.input_size[1],\n",
    "            \"input_width\": self.input_size[2],\n",
    "        }\n",
    "\n",
    "    def _get_system_params(self):\n",
    "        \"\"\"System hardware and software parameters\"\"\"\n",
    "        gpu_info = {}\n",
    "        if torch.cuda.is_available():\n",
    "            props = torch.cuda.get_device_properties(0)\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": torch.cuda.get_device_name(0),\n",
    "                \"gpu_memory_gb\": round(props.total_memory / (1024**3), 2),\n",
    "                \"cuda_version\": torch.version.cuda,\n",
    "                \"num_gpus\": torch.cuda.device_count(),\n",
    "            }\n",
    "        elif torch.backends.mps.is_available():\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": \"Apple Silicon MPS\",\n",
    "                \"device_type\": \"mps\"\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"cpu_count\": psutil.cpu_count(),\n",
    "            \"memory_total_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"python_version\": platform.python_version(),\n",
    "            \"pytorch_version\": torch.__version__,\n",
    "            **gpu_info\n",
    "        }\n",
    "\n",
    "    def _get_environment_params(self):\n",
    "        \"\"\"Environment and reproducibility parameters\"\"\"\n",
    "        git_info = {}\n",
    "        try:\n",
    "            commit = subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip()\n",
    "            branch = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD']).decode().strip()\n",
    "            git_info = {\n",
    "                \"git_commit\": commit[:8],\n",
    "                \"git_branch\": branch,\n",
    "            }\n",
    "        except:\n",
    "            git_info = {\"git_commit\": \"unknown\", \"git_branch\": \"unknown\"}\n",
    "\n",
    "        return git_info\n",
    "\n",
    "    def _get_data_params(self):\n",
    "        \"\"\"Data pipeline parameters\"\"\"\n",
    "        return {\n",
    "            \"train_size\": self.train_size,\n",
    "            \"val_size\": self.val_size,\n",
    "            \"total_samples\": self.train_size + self.val_size,\n",
    "            \"num_workers\": self.num_workers,\n",
    "        }\n",
    "\n",
    "    def _get_training_params(self):\n",
    "        \"\"\"Advanced training configuration\"\"\"\n",
    "        return {\n",
    "            \"mlflow_uri\": self.mlflow_uri,\n",
    "            \"experiment_name\": f\"{self.model_name}-{self.dataset_name}\",\n",
    "        }\n",
    "\n",
    "    def log_epoch_metrics(self, epoch, epoch_loss, epoch_acc, batch_count=None):\n",
    "        \"\"\"Comprehensive epoch metrics logging\"\"\"\n",
    "        if not self.use_mlflow or not self.run_started:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            epoch_time = self.epoch_times[-1] if self.epoch_times else 0\n",
    "\n",
    "            # Core metrics\n",
    "            metrics = {\n",
    "                \"train_loss\": epoch_loss,\n",
    "                \"train_accuracy\": epoch_acc,\n",
    "                \"epoch_time_seconds\": epoch_time,\n",
    "                \"learning_rate\": self.optimizer.param_groups[0]['lr'],\n",
    "            }\n",
    "\n",
    "            # Performance metrics\n",
    "            if batch_count:\n",
    "                metrics[\"batches_per_second\"] = batch_count / epoch_time if epoch_time > 0 else 0\n",
    "                metrics[\"samples_per_second\"] = (batch_count * self.batch_size) / epoch_time if epoch_time > 0 else 0\n",
    "\n",
    "            # Memory metrics\n",
    "            if torch.cuda.is_available():\n",
    "                metrics[\"gpu_memory_allocated_gb\"] = torch.cuda.memory_allocated() / (1024**3)\n",
    "                metrics[\"gpu_memory_reserved_gb\"] = torch.cuda.memory_reserved() / (1024**3)\n",
    "\n",
    "            # Running statistics\n",
    "            total_time = sum(self.epoch_times)\n",
    "            metrics[\"total_time_minutes\"] = total_time / 60\n",
    "            metrics[\"average_epoch_time\"] = np.mean(self.epoch_times) if self.epoch_times else 0\n",
    "\n",
    "            mlflow.log_metrics(metrics, step=epoch)\n",
    "\n",
    "            # Update best model if improved\n",
    "            if epoch_acc > self.best_metric:\n",
    "                self.best_metric = epoch_acc\n",
    "                self._log_model_checkpoint(epoch)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log metrics for epoch {epoch}: {e}\")\n",
    "\n",
    "    def _log_model_checkpoint(self, epoch):\n",
    "        \"\"\"Log model checkpoint and metadata\"\"\"\n",
    "        try:\n",
    "            # Log the model\n",
    "            mlflow.pytorch.log_model(\n",
    "                self.model,\n",
    "                artifact_path=\"model\",\n",
    "                registered_model_name=f\"{self.model_name}-{self.dataset_name}\",\n",
    "                pip_requirements=[\"torch\", \"torchvision\", \"pillow\", \"numpy\"]\n",
    "            )\n",
    "\n",
    "            # Log additional metadata\n",
    "            model_metadata = {\n",
    "                \"best_epoch\": epoch,\n",
    "                \"best_accuracy\": self.best_metric,\n",
    "                \"checkpoint_time\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(model_metadata)\n",
    "            logger.info(f\"Model metadata logged for accuracy: {self.best_metric:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log model metadata: {e}\")\n",
    "\n",
    "    def end_run(self, status=\"FINISHED\"):\n",
    "        \"\"\"Clean up and end MLflow run\"\"\"\n",
    "        if self.use_mlflow and self.run_started:\n",
    "            try:\n",
    "                total_time = time.time() - self.start_time\n",
    "                summary = {\n",
    "                    \"final_total_training_time_minutes\": round(total_time / 60, 2),\n",
    "                    \"final_best_accuracy\": self.best_metric,\n",
    "                    \"final_epochs_completed\": len(self.epoch_times),\n",
    "                }\n",
    "                mlflow.log_params(summary)\n",
    "                mlflow.end_run(status=status)\n",
    "                self.run_started = False\n",
    "                return summary\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to end MLflow run properly: {e}\")\n",
    "                return {}\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "J_Cn29LwG15g",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752032447493,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "J_Cn29LwG15g"
   },
   "outputs": [],
   "source": [
    "class EnhancedResNet18:\n",
    "    \"\"\"ResNet18 with comprehensive monitoring integration\"\"\"\n",
    "\n",
    "    def __init__(self, num_epochs=100, batch_size=128, num_classes=100,\n",
    "                 learning_rate=5e-3, use_mlflow=True):\n",
    "        # Core parameters\n",
    "        self._num_classes = num_classes\n",
    "        self._use_mlflow = use_mlflow\n",
    "        self._batch_size = batch_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        # Create model components\n",
    "        self._model = self._create_model()\n",
    "        self._device = self._set_device()\n",
    "        self._model.to(self._device)\n",
    "        self._criterion = self._set_criterion()\n",
    "        self._optimizer = self._set_optimizer()\n",
    "\n",
    "        # Initialize comprehensive monitor\n",
    "        self.monitor = ComprehensiveTrainingMonitor(\n",
    "            model=self._model,\n",
    "            optimizer=self._optimizer,\n",
    "            criterion=self._criterion,\n",
    "            device=self._device,\n",
    "            model_name='ResNet18',\n",
    "            dataset_name='CIFAR-100',\n",
    "            batch_size=batch_size,\n",
    "            epochs=num_epochs,\n",
    "            input_size=(3, 32, 32),\n",
    "            learning_rate=learning_rate,\n",
    "            use_mlflow=use_mlflow,\n",
    "            use_pretrained=True,\n",
    "            train_size=50000,\n",
    "            val_size=10000,\n",
    "            num_workers=0,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Model initialized on device: {self._device}\")\n",
    "        logger.info(f\"Model parameters: {sum(p.numel() for p in self._model.parameters()):,}\")\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Create ResNet18 model with CIFAR-100 adaptation\"\"\"\n",
    "        model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        # Adapt classifier for CIFAR-100 (100 classes)\n",
    "        model.fc = nn.Linear(model.fc.in_features, self._num_classes)\n",
    "        return model\n",
    "\n",
    "    def _set_device(self):\n",
    "        \"\"\"Set appropriate device for training\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def _set_optimizer(self):\n",
    "        \"\"\"Configure SGD optimizer with momentum and weight decay\"\"\"\n",
    "        return optim.SGD(self._model.parameters(),\n",
    "                        lr=self._learning_rate,\n",
    "                        momentum=0.9,\n",
    "                        weight_decay=4e-5)\n",
    "\n",
    "    def _set_criterion(self):\n",
    "        \"\"\"Set loss function for classification\"\"\"\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    def train_epoch(self, data_loader, epoch_idx):\n",
    "        \"\"\"Enhanced training epoch with comprehensive monitoring\"\"\"\n",
    "        logger.info(f\"Starting epoch {epoch_idx+1}, total batches: {len(data_loader)}\")\n",
    "\n",
    "        self._model.train()\n",
    "        epoch_total_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "        batch_count = len(data_loader)\n",
    "\n",
    "        for idx, (images, targets) in enumerate(data_loader):\n",
    "            images = images.to(self._device)\n",
    "            targets = targets.to(self._device)\n",
    "\n",
    "            self._optimizer.zero_grad()\n",
    "            logits = self._model(images)\n",
    "            loss = self._criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            running_correct += (predictions == targets).sum().item()\n",
    "            running_total += targets.size(0)\n",
    "            running_loss += loss.item()\n",
    "            epoch_total_loss += loss.item()\n",
    "\n",
    "            # Log progress every 10 batches\n",
    "            if idx % 10 == 9:\n",
    "                avg_loss = running_loss / 10\n",
    "                acc_sofar = running_correct / running_total\n",
    "                logger.info(f\"Epoch {epoch_idx+1} | Batch {idx+1}/{batch_count} | \"\n",
    "                          f\"Loss {avg_loss:.4f} | Acc {acc_sofar:.4f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = epoch_total_loss / batch_count\n",
    "        epoch_acc = running_correct / running_total\n",
    "\n",
    "        logger.info(f\"Epoch {epoch_idx+1} completed | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    def train(self, data_loader):\n",
    "        \"\"\"Full training loop with comprehensive monitoring\"\"\"\n",
    "        logger.info(\"Starting training process\")\n",
    "\n",
    "        try:\n",
    "            for epoch in range(self._num_epochs):\n",
    "                epoch_start = time.time()\n",
    "\n",
    "                # Train for one epoch\n",
    "                epoch_loss, epoch_acc = self.train_epoch(data_loader, epoch)\n",
    "\n",
    "                # Track timing\n",
    "                epoch_time = time.time() - epoch_start\n",
    "                self.monitor.epoch_times.append(epoch_time)\n",
    "\n",
    "                # Log metrics\n",
    "                self.monitor.log_epoch_metrics(epoch, epoch_loss, epoch_acc, len(data_loader))\n",
    "\n",
    "                # Progress report\n",
    "                eta = np.mean(self.monitor.epoch_times) * (self._num_epochs - epoch - 1)\n",
    "                logger.info(f\"Epoch {epoch+1}/{self._num_epochs} | \"\n",
    "                          f\"Time: {epoch_time:.1f}s | ETA: {eta/60:.1f}min\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            logger.info(\"Training interrupted by user\")\n",
    "            summary = self.monitor.end_run(status=\"KILLED\")\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training failed with error: {e}\")\n",
    "            summary = self.monitor.end_run(status=\"FAILED\")\n",
    "            raise e\n",
    "\n",
    "        # Training completed\n",
    "        summary = self.monitor.end_run(status=\"FINISHED\")\n",
    "        logger.info(f\"Training completed. Summary: {summary}\")\n",
    "\n",
    "        if summary:\n",
    "            print(f\"\\nTraining Summary:\")\n",
    "            print(f\"Total time: {summary.get('final_total_training_time_minutes', 0):.1f} minutes\")\n",
    "            print(f\"Best accuracy: {summary.get('final_best_accuracy', 0):.4f}\")\n",
    "            print(f\"Epochs completed: {summary.get('final_epochs_completed', 0)}\")\n",
    "\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dscyqDcSG13Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4360,
     "status": "ok",
     "timestamp": 1752032451857,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "dscyqDcSG13Y",
    "outputId": "49b47bc4-6282-474f-afb6-9a16e35da61c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 17:41:37,049 - INFO - 2730644991.py - PID:35199 - TID:8462606080 - Initializing Enhanced ResNet18 model\n",
      "2025-07-27 17:41:38,181 - INFO - 1164146881.py - PID:35199 - TID:8462606080 - MLflow run started: ResNet18_20250727_174137\n",
      "2025-07-27 17:41:38,182 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Model initialized on device: mps\n",
      "2025-07-27 17:41:38,183 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Model parameters: 11,227,812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully!\n",
      "Device: mps\n",
      "Total parameters: 11,227,812\n",
      "Trainable parameters: 11,227,812\n"
     ]
    }
   ],
   "source": [
    "# Clear any existing MLflow runs\n",
    "import mlflow\n",
    "\n",
    "# End any active runs\n",
    "if mlflow.active_run():\n",
    "    print(f\"Ending active run: {mlflow.active_run().info.run_id}\")\n",
    "    mlflow.end_run()\n",
    "    print(\"Active run ended\")\n",
    "else:\n",
    "    print(\"No active runs to clear\")\n",
    "\n",
    "# Verify no active runs\n",
    "print(f\"Active run after cleanup: {mlflow.active_run()}\")\n",
    "\n",
    "# Initialize and train the model\n",
    "logger.info(\"Initializing Enhanced ResNet18 model\")\n",
    "\n",
    "model = EnhancedResNet18(\n",
    "    num_epochs=15,\n",
    "    batch_size=128,\n",
    "    num_classes=100,\n",
    "    learning_rate=5e-3,\n",
    "    use_mlflow=True\n",
    ")\n",
    "\n",
    "print(\"Model initialized successfully!\")\n",
    "print(f\"Device: {model._device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model._model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model._model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "W7KCg0BcG1xW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1177153,
     "status": "ok",
     "timestamp": 1752033629012,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "W7KCg0BcG1xW",
    "outputId": "49417a52-6e5a-4205-e45a-d57a3cd35ec8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 17:41:40,428 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting training process\n",
      "2025-07-27 17:41:40,429 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 1, total batches: 391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " STARTING ENHANCED RESNET18 TRAINING\n",
      "==================================================\n",
      "Dataset: CIFAR-100 (100 classes)\n",
      "Model: ResNet18 (pretrained)\n",
      "Epochs: 15\n",
      "Batch size: 128\n",
      "Learning rate: 0.005\n",
      "MLflow tracking: Enabled\n",
      "MLflow URI: https://neuralripper.com/mlflow/\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 17:41:41,862 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 10/391 | Loss 4.8242 | Acc 0.0242\n",
      "2025-07-27 17:41:42,419 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 20/391 | Loss 4.4231 | Acc 0.0422\n",
      "2025-07-27 17:41:43,025 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 30/391 | Loss 4.1960 | Acc 0.0563\n",
      "2025-07-27 17:41:43,689 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 40/391 | Loss 3.8494 | Acc 0.0762\n",
      "2025-07-27 17:41:44,409 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 50/391 | Loss 3.6127 | Acc 0.0966\n",
      "2025-07-27 17:41:45,135 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 60/391 | Loss 3.4384 | Acc 0.1121\n",
      "2025-07-27 17:41:45,826 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 70/391 | Loss 3.3352 | Acc 0.1240\n",
      "2025-07-27 17:41:46,494 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 80/391 | Loss 3.2092 | Acc 0.1361\n",
      "2025-07-27 17:41:47,154 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 90/391 | Loss 3.1607 | Acc 0.1471\n",
      "2025-07-27 17:41:47,798 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 100/391 | Loss 3.1311 | Acc 0.1560\n",
      "2025-07-27 17:41:48,491 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 110/391 | Loss 2.9719 | Acc 0.1644\n",
      "2025-07-27 17:41:49,200 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 120/391 | Loss 2.8581 | Acc 0.1742\n",
      "2025-07-27 17:41:49,982 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 130/391 | Loss 2.8191 | Acc 0.1820\n",
      "2025-07-27 17:41:50,777 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 140/391 | Loss 2.8208 | Acc 0.1902\n",
      "2025-07-27 17:41:51,713 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 150/391 | Loss 2.7956 | Acc 0.1966\n",
      "2025-07-27 17:41:52,642 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 160/391 | Loss 2.7237 | Acc 0.2029\n",
      "2025-07-27 17:41:53,509 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 170/391 | Loss 2.7032 | Acc 0.2086\n",
      "2025-07-27 17:41:54,489 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 180/391 | Loss 2.6670 | Acc 0.2140\n",
      "2025-07-27 17:41:55,297 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 190/391 | Loss 2.6188 | Acc 0.2197\n",
      "2025-07-27 17:41:56,054 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 200/391 | Loss 2.6004 | Acc 0.2249\n",
      "2025-07-27 17:41:56,787 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 210/391 | Loss 2.6556 | Acc 0.2295\n",
      "2025-07-27 17:41:57,576 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 220/391 | Loss 2.5663 | Acc 0.2347\n",
      "2025-07-27 17:41:58,425 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 230/391 | Loss 2.5328 | Acc 0.2395\n",
      "2025-07-27 17:41:59,287 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 240/391 | Loss 2.4359 | Acc 0.2453\n",
      "2025-07-27 17:42:00,178 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 250/391 | Loss 2.5620 | Acc 0.2491\n",
      "2025-07-27 17:42:01,010 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 260/391 | Loss 2.5481 | Acc 0.2529\n",
      "2025-07-27 17:42:01,804 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 270/391 | Loss 2.4008 | Acc 0.2573\n",
      "2025-07-27 17:42:02,549 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 280/391 | Loss 2.3643 | Acc 0.2618\n",
      "2025-07-27 17:42:03,328 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 290/391 | Loss 2.4435 | Acc 0.2655\n",
      "2025-07-27 17:42:04,041 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 300/391 | Loss 2.3310 | Acc 0.2687\n",
      "2025-07-27 17:42:04,738 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 310/391 | Loss 2.4113 | Acc 0.2727\n",
      "2025-07-27 17:42:05,426 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 320/391 | Loss 2.4410 | Acc 0.2754\n",
      "2025-07-27 17:42:06,162 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 330/391 | Loss 2.3943 | Acc 0.2789\n",
      "2025-07-27 17:42:06,824 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 340/391 | Loss 2.4104 | Acc 0.2814\n",
      "2025-07-27 17:42:07,403 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 350/391 | Loss 2.3979 | Acc 0.2837\n",
      "2025-07-27 17:42:07,993 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 360/391 | Loss 2.4079 | Acc 0.2862\n",
      "2025-07-27 17:42:08,646 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 370/391 | Loss 2.3254 | Acc 0.2889\n",
      "2025-07-27 17:42:09,363 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 380/391 | Loss 2.2953 | Acc 0.2918\n",
      "2025-07-27 17:42:10,492 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 390/391 | Loss 2.2367 | Acc 0.2948\n",
      "2025-07-27 17:42:11,036 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 completed | Loss: 2.8427 | Acc: 0.2949\n",
      "2025/07/27 17:42:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:42:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'ResNet18-CIFAR-100'.\n",
      "2025/07/27 17:42:22 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 1\n",
      "Created version '1' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:42:23,547 - INFO - 1164146881.py - PID:35199 - TID:8462606080 - Model metadata logged for accuracy: 0.2949\n",
      "2025-07-27 17:42:23,548 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1/15 | Time: 30.6s | ETA: 7.1min\n",
      "2025-07-27 17:42:23,549 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 2, total batches: 391\n",
      "2025-07-27 17:42:24,311 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 10/391 | Loss 2.1369 | Acc 0.4219\n",
      "2025-07-27 17:42:25,232 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 20/391 | Loss 2.1380 | Acc 0.4184\n",
      "2025-07-27 17:42:26,421 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 30/391 | Loss 2.1817 | Acc 0.4216\n",
      "2025-07-27 17:42:27,469 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 40/391 | Loss 2.1278 | Acc 0.4266\n",
      "2025-07-27 17:42:28,409 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 50/391 | Loss 2.0911 | Acc 0.4270\n",
      "2025-07-27 17:42:29,347 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 60/391 | Loss 2.0663 | Acc 0.4315\n",
      "2025-07-27 17:42:30,264 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 70/391 | Loss 2.1827 | Acc 0.4280\n",
      "2025-07-27 17:42:31,205 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 80/391 | Loss 2.1714 | Acc 0.4278\n",
      "2025-07-27 17:42:32,185 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 90/391 | Loss 2.1047 | Acc 0.4285\n",
      "2025-07-27 17:42:33,141 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 100/391 | Loss 2.0873 | Acc 0.4308\n",
      "2025-07-27 17:42:34,081 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 110/391 | Loss 2.1573 | Acc 0.4305\n",
      "2025-07-27 17:42:35,074 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 120/391 | Loss 2.0902 | Acc 0.4307\n",
      "2025-07-27 17:42:36,070 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 130/391 | Loss 2.0569 | Acc 0.4311\n",
      "2025-07-27 17:42:37,616 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 140/391 | Loss 2.0747 | Acc 0.4312\n",
      "2025-07-27 17:42:38,896 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 150/391 | Loss 1.9934 | Acc 0.4329\n",
      "2025-07-27 17:42:40,052 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 160/391 | Loss 2.0483 | Acc 0.4338\n",
      "2025-07-27 17:42:41,150 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 170/391 | Loss 2.1494 | Acc 0.4329\n",
      "2025-07-27 17:42:42,204 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 180/391 | Loss 2.0537 | Acc 0.4326\n",
      "2025-07-27 17:42:43,243 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 190/391 | Loss 2.0570 | Acc 0.4323\n",
      "2025-07-27 17:42:44,310 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 200/391 | Loss 2.0965 | Acc 0.4324\n",
      "2025-07-27 17:42:45,304 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 210/391 | Loss 2.0000 | Acc 0.4335\n",
      "2025-07-27 17:42:46,447 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 220/391 | Loss 2.0487 | Acc 0.4344\n",
      "2025-07-27 17:42:47,323 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 230/391 | Loss 2.1453 | Acc 0.4343\n",
      "2025-07-27 17:42:48,108 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 240/391 | Loss 2.0311 | Acc 0.4351\n",
      "2025-07-27 17:42:48,858 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 250/391 | Loss 2.0245 | Acc 0.4357\n",
      "2025-07-27 17:42:49,593 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 260/391 | Loss 2.0328 | Acc 0.4359\n",
      "2025-07-27 17:42:50,324 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 270/391 | Loss 2.0562 | Acc 0.4357\n",
      "2025-07-27 17:42:51,064 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 280/391 | Loss 2.0316 | Acc 0.4362\n",
      "2025-07-27 17:42:51,816 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 290/391 | Loss 2.0299 | Acc 0.4374\n",
      "2025-07-27 17:42:52,563 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 300/391 | Loss 1.9900 | Acc 0.4382\n",
      "2025-07-27 17:42:53,323 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 310/391 | Loss 2.0477 | Acc 0.4386\n",
      "2025-07-27 17:42:54,088 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 320/391 | Loss 2.0543 | Acc 0.4385\n",
      "2025-07-27 17:42:54,934 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 330/391 | Loss 2.0359 | Acc 0.4388\n",
      "2025-07-27 17:42:55,764 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 340/391 | Loss 1.9555 | Acc 0.4397\n",
      "2025-07-27 17:42:56,624 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 350/391 | Loss 1.9973 | Acc 0.4404\n",
      "2025-07-27 17:42:57,540 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 360/391 | Loss 1.9870 | Acc 0.4410\n",
      "2025-07-27 17:42:58,557 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 370/391 | Loss 1.9261 | Acc 0.4418\n",
      "2025-07-27 17:42:59,660 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 380/391 | Loss 2.0530 | Acc 0.4419\n",
      "2025-07-27 17:43:00,730 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 | Batch 390/391 | Loss 2.0189 | Acc 0.4419\n",
      "2025-07-27 17:43:00,854 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2 completed | Loss: 2.0644 | Acc: 0.4420\n",
      "2025/07/27 17:43:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:43:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:43:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 2\n",
      "Created version '2' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:43:10,949 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '1'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.44204'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:43:10.779126'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:43:10,951 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 2/15 | Time: 37.3s | ETA: 7.4min\n",
      "2025-07-27 17:43:10,951 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 3, total batches: 391\n",
      "2025-07-27 17:43:11,522 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 10/391 | Loss 1.8543 | Acc 0.4820\n",
      "2025-07-27 17:43:12,051 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 20/391 | Loss 1.8313 | Acc 0.4930\n",
      "2025-07-27 17:43:12,581 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 30/391 | Loss 1.7098 | Acc 0.4997\n",
      "2025-07-27 17:43:13,113 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 40/391 | Loss 1.7766 | Acc 0.5016\n",
      "2025-07-27 17:43:13,643 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 50/391 | Loss 1.8157 | Acc 0.4972\n",
      "2025-07-27 17:43:14,175 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 60/391 | Loss 1.8807 | Acc 0.4953\n",
      "2025-07-27 17:43:14,710 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 70/391 | Loss 1.8123 | Acc 0.4963\n",
      "2025-07-27 17:43:15,250 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 80/391 | Loss 1.8347 | Acc 0.4936\n",
      "2025-07-27 17:43:15,789 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 90/391 | Loss 1.8713 | Acc 0.4931\n",
      "2025-07-27 17:43:16,339 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 100/391 | Loss 1.7507 | Acc 0.4947\n",
      "2025-07-27 17:43:16,910 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 110/391 | Loss 1.7739 | Acc 0.4962\n",
      "2025-07-27 17:43:17,612 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 120/391 | Loss 1.8254 | Acc 0.4959\n",
      "2025-07-27 17:43:19,034 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 130/391 | Loss 1.7833 | Acc 0.4967\n",
      "2025-07-27 17:43:20,100 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 140/391 | Loss 1.8338 | Acc 0.4968\n",
      "2025-07-27 17:43:21,007 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 150/391 | Loss 1.8505 | Acc 0.4962\n",
      "2025-07-27 17:43:21,930 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 160/391 | Loss 1.7042 | Acc 0.4986\n",
      "2025-07-27 17:43:22,833 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 170/391 | Loss 1.8512 | Acc 0.4983\n",
      "2025-07-27 17:43:23,784 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 180/391 | Loss 1.8021 | Acc 0.4989\n",
      "2025-07-27 17:43:24,690 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 190/391 | Loss 1.9224 | Acc 0.4966\n",
      "2025-07-27 17:43:25,670 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 200/391 | Loss 1.8392 | Acc 0.4959\n",
      "2025-07-27 17:43:26,663 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 210/391 | Loss 1.9179 | Acc 0.4946\n",
      "2025-07-27 17:43:27,508 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 220/391 | Loss 1.7497 | Acc 0.4948\n",
      "2025-07-27 17:43:28,336 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 230/391 | Loss 1.7029 | Acc 0.4962\n",
      "2025-07-27 17:43:29,155 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 240/391 | Loss 1.7873 | Acc 0.4965\n",
      "2025-07-27 17:43:30,031 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 250/391 | Loss 1.8737 | Acc 0.4959\n",
      "2025-07-27 17:43:30,929 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 260/391 | Loss 1.7397 | Acc 0.4970\n",
      "2025-07-27 17:43:31,813 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 270/391 | Loss 1.7742 | Acc 0.4973\n",
      "2025-07-27 17:43:32,666 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 280/391 | Loss 1.8679 | Acc 0.4975\n",
      "2025-07-27 17:43:33,518 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 290/391 | Loss 1.8104 | Acc 0.4977\n",
      "2025-07-27 17:43:34,365 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 300/391 | Loss 1.7641 | Acc 0.4982\n",
      "2025-07-27 17:43:35,178 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 310/391 | Loss 1.7935 | Acc 0.4980\n",
      "2025-07-27 17:43:35,996 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 320/391 | Loss 1.7018 | Acc 0.4989\n",
      "2025-07-27 17:43:36,829 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 330/391 | Loss 1.7955 | Acc 0.4989\n",
      "2025-07-27 17:43:37,669 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 340/391 | Loss 1.8103 | Acc 0.4995\n",
      "2025-07-27 17:43:38,504 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 350/391 | Loss 1.8173 | Acc 0.4994\n",
      "2025-07-27 17:43:39,338 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 360/391 | Loss 1.8084 | Acc 0.4995\n",
      "2025-07-27 17:43:40,354 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 370/391 | Loss 1.7821 | Acc 0.4999\n",
      "2025-07-27 17:43:41,397 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 380/391 | Loss 1.7386 | Acc 0.5004\n",
      "2025-07-27 17:43:42,404 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 | Batch 390/391 | Loss 1.8004 | Acc 0.5004\n",
      "2025-07-27 17:43:42,477 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3 completed | Loss: 1.8038 | Acc: 0.5003\n",
      "2025/07/27 17:43:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:43:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:43:51 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 3\n",
      "Created version '3' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:43:52,245 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '2'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.50034'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:43:52.071479'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:43:52,246 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 3/15 | Time: 31.5s | ETA: 6.6min\n",
      "2025-07-27 17:43:52,247 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 4, total batches: 391\n",
      "2025-07-27 17:43:52,902 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 10/391 | Loss 1.6714 | Acc 0.5258\n",
      "2025-07-27 17:43:53,428 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 20/391 | Loss 1.6796 | Acc 0.5309\n",
      "2025-07-27 17:43:53,955 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 30/391 | Loss 1.5980 | Acc 0.5318\n",
      "2025-07-27 17:43:54,486 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 40/391 | Loss 1.6280 | Acc 0.5365\n",
      "2025-07-27 17:43:55,016 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 50/391 | Loss 1.5559 | Acc 0.5402\n",
      "2025-07-27 17:43:55,551 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 60/391 | Loss 1.5434 | Acc 0.5426\n",
      "2025-07-27 17:43:56,089 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 70/391 | Loss 1.6479 | Acc 0.5423\n",
      "2025-07-27 17:43:56,624 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 80/391 | Loss 1.6169 | Acc 0.5423\n",
      "2025-07-27 17:43:57,199 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 90/391 | Loss 1.6927 | Acc 0.5407\n",
      "2025-07-27 17:43:58,005 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 100/391 | Loss 1.5620 | Acc 0.5435\n",
      "2025-07-27 17:43:59,693 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 110/391 | Loss 1.6875 | Acc 0.5434\n",
      "2025-07-27 17:44:01,548 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 120/391 | Loss 1.6567 | Acc 0.5436\n",
      "2025-07-27 17:44:02,554 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 130/391 | Loss 1.6160 | Acc 0.5428\n",
      "2025-07-27 17:44:03,590 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 140/391 | Loss 1.7250 | Acc 0.5414\n",
      "2025-07-27 17:44:04,719 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 150/391 | Loss 1.5732 | Acc 0.5425\n",
      "2025-07-27 17:44:06,090 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 160/391 | Loss 1.6743 | Acc 0.5421\n",
      "2025-07-27 17:44:07,170 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 170/391 | Loss 1.5742 | Acc 0.5426\n",
      "2025-07-27 17:44:08,526 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 180/391 | Loss 1.6095 | Acc 0.5424\n",
      "2025-07-27 17:44:09,570 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 190/391 | Loss 1.6889 | Acc 0.5414\n",
      "2025-07-27 17:44:10,561 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 200/391 | Loss 1.5359 | Acc 0.5422\n",
      "2025-07-27 17:44:11,681 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 210/391 | Loss 1.6505 | Acc 0.5419\n",
      "2025-07-27 17:44:12,861 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 220/391 | Loss 1.7080 | Acc 0.5419\n",
      "2025-07-27 17:44:13,706 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 230/391 | Loss 1.6782 | Acc 0.5418\n",
      "2025-07-27 17:44:14,687 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 240/391 | Loss 1.6767 | Acc 0.5413\n",
      "2025-07-27 17:44:15,596 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 250/391 | Loss 1.6449 | Acc 0.5409\n",
      "2025-07-27 17:44:16,473 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 260/391 | Loss 1.6371 | Acc 0.5410\n",
      "2025-07-27 17:44:17,296 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 270/391 | Loss 1.5505 | Acc 0.5416\n",
      "2025-07-27 17:44:18,115 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 280/391 | Loss 1.5970 | Acc 0.5419\n",
      "2025-07-27 17:44:18,929 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 290/391 | Loss 1.6558 | Acc 0.5415\n",
      "2025-07-27 17:44:19,733 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 300/391 | Loss 1.6521 | Acc 0.5416\n",
      "2025-07-27 17:44:20,544 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 310/391 | Loss 1.6293 | Acc 0.5412\n",
      "2025-07-27 17:44:21,373 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 320/391 | Loss 1.7360 | Acc 0.5409\n",
      "2025-07-27 17:44:22,222 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 330/391 | Loss 1.6981 | Acc 0.5404\n",
      "2025-07-27 17:44:23,049 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 340/391 | Loss 1.7018 | Acc 0.5402\n",
      "2025-07-27 17:44:23,900 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 350/391 | Loss 1.6259 | Acc 0.5411\n",
      "2025-07-27 17:44:24,815 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 360/391 | Loss 1.6497 | Acc 0.5412\n",
      "2025-07-27 17:44:25,896 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 370/391 | Loss 1.6999 | Acc 0.5408\n",
      "2025-07-27 17:44:26,960 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 380/391 | Loss 1.6176 | Acc 0.5409\n",
      "2025-07-27 17:44:28,316 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 | Batch 390/391 | Loss 1.6525 | Acc 0.5408\n",
      "2025-07-27 17:44:28,404 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4 completed | Loss: 1.6416 | Acc: 0.5406\n",
      "2025/07/27 17:44:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:44:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:44:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 4\n",
      "Created version '4' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:44:39,007 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '3'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.54056'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:44:38.830220'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:44:39,007 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 4/15 | Time: 36.2s | ETA: 6.2min\n",
      "2025-07-27 17:44:39,008 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 5, total batches: 391\n",
      "2025-07-27 17:44:39,576 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 10/391 | Loss 1.4756 | Acc 0.5703\n",
      "2025-07-27 17:44:40,118 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 20/391 | Loss 1.4341 | Acc 0.5832\n",
      "2025-07-27 17:44:40,649 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 30/391 | Loss 1.5239 | Acc 0.5797\n",
      "2025-07-27 17:44:41,177 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 40/391 | Loss 1.5395 | Acc 0.5742\n",
      "2025-07-27 17:44:41,711 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 50/391 | Loss 1.4796 | Acc 0.5736\n",
      "2025-07-27 17:44:42,250 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 60/391 | Loss 1.4026 | Acc 0.5779\n",
      "2025-07-27 17:44:42,795 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 70/391 | Loss 1.4961 | Acc 0.5761\n",
      "2025-07-27 17:44:43,336 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 80/391 | Loss 1.5705 | Acc 0.5758\n",
      "2025-07-27 17:44:43,929 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 90/391 | Loss 1.4714 | Acc 0.5777\n",
      "2025-07-27 17:44:44,787 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 100/391 | Loss 1.4901 | Acc 0.5776\n",
      "2025-07-27 17:44:46,116 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 110/391 | Loss 1.5583 | Acc 0.5755\n",
      "2025-07-27 17:44:47,022 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 120/391 | Loss 1.5281 | Acc 0.5761\n",
      "2025-07-27 17:44:47,925 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 130/391 | Loss 1.4809 | Acc 0.5763\n",
      "2025-07-27 17:44:48,913 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 140/391 | Loss 1.5377 | Acc 0.5763\n",
      "2025-07-27 17:44:49,883 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 150/391 | Loss 1.6030 | Acc 0.5768\n",
      "2025-07-27 17:44:50,931 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 160/391 | Loss 1.4295 | Acc 0.5770\n",
      "2025-07-27 17:44:51,805 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 170/391 | Loss 1.4628 | Acc 0.5769\n",
      "2025-07-27 17:44:52,764 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 180/391 | Loss 1.5057 | Acc 0.5769\n",
      "2025-07-27 17:44:53,805 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 190/391 | Loss 1.5078 | Acc 0.5770\n",
      "2025-07-27 17:44:54,657 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 200/391 | Loss 1.5638 | Acc 0.5763\n",
      "2025-07-27 17:44:55,581 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 210/391 | Loss 1.5007 | Acc 0.5760\n",
      "2025-07-27 17:44:56,505 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 220/391 | Loss 1.5687 | Acc 0.5745\n",
      "2025-07-27 17:44:57,418 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 230/391 | Loss 1.5364 | Acc 0.5742\n",
      "2025-07-27 17:44:58,402 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 240/391 | Loss 1.5286 | Acc 0.5736\n",
      "2025-07-27 17:44:59,799 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 250/391 | Loss 1.5768 | Acc 0.5725\n",
      "2025-07-27 17:45:00,895 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 260/391 | Loss 1.5227 | Acc 0.5725\n",
      "2025-07-27 17:45:01,746 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 270/391 | Loss 1.5268 | Acc 0.5724\n",
      "2025-07-27 17:45:02,766 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 280/391 | Loss 1.5802 | Acc 0.5720\n",
      "2025-07-27 17:45:03,658 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 290/391 | Loss 1.6015 | Acc 0.5707\n",
      "2025-07-27 17:45:04,639 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 300/391 | Loss 1.5398 | Acc 0.5703\n",
      "2025-07-27 17:45:05,729 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 310/391 | Loss 1.5526 | Acc 0.5699\n",
      "2025-07-27 17:45:06,754 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 320/391 | Loss 1.4074 | Acc 0.5708\n",
      "2025-07-27 17:45:07,620 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 330/391 | Loss 1.4779 | Acc 0.5709\n",
      "2025-07-27 17:45:08,513 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 340/391 | Loss 1.4253 | Acc 0.5720\n",
      "2025-07-27 17:45:09,427 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 350/391 | Loss 1.5077 | Acc 0.5722\n",
      "2025-07-27 17:45:10,421 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 360/391 | Loss 1.4892 | Acc 0.5720\n",
      "2025-07-27 17:45:11,524 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 370/391 | Loss 1.5177 | Acc 0.5718\n",
      "2025-07-27 17:45:12,524 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 380/391 | Loss 1.5632 | Acc 0.5713\n",
      "2025-07-27 17:45:13,436 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 | Batch 390/391 | Loss 1.5447 | Acc 0.5714\n",
      "2025-07-27 17:45:13,506 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5 completed | Loss: 1.5144 | Acc: 0.5712\n",
      "2025/07/27 17:45:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:45:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:45:26 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 5\n",
      "Created version '5' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:45:26,880 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '4'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.5712'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:45:26.653929'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:45:26,882 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 5/15 | Time: 34.5s | ETA: 5.7min\n",
      "2025-07-27 17:45:26,883 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 6, total batches: 391\n",
      "2025-07-27 17:45:27,474 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 10/391 | Loss 1.3319 | Acc 0.6078\n",
      "2025-07-27 17:45:28,100 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 20/391 | Loss 1.3460 | Acc 0.6043\n",
      "2025-07-27 17:45:29,000 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 30/391 | Loss 1.4039 | Acc 0.6073\n",
      "2025-07-27 17:45:30,352 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 40/391 | Loss 1.3790 | Acc 0.6035\n",
      "2025-07-27 17:45:31,404 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 50/391 | Loss 1.4513 | Acc 0.5995\n",
      "2025-07-27 17:45:32,330 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 60/391 | Loss 1.3469 | Acc 0.6000\n",
      "2025-07-27 17:45:33,331 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 70/391 | Loss 1.4366 | Acc 0.6002\n",
      "2025-07-27 17:45:34,204 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 80/391 | Loss 1.3576 | Acc 0.5992\n",
      "2025-07-27 17:45:35,177 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 90/391 | Loss 1.3616 | Acc 0.6002\n",
      "2025-07-27 17:45:36,300 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 100/391 | Loss 1.4322 | Acc 0.5992\n",
      "2025-07-27 17:45:37,315 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 110/391 | Loss 1.3894 | Acc 0.5997\n",
      "2025-07-27 17:45:38,369 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 120/391 | Loss 1.4086 | Acc 0.5984\n",
      "2025-07-27 17:45:39,429 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 130/391 | Loss 1.4264 | Acc 0.5981\n",
      "2025-07-27 17:45:40,752 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 140/391 | Loss 1.5003 | Acc 0.5955\n",
      "2025-07-27 17:45:41,894 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 150/391 | Loss 1.4234 | Acc 0.5964\n",
      "2025-07-27 17:45:43,114 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 160/391 | Loss 1.4337 | Acc 0.5958\n",
      "2025-07-27 17:45:44,109 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 170/391 | Loss 1.4543 | Acc 0.5941\n",
      "2025-07-27 17:45:45,058 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 180/391 | Loss 1.3650 | Acc 0.5951\n",
      "2025-07-27 17:45:45,939 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 190/391 | Loss 1.3854 | Acc 0.5953\n",
      "2025-07-27 17:45:46,937 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 200/391 | Loss 1.3892 | Acc 0.5952\n",
      "2025-07-27 17:45:48,033 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 210/391 | Loss 1.4121 | Acc 0.5946\n",
      "2025-07-27 17:45:49,435 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 220/391 | Loss 1.3987 | Acc 0.5953\n",
      "2025-07-27 17:45:50,488 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 230/391 | Loss 1.4452 | Acc 0.5949\n",
      "2025-07-27 17:45:51,426 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 240/391 | Loss 1.4161 | Acc 0.5942\n",
      "2025-07-27 17:45:52,419 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 250/391 | Loss 1.4347 | Acc 0.5937\n",
      "2025-07-27 17:45:53,230 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 260/391 | Loss 1.4049 | Acc 0.5938\n",
      "2025-07-27 17:45:54,002 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 270/391 | Loss 1.4922 | Acc 0.5930\n",
      "2025-07-27 17:45:54,748 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 280/391 | Loss 1.3467 | Acc 0.5931\n",
      "2025-07-27 17:45:55,474 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 290/391 | Loss 1.4741 | Acc 0.5925\n",
      "2025-07-27 17:45:56,204 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 300/391 | Loss 1.4130 | Acc 0.5926\n",
      "2025-07-27 17:45:56,933 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 310/391 | Loss 1.3552 | Acc 0.5937\n",
      "2025-07-27 17:45:57,666 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 320/391 | Loss 1.3595 | Acc 0.5942\n",
      "2025-07-27 17:45:58,410 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 330/391 | Loss 1.4189 | Acc 0.5940\n",
      "2025-07-27 17:45:59,168 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 340/391 | Loss 1.4690 | Acc 0.5935\n",
      "2025-07-27 17:46:00,035 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 350/391 | Loss 1.4479 | Acc 0.5934\n",
      "2025-07-27 17:46:00,967 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 360/391 | Loss 1.4612 | Acc 0.5933\n",
      "2025-07-27 17:46:02,032 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 370/391 | Loss 1.4522 | Acc 0.5929\n",
      "2025-07-27 17:46:03,088 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 380/391 | Loss 1.4046 | Acc 0.5932\n",
      "2025-07-27 17:46:03,930 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 | Batch 390/391 | Loss 1.4681 | Acc 0.5931\n",
      "2025-07-27 17:46:03,998 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6 completed | Loss: 1.4123 | Acc: 0.5931\n",
      "2025/07/27 17:46:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:46:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:46:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 6\n",
      "Created version '6' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:46:13,072 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '5'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.59308'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:46:12.904081'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:46:13,073 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 6/15 | Time: 37.1s | ETA: 5.2min\n",
      "2025-07-27 17:46:13,074 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 7, total batches: 391\n",
      "2025-07-27 17:46:13,657 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 10/391 | Loss 1.2597 | Acc 0.6461\n",
      "2025-07-27 17:46:14,190 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 20/391 | Loss 1.2432 | Acc 0.6395\n",
      "2025-07-27 17:46:14,718 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 30/391 | Loss 1.2306 | Acc 0.6346\n",
      "2025-07-27 17:46:15,257 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 40/391 | Loss 1.2661 | Acc 0.6354\n",
      "2025-07-27 17:46:15,834 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 50/391 | Loss 1.2657 | Acc 0.6366\n",
      "2025-07-27 17:46:16,453 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 60/391 | Loss 1.2706 | Acc 0.6361\n",
      "2025-07-27 17:46:17,185 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 70/391 | Loss 1.2879 | Acc 0.6330\n",
      "2025-07-27 17:46:19,053 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 80/391 | Loss 1.2487 | Acc 0.6346\n",
      "2025-07-27 17:46:19,962 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 90/391 | Loss 1.2905 | Acc 0.6351\n",
      "2025-07-27 17:46:20,705 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 100/391 | Loss 1.3529 | Acc 0.6315\n",
      "2025-07-27 17:46:21,399 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 110/391 | Loss 1.3035 | Acc 0.6302\n",
      "2025-07-27 17:46:22,105 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 120/391 | Loss 1.2455 | Acc 0.6296\n",
      "2025-07-27 17:46:22,836 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 130/391 | Loss 1.2922 | Acc 0.6299\n",
      "2025-07-27 17:46:23,567 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 140/391 | Loss 1.2875 | Acc 0.6299\n",
      "2025-07-27 17:46:24,304 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 150/391 | Loss 1.2809 | Acc 0.6293\n",
      "2025-07-27 17:46:25,072 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 160/391 | Loss 1.4813 | Acc 0.6260\n",
      "2025-07-27 17:46:26,177 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 170/391 | Loss 1.2737 | Acc 0.6261\n",
      "2025-07-27 17:46:27,320 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 180/391 | Loss 1.4173 | Acc 0.6246\n",
      "2025-07-27 17:46:28,254 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 190/391 | Loss 1.3216 | Acc 0.6239\n",
      "2025-07-27 17:46:29,125 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 200/391 | Loss 1.3636 | Acc 0.6232\n",
      "2025-07-27 17:46:29,943 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 210/391 | Loss 1.3196 | Acc 0.6235\n",
      "2025-07-27 17:46:30,794 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 220/391 | Loss 1.3885 | Acc 0.6222\n",
      "2025-07-27 17:46:31,640 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 230/391 | Loss 1.3922 | Acc 0.6213\n",
      "2025-07-27 17:46:32,451 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 240/391 | Loss 1.3214 | Acc 0.6211\n",
      "2025-07-27 17:46:33,218 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 250/391 | Loss 1.3382 | Acc 0.6212\n",
      "2025-07-27 17:46:34,004 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 260/391 | Loss 1.3425 | Acc 0.6204\n",
      "2025-07-27 17:46:34,783 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 270/391 | Loss 1.3269 | Acc 0.6203\n",
      "2025-07-27 17:46:35,610 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 280/391 | Loss 1.2789 | Acc 0.6208\n",
      "2025-07-27 17:46:36,493 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 290/391 | Loss 1.3812 | Acc 0.6201\n",
      "2025-07-27 17:46:37,416 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 300/391 | Loss 1.4125 | Acc 0.6191\n",
      "2025-07-27 17:46:38,315 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 310/391 | Loss 1.3572 | Acc 0.6180\n",
      "2025-07-27 17:46:39,205 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 320/391 | Loss 1.3360 | Acc 0.6179\n",
      "2025-07-27 17:46:40,105 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 330/391 | Loss 1.3578 | Acc 0.6176\n",
      "2025-07-27 17:46:41,000 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 340/391 | Loss 1.3282 | Acc 0.6175\n",
      "2025-07-27 17:46:41,883 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 350/391 | Loss 1.3481 | Acc 0.6179\n",
      "2025-07-27 17:46:42,748 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 360/391 | Loss 1.3760 | Acc 0.6174\n",
      "2025-07-27 17:46:43,617 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 370/391 | Loss 1.3970 | Acc 0.6165\n",
      "2025-07-27 17:46:44,480 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 380/391 | Loss 1.4286 | Acc 0.6161\n",
      "2025-07-27 17:46:45,353 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 | Batch 390/391 | Loss 1.3520 | Acc 0.6161\n",
      "2025-07-27 17:46:45,416 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7 completed | Loss: 1.3274 | Acc: 0.6160\n",
      "2025/07/27 17:46:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:46:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:46:54 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 7\n",
      "Created version '7' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:46:54,961 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '6'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.61598'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:46:54.845862'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:46:54,962 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 7/15 | Time: 32.3s | ETA: 4.6min\n",
      "2025-07-27 17:46:54,963 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 8, total batches: 391\n",
      "2025-07-27 17:46:55,587 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 10/391 | Loss 1.1614 | Acc 0.6562\n",
      "2025-07-27 17:46:56,208 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 20/391 | Loss 1.2212 | Acc 0.6527\n",
      "2025-07-27 17:46:57,475 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 30/391 | Loss 1.1974 | Acc 0.6484\n",
      "2025-07-27 17:46:59,657 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 40/391 | Loss 1.1771 | Acc 0.6516\n",
      "2025-07-27 17:47:00,754 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 50/391 | Loss 1.1769 | Acc 0.6523\n",
      "2025-07-27 17:47:01,761 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 60/391 | Loss 1.1127 | Acc 0.6540\n",
      "2025-07-27 17:47:02,816 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 70/391 | Loss 1.2127 | Acc 0.6535\n",
      "2025-07-27 17:47:03,979 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 80/391 | Loss 1.1736 | Acc 0.6534\n",
      "2025-07-27 17:47:05,112 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 90/391 | Loss 1.2546 | Acc 0.6495\n",
      "2025-07-27 17:47:06,203 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 100/391 | Loss 1.1824 | Acc 0.6516\n",
      "2025-07-27 17:47:07,310 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 110/391 | Loss 1.1493 | Acc 0.6524\n",
      "2025-07-27 17:47:08,418 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 120/391 | Loss 1.2722 | Acc 0.6516\n",
      "2025-07-27 17:47:09,538 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 130/391 | Loss 1.1984 | Acc 0.6512\n",
      "2025-07-27 17:47:10,634 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 140/391 | Loss 1.1654 | Acc 0.6527\n",
      "2025-07-27 17:47:11,746 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 150/391 | Loss 1.1814 | Acc 0.6523\n",
      "2025-07-27 17:47:12,835 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 160/391 | Loss 1.2673 | Acc 0.6512\n",
      "2025-07-27 17:47:13,973 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 170/391 | Loss 1.1630 | Acc 0.6511\n",
      "2025-07-27 17:47:15,055 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 180/391 | Loss 1.2514 | Acc 0.6503\n",
      "2025-07-27 17:47:16,168 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 190/391 | Loss 1.2600 | Acc 0.6495\n",
      "2025-07-27 17:47:17,276 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 200/391 | Loss 1.2645 | Acc 0.6486\n",
      "2025-07-27 17:47:18,625 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 210/391 | Loss 1.3111 | Acc 0.6470\n",
      "2025-07-27 17:47:19,672 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 220/391 | Loss 1.2616 | Acc 0.6462\n",
      "2025-07-27 17:47:20,768 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 230/391 | Loss 1.2892 | Acc 0.6453\n",
      "2025-07-27 17:47:21,691 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 240/391 | Loss 1.2136 | Acc 0.6457\n",
      "2025-07-27 17:47:22,535 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 250/391 | Loss 1.2732 | Acc 0.6453\n",
      "2025-07-27 17:47:23,352 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 260/391 | Loss 1.2709 | Acc 0.6450\n",
      "2025-07-27 17:47:24,154 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 270/391 | Loss 1.2981 | Acc 0.6443\n",
      "2025-07-27 17:47:24,967 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 280/391 | Loss 1.2683 | Acc 0.6432\n",
      "2025-07-27 17:47:25,778 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 290/391 | Loss 1.3472 | Acc 0.6420\n",
      "2025-07-27 17:47:26,598 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 300/391 | Loss 1.2584 | Acc 0.6414\n",
      "2025-07-27 17:47:27,440 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 310/391 | Loss 1.3592 | Acc 0.6403\n",
      "2025-07-27 17:47:28,262 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 320/391 | Loss 1.3141 | Acc 0.6396\n",
      "2025-07-27 17:47:29,086 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 330/391 | Loss 1.2791 | Acc 0.6389\n",
      "2025-07-27 17:47:29,896 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 340/391 | Loss 1.2691 | Acc 0.6387\n",
      "2025-07-27 17:47:30,715 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 350/391 | Loss 1.3108 | Acc 0.6380\n",
      "2025-07-27 17:47:31,557 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 360/391 | Loss 1.2777 | Acc 0.6382\n",
      "2025-07-27 17:47:32,374 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 370/391 | Loss 1.3288 | Acc 0.6378\n",
      "2025-07-27 17:47:33,229 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 380/391 | Loss 1.2102 | Acc 0.6380\n",
      "2025-07-27 17:47:34,088 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 | Batch 390/391 | Loss 1.2730 | Acc 0.6378\n",
      "2025-07-27 17:47:34,149 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8 completed | Loss: 1.2432 | Acc: 0.6377\n",
      "2025/07/27 17:47:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:47:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:47:43 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 8\n",
      "Created version '8' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:47:44,616 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '7'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.63772'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:47:44.343065'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:47:44,617 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 8/15 | Time: 39.2s | ETA: 4.1min\n",
      "2025-07-27 17:47:44,618 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 9, total batches: 391\n",
      "2025-07-27 17:47:45,192 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 10/391 | Loss 1.1465 | Acc 0.6578\n",
      "2025-07-27 17:47:45,721 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 20/391 | Loss 1.1300 | Acc 0.6531\n",
      "2025-07-27 17:47:46,251 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 30/391 | Loss 1.1273 | Acc 0.6544\n",
      "2025-07-27 17:47:46,779 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 40/391 | Loss 1.1362 | Acc 0.6611\n",
      "2025-07-27 17:47:47,311 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 50/391 | Loss 1.0980 | Acc 0.6628\n",
      "2025-07-27 17:47:47,840 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 60/391 | Loss 1.0504 | Acc 0.6647\n",
      "2025-07-27 17:47:48,374 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 70/391 | Loss 1.1082 | Acc 0.6660\n",
      "2025-07-27 17:47:48,905 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 80/391 | Loss 1.1644 | Acc 0.6638\n",
      "2025-07-27 17:47:49,449 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 90/391 | Loss 1.1200 | Acc 0.6646\n",
      "2025-07-27 17:47:49,998 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 100/391 | Loss 1.1090 | Acc 0.6651\n",
      "2025-07-27 17:47:50,555 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 110/391 | Loss 1.1916 | Acc 0.6629\n",
      "2025-07-27 17:47:51,189 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 120/391 | Loss 1.1364 | Acc 0.6634\n",
      "2025-07-27 17:47:52,239 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 130/391 | Loss 1.1462 | Acc 0.6639\n",
      "2025-07-27 17:47:53,365 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 140/391 | Loss 1.1380 | Acc 0.6638\n",
      "2025-07-27 17:47:54,222 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 150/391 | Loss 1.0913 | Acc 0.6644\n",
      "2025-07-27 17:47:55,018 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 160/391 | Loss 1.1931 | Acc 0.6640\n",
      "2025-07-27 17:47:55,810 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 170/391 | Loss 1.1607 | Acc 0.6638\n",
      "2025-07-27 17:47:56,594 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 180/391 | Loss 1.1261 | Acc 0.6642\n",
      "2025-07-27 17:47:57,392 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 190/391 | Loss 1.1816 | Acc 0.6629\n",
      "2025-07-27 17:47:58,209 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 200/391 | Loss 1.1542 | Acc 0.6625\n",
      "2025-07-27 17:47:59,032 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 210/391 | Loss 1.1804 | Acc 0.6615\n",
      "2025-07-27 17:47:59,898 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 220/391 | Loss 1.2634 | Acc 0.6605\n",
      "2025-07-27 17:48:00,777 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 230/391 | Loss 1.1168 | Acc 0.6610\n",
      "2025-07-27 17:48:01,635 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 240/391 | Loss 1.1990 | Acc 0.6608\n",
      "2025-07-27 17:48:02,458 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 250/391 | Loss 1.2049 | Acc 0.6598\n",
      "2025-07-27 17:48:03,256 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 260/391 | Loss 1.1883 | Acc 0.6596\n",
      "2025-07-27 17:48:04,063 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 270/391 | Loss 1.1934 | Acc 0.6599\n",
      "2025-07-27 17:48:04,874 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 280/391 | Loss 1.1787 | Acc 0.6591\n",
      "2025-07-27 17:48:05,676 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 290/391 | Loss 1.1081 | Acc 0.6595\n",
      "2025-07-27 17:48:06,473 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 300/391 | Loss 1.1781 | Acc 0.6591\n",
      "2025-07-27 17:48:07,274 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 310/391 | Loss 1.2390 | Acc 0.6586\n",
      "2025-07-27 17:48:08,091 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 320/391 | Loss 1.2000 | Acc 0.6580\n",
      "2025-07-27 17:48:08,933 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 330/391 | Loss 1.2188 | Acc 0.6580\n",
      "2025-07-27 17:48:09,771 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 340/391 | Loss 1.1572 | Acc 0.6584\n",
      "2025-07-27 17:48:10,573 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 350/391 | Loss 1.2553 | Acc 0.6577\n",
      "2025-07-27 17:48:11,376 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 360/391 | Loss 1.2570 | Acc 0.6570\n",
      "2025-07-27 17:48:12,180 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 370/391 | Loss 1.2424 | Acc 0.6562\n",
      "2025-07-27 17:48:12,995 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 380/391 | Loss 1.2207 | Acc 0.6563\n",
      "2025-07-27 17:48:13,808 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 | Batch 390/391 | Loss 1.2965 | Acc 0.6558\n",
      "2025-07-27 17:48:13,869 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9 completed | Loss: 1.1697 | Acc: 0.6557\n",
      "2025/07/27 17:48:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:48:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:48:27 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 9\n",
      "Created version '9' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:48:28,446 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '8'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.65572'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:48:28.381832'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:48:28,447 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 9/15 | Time: 29.3s | ETA: 3.4min\n",
      "2025-07-27 17:48:28,447 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 10, total batches: 391\n",
      "2025-07-27 17:48:29,028 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 10/391 | Loss 1.0483 | Acc 0.6875\n",
      "2025-07-27 17:48:29,624 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 20/391 | Loss 1.0986 | Acc 0.6781\n",
      "2025-07-27 17:48:30,313 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 30/391 | Loss 1.0876 | Acc 0.6773\n",
      "2025-07-27 17:48:31,108 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 40/391 | Loss 1.0513 | Acc 0.6818\n",
      "2025-07-27 17:48:31,964 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 50/391 | Loss 1.0449 | Acc 0.6817\n",
      "2025-07-27 17:48:32,772 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 60/391 | Loss 1.0334 | Acc 0.6846\n",
      "2025-07-27 17:48:33,559 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 70/391 | Loss 1.0634 | Acc 0.6854\n",
      "2025-07-27 17:48:34,317 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 80/391 | Loss 1.0918 | Acc 0.6854\n",
      "2025-07-27 17:48:35,115 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 90/391 | Loss 1.1132 | Acc 0.6848\n",
      "2025-07-27 17:48:35,888 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 100/391 | Loss 1.0388 | Acc 0.6851\n",
      "2025-07-27 17:48:36,660 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 110/391 | Loss 1.0750 | Acc 0.6843\n",
      "2025-07-27 17:48:37,429 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 120/391 | Loss 1.0814 | Acc 0.6851\n",
      "2025-07-27 17:48:38,181 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 130/391 | Loss 1.0853 | Acc 0.6843\n",
      "2025-07-27 17:48:38,910 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 140/391 | Loss 1.1064 | Acc 0.6834\n",
      "2025-07-27 17:48:39,699 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 150/391 | Loss 1.0741 | Acc 0.6821\n",
      "2025-07-27 17:48:40,510 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 160/391 | Loss 1.0935 | Acc 0.6826\n",
      "2025-07-27 17:48:41,309 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 170/391 | Loss 0.9897 | Acc 0.6836\n",
      "2025-07-27 17:48:42,084 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 180/391 | Loss 1.0911 | Acc 0.6833\n",
      "2025-07-27 17:48:42,809 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 190/391 | Loss 1.1358 | Acc 0.6816\n",
      "2025-07-27 17:48:43,543 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 200/391 | Loss 1.0451 | Acc 0.6825\n",
      "2025-07-27 17:48:44,256 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 210/391 | Loss 1.1120 | Acc 0.6820\n",
      "2025-07-27 17:48:44,979 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 220/391 | Loss 1.1246 | Acc 0.6815\n",
      "2025-07-27 17:48:45,711 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 230/391 | Loss 1.1607 | Acc 0.6800\n",
      "2025-07-27 17:48:46,440 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 240/391 | Loss 1.0769 | Acc 0.6804\n",
      "2025-07-27 17:48:47,194 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 250/391 | Loss 1.0960 | Acc 0.6799\n",
      "2025-07-27 17:48:47,970 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 260/391 | Loss 1.0416 | Acc 0.6801\n",
      "2025-07-27 17:48:48,735 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 270/391 | Loss 1.1644 | Acc 0.6791\n",
      "2025-07-27 17:48:49,537 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 280/391 | Loss 1.1535 | Acc 0.6782\n",
      "2025-07-27 17:48:50,356 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 290/391 | Loss 1.1800 | Acc 0.6770\n",
      "2025-07-27 17:48:51,166 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 300/391 | Loss 1.1381 | Acc 0.6762\n",
      "2025-07-27 17:48:51,970 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 310/391 | Loss 1.1908 | Acc 0.6755\n",
      "2025-07-27 17:48:52,776 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 320/391 | Loss 1.1946 | Acc 0.6743\n",
      "2025-07-27 17:48:53,577 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 330/391 | Loss 1.1046 | Acc 0.6742\n",
      "2025-07-27 17:48:54,381 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 340/391 | Loss 1.1701 | Acc 0.6737\n",
      "2025-07-27 17:48:55,182 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 350/391 | Loss 1.1500 | Acc 0.6733\n",
      "2025-07-27 17:48:55,984 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 360/391 | Loss 1.0830 | Acc 0.6734\n",
      "2025-07-27 17:48:56,789 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 370/391 | Loss 1.1442 | Acc 0.6729\n",
      "2025-07-27 17:48:57,589 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 380/391 | Loss 1.1303 | Acc 0.6728\n",
      "2025-07-27 17:48:58,393 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 | Batch 390/391 | Loss 1.1316 | Acc 0.6726\n",
      "2025-07-27 17:48:58,453 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10 completed | Loss: 1.1030 | Acc: 0.6724\n",
      "2025/07/27 17:48:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:49:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:49:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 10\n",
      "Created version '10' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:49:08,128 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '9'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.6724'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:49:07.974568'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:49:08,130 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 10/15 | Time: 30.0s | ETA: 2.8min\n",
      "2025-07-27 17:49:08,131 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 11, total batches: 391\n",
      "2025-07-27 17:49:08,745 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 10/391 | Loss 1.0235 | Acc 0.7055\n",
      "2025-07-27 17:49:09,305 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 20/391 | Loss 0.9613 | Acc 0.7117\n",
      "2025-07-27 17:49:09,923 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 30/391 | Loss 0.9703 | Acc 0.7091\n",
      "2025-07-27 17:49:10,638 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 40/391 | Loss 0.9433 | Acc 0.7141\n",
      "2025-07-27 17:49:11,424 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 50/391 | Loss 1.0351 | Acc 0.7105\n",
      "2025-07-27 17:49:12,186 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 60/391 | Loss 1.0531 | Acc 0.7051\n",
      "2025-07-27 17:49:12,913 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 70/391 | Loss 1.0317 | Acc 0.7038\n",
      "2025-07-27 17:49:13,638 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 80/391 | Loss 0.8800 | Acc 0.7074\n",
      "2025-07-27 17:49:14,337 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 90/391 | Loss 0.9765 | Acc 0.7077\n",
      "2025-07-27 17:49:15,041 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 100/391 | Loss 0.9939 | Acc 0.7060\n",
      "2025-07-27 17:49:15,736 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 110/391 | Loss 1.0664 | Acc 0.7042\n",
      "2025-07-27 17:49:16,425 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 120/391 | Loss 0.9962 | Acc 0.7037\n",
      "2025-07-27 17:49:17,142 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 130/391 | Loss 0.9673 | Acc 0.7040\n",
      "2025-07-27 17:49:18,141 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 140/391 | Loss 0.9931 | Acc 0.7051\n",
      "2025-07-27 17:49:19,329 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 150/391 | Loss 1.0805 | Acc 0.7034\n",
      "2025-07-27 17:49:20,103 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 160/391 | Loss 1.0324 | Acc 0.7025\n",
      "2025-07-27 17:49:20,833 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 170/391 | Loss 1.0252 | Acc 0.7025\n",
      "2025-07-27 17:49:21,565 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 180/391 | Loss 0.9794 | Acc 0.7030\n",
      "2025-07-27 17:49:22,270 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 190/391 | Loss 1.0584 | Acc 0.7026\n",
      "2025-07-27 17:49:22,965 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 200/391 | Loss 1.1233 | Acc 0.7011\n",
      "2025-07-27 17:49:23,705 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 210/391 | Loss 1.0483 | Acc 0.6996\n",
      "2025-07-27 17:49:24,533 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 220/391 | Loss 1.0654 | Acc 0.6988\n",
      "2025-07-27 17:49:25,368 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 230/391 | Loss 1.1014 | Acc 0.6978\n",
      "2025-07-27 17:49:26,328 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 240/391 | Loss 1.0687 | Acc 0.6967\n",
      "2025-07-27 17:49:27,214 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 250/391 | Loss 1.1036 | Acc 0.6953\n",
      "2025-07-27 17:49:28,137 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 260/391 | Loss 1.0663 | Acc 0.6943\n",
      "2025-07-27 17:49:29,247 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 270/391 | Loss 1.0758 | Acc 0.6934\n",
      "2025-07-27 17:49:30,206 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 280/391 | Loss 1.1147 | Acc 0.6922\n",
      "2025-07-27 17:49:31,092 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 290/391 | Loss 1.0044 | Acc 0.6928\n",
      "2025-07-27 17:49:31,921 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 300/391 | Loss 1.1004 | Acc 0.6924\n",
      "2025-07-27 17:49:32,719 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 310/391 | Loss 1.0951 | Acc 0.6924\n",
      "2025-07-27 17:49:33,480 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 320/391 | Loss 1.1277 | Acc 0.6916\n",
      "2025-07-27 17:49:34,244 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 330/391 | Loss 1.0235 | Acc 0.6917\n",
      "2025-07-27 17:49:35,117 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 340/391 | Loss 1.0870 | Acc 0.6908\n",
      "2025-07-27 17:49:36,203 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 350/391 | Loss 1.1488 | Acc 0.6901\n",
      "2025-07-27 17:49:37,360 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 360/391 | Loss 1.0917 | Acc 0.6896\n",
      "2025-07-27 17:49:38,338 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 370/391 | Loss 1.0705 | Acc 0.6893\n",
      "2025-07-27 17:49:39,323 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 380/391 | Loss 1.0485 | Acc 0.6891\n",
      "2025-07-27 17:49:40,280 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 | Batch 390/391 | Loss 1.0973 | Acc 0.6890\n",
      "2025-07-27 17:49:40,351 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11 completed | Loss: 1.0443 | Acc: 0.6890\n",
      "2025/07/27 17:49:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:49:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:49:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 11\n",
      "Created version '11' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:49:49,375 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '10'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.68896'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:49:49.138117'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:49:49,377 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 11/15 | Time: 32.2s | ETA: 2.2min\n",
      "2025-07-27 17:49:49,377 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 12, total batches: 391\n",
      "2025-07-27 17:49:50,042 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 10/391 | Loss 0.9185 | Acc 0.7227\n",
      "2025-07-27 17:49:50,638 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 20/391 | Loss 0.9112 | Acc 0.7238\n",
      "2025-07-27 17:49:51,223 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 30/391 | Loss 0.8828 | Acc 0.7273\n",
      "2025-07-27 17:49:51,781 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 40/391 | Loss 0.9410 | Acc 0.7217\n",
      "2025-07-27 17:49:52,345 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 50/391 | Loss 0.9341 | Acc 0.7208\n",
      "2025-07-27 17:49:52,915 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 60/391 | Loss 0.9296 | Acc 0.7186\n",
      "2025-07-27 17:49:53,493 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 70/391 | Loss 0.9224 | Acc 0.7183\n",
      "2025-07-27 17:49:54,068 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 80/391 | Loss 0.9063 | Acc 0.7189\n",
      "2025-07-27 17:49:54,656 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 90/391 | Loss 0.8512 | Acc 0.7215\n",
      "2025-07-27 17:49:55,276 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 100/391 | Loss 0.9950 | Acc 0.7192\n",
      "2025-07-27 17:49:56,134 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 110/391 | Loss 0.9573 | Acc 0.7184\n",
      "2025-07-27 17:49:57,626 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 120/391 | Loss 0.9327 | Acc 0.7178\n",
      "2025-07-27 17:49:58,726 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 130/391 | Loss 0.9709 | Acc 0.7171\n",
      "2025-07-27 17:49:59,687 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 140/391 | Loss 0.9747 | Acc 0.7166\n",
      "2025-07-27 17:50:00,674 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 150/391 | Loss 1.0414 | Acc 0.7154\n",
      "2025-07-27 17:50:01,651 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 160/391 | Loss 0.9676 | Acc 0.7161\n",
      "2025-07-27 17:50:02,473 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 170/391 | Loss 0.9784 | Acc 0.7158\n",
      "2025-07-27 17:50:03,290 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 180/391 | Loss 1.0247 | Acc 0.7145\n",
      "2025-07-27 17:50:04,110 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 190/391 | Loss 0.9682 | Acc 0.7143\n",
      "2025-07-27 17:50:04,952 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 200/391 | Loss 1.0625 | Acc 0.7124\n",
      "2025-07-27 17:50:05,816 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 210/391 | Loss 1.0344 | Acc 0.7108\n",
      "2025-07-27 17:50:06,721 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 220/391 | Loss 1.0224 | Acc 0.7097\n",
      "2025-07-27 17:50:07,858 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 230/391 | Loss 0.9585 | Acc 0.7097\n",
      "2025-07-27 17:50:08,981 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 240/391 | Loss 1.0391 | Acc 0.7090\n",
      "2025-07-27 17:50:10,028 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 250/391 | Loss 1.0142 | Acc 0.7086\n",
      "2025-07-27 17:50:11,044 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 260/391 | Loss 1.0572 | Acc 0.7079\n",
      "2025-07-27 17:50:11,959 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 270/391 | Loss 1.0414 | Acc 0.7076\n",
      "2025-07-27 17:50:12,816 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 280/391 | Loss 1.0161 | Acc 0.7073\n",
      "2025-07-27 17:50:13,670 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 290/391 | Loss 1.1353 | Acc 0.7056\n",
      "2025-07-27 17:50:14,549 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 300/391 | Loss 1.0468 | Acc 0.7051\n",
      "2025-07-27 17:50:15,425 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 310/391 | Loss 1.0528 | Acc 0.7042\n",
      "2025-07-27 17:50:16,319 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 320/391 | Loss 1.0248 | Acc 0.7039\n",
      "2025-07-27 17:50:17,360 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 330/391 | Loss 1.0668 | Acc 0.7033\n",
      "2025-07-27 17:50:18,517 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 340/391 | Loss 0.9911 | Acc 0.7034\n",
      "2025-07-27 17:50:19,681 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 350/391 | Loss 0.9820 | Acc 0.7034\n",
      "2025-07-27 17:50:20,796 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 360/391 | Loss 0.9815 | Acc 0.7039\n",
      "2025-07-27 17:50:21,822 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 370/391 | Loss 1.0914 | Acc 0.7029\n",
      "2025-07-27 17:50:22,711 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 380/391 | Loss 1.0610 | Acc 0.7020\n",
      "2025-07-27 17:50:23,599 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 | Batch 390/391 | Loss 1.0481 | Acc 0.7014\n",
      "2025-07-27 17:50:23,663 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12 completed | Loss: 0.9930 | Acc: 0.7015\n",
      "2025/07/27 17:50:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:50:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:50:32 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 12\n",
      "Created version '12' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:50:33,645 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '11'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.70152'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:50:33.459930'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:50:33,646 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 12/15 | Time: 34.3s | ETA: 1.7min\n",
      "2025-07-27 17:50:33,647 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 13, total batches: 391\n",
      "2025-07-27 17:50:34,245 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 10/391 | Loss 0.9351 | Acc 0.7250\n",
      "2025-07-27 17:50:34,809 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 20/391 | Loss 0.8489 | Acc 0.7324\n",
      "2025-07-27 17:50:35,376 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 30/391 | Loss 0.8618 | Acc 0.7320\n",
      "2025-07-27 17:50:35,942 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 40/391 | Loss 0.8263 | Acc 0.7342\n",
      "2025-07-27 17:50:36,511 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 50/391 | Loss 0.8886 | Acc 0.7325\n",
      "2025-07-27 17:50:37,116 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 60/391 | Loss 0.9426 | Acc 0.7290\n",
      "2025-07-27 17:50:37,730 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 70/391 | Loss 0.8930 | Acc 0.7296\n",
      "2025-07-27 17:50:38,447 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 80/391 | Loss 0.8714 | Acc 0.7305\n",
      "2025-07-27 17:50:40,678 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 90/391 | Loss 0.9510 | Acc 0.7290\n",
      "2025-07-27 17:50:41,781 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 100/391 | Loss 0.8811 | Acc 0.7288\n",
      "2025-07-27 17:50:42,558 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 110/391 | Loss 0.8892 | Acc 0.7298\n",
      "2025-07-27 17:50:43,363 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 120/391 | Loss 0.8959 | Acc 0.7296\n",
      "2025-07-27 17:50:44,196 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 130/391 | Loss 0.9959 | Acc 0.7270\n",
      "2025-07-27 17:50:45,325 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 140/391 | Loss 0.8972 | Acc 0.7268\n",
      "2025-07-27 17:50:46,310 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 150/391 | Loss 0.9362 | Acc 0.7261\n",
      "2025-07-27 17:50:47,366 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 160/391 | Loss 0.8977 | Acc 0.7277\n",
      "2025-07-27 17:50:48,536 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 170/391 | Loss 0.9186 | Acc 0.7275\n",
      "2025-07-27 17:50:49,715 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 180/391 | Loss 0.8830 | Acc 0.7274\n",
      "2025-07-27 17:50:50,892 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 190/391 | Loss 0.8727 | Acc 0.7277\n",
      "2025-07-27 17:50:51,979 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 200/391 | Loss 0.9100 | Acc 0.7277\n",
      "2025-07-27 17:50:53,136 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 210/391 | Loss 0.9845 | Acc 0.7263\n",
      "2025-07-27 17:50:54,272 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 220/391 | Loss 0.9603 | Acc 0.7260\n",
      "2025-07-27 17:50:55,312 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 230/391 | Loss 0.9586 | Acc 0.7245\n",
      "2025-07-27 17:50:56,384 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 240/391 | Loss 0.9648 | Acc 0.7252\n",
      "2025-07-27 17:50:57,715 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 250/391 | Loss 0.9098 | Acc 0.7247\n",
      "2025-07-27 17:50:59,218 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 260/391 | Loss 0.9663 | Acc 0.7244\n",
      "2025-07-27 17:51:00,559 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 270/391 | Loss 0.9298 | Acc 0.7239\n",
      "2025-07-27 17:51:01,808 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 280/391 | Loss 0.9705 | Acc 0.7230\n",
      "2025-07-27 17:51:02,814 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 290/391 | Loss 0.9340 | Acc 0.7225\n",
      "2025-07-27 17:51:03,768 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 300/391 | Loss 1.0309 | Acc 0.7212\n",
      "2025-07-27 17:51:04,712 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 310/391 | Loss 0.9667 | Acc 0.7207\n",
      "2025-07-27 17:51:05,663 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 320/391 | Loss 0.9647 | Acc 0.7204\n",
      "2025-07-27 17:51:06,661 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 330/391 | Loss 1.0453 | Acc 0.7191\n",
      "2025-07-27 17:51:07,783 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 340/391 | Loss 1.0812 | Acc 0.7181\n",
      "2025-07-27 17:51:09,022 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 350/391 | Loss 0.9974 | Acc 0.7176\n",
      "2025-07-27 17:51:10,272 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 360/391 | Loss 0.9995 | Acc 0.7172\n",
      "2025-07-27 17:51:11,504 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 370/391 | Loss 0.9572 | Acc 0.7170\n",
      "2025-07-27 17:51:12,569 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 380/391 | Loss 0.9356 | Acc 0.7171\n",
      "2025-07-27 17:51:13,536 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 | Batch 390/391 | Loss 1.0529 | Acc 0.7164\n",
      "2025-07-27 17:51:13,606 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13 completed | Loss: 0.9385 | Acc: 0.7165\n",
      "2025/07/27 17:51:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:51:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:51:22 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 13\n",
      "Created version '13' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:51:23,158 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '12'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.71648'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:51:22.976500'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:51:23,159 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 13/15 | Time: 40.0s | ETA: 1.1min\n",
      "2025-07-27 17:51:23,159 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 14, total batches: 391\n",
      "2025-07-27 17:51:23,774 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 10/391 | Loss 0.8913 | Acc 0.7258\n",
      "2025-07-27 17:51:24,332 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 20/391 | Loss 0.8005 | Acc 0.7492\n",
      "2025-07-27 17:51:24,897 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 30/391 | Loss 0.8043 | Acc 0.7513\n",
      "2025-07-27 17:51:25,474 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 40/391 | Loss 0.8602 | Acc 0.7490\n",
      "2025-07-27 17:51:26,047 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 50/391 | Loss 0.8200 | Acc 0.7481\n",
      "2025-07-27 17:51:26,620 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 60/391 | Loss 0.8990 | Acc 0.7431\n",
      "2025-07-27 17:51:27,286 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 70/391 | Loss 0.8596 | Acc 0.7417\n",
      "2025-07-27 17:51:29,208 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 80/391 | Loss 0.8520 | Acc 0.7406\n",
      "2025-07-27 17:51:30,639 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 90/391 | Loss 0.8380 | Acc 0.7405\n",
      "2025-07-27 17:51:31,819 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 100/391 | Loss 0.8373 | Acc 0.7420\n",
      "2025-07-27 17:51:32,864 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 110/391 | Loss 0.8228 | Acc 0.7427\n",
      "2025-07-27 17:51:33,801 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 120/391 | Loss 0.8575 | Acc 0.7427\n",
      "2025-07-27 17:51:34,731 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 130/391 | Loss 0.8329 | Acc 0.7428\n",
      "2025-07-27 17:51:35,684 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 140/391 | Loss 0.8764 | Acc 0.7417\n",
      "2025-07-27 17:51:36,671 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 150/391 | Loss 0.8519 | Acc 0.7415\n",
      "2025-07-27 17:51:37,752 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 160/391 | Loss 0.8704 | Acc 0.7409\n",
      "2025-07-27 17:51:39,045 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 170/391 | Loss 0.8518 | Acc 0.7408\n",
      "2025-07-27 17:51:40,422 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 180/391 | Loss 0.8337 | Acc 0.7410\n",
      "2025-07-27 17:51:41,663 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 190/391 | Loss 0.8661 | Acc 0.7412\n",
      "2025-07-27 17:51:42,736 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 200/391 | Loss 0.9013 | Acc 0.7407\n",
      "2025-07-27 17:51:43,648 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 210/391 | Loss 0.9346 | Acc 0.7394\n",
      "2025-07-27 17:51:44,595 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 220/391 | Loss 0.8298 | Acc 0.7396\n",
      "2025-07-27 17:51:45,523 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 230/391 | Loss 0.8702 | Acc 0.7387\n",
      "2025-07-27 17:51:46,478 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 240/391 | Loss 0.8718 | Acc 0.7385\n",
      "2025-07-27 17:51:47,506 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 250/391 | Loss 0.8518 | Acc 0.7384\n",
      "2025-07-27 17:51:48,721 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 260/391 | Loss 0.9672 | Acc 0.7372\n",
      "2025-07-27 17:51:50,064 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 270/391 | Loss 0.8948 | Acc 0.7365\n",
      "2025-07-27 17:51:51,329 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 280/391 | Loss 0.8882 | Acc 0.7363\n",
      "2025-07-27 17:51:52,495 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 290/391 | Loss 0.9368 | Acc 0.7357\n",
      "2025-07-27 17:51:53,443 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 300/391 | Loss 0.9071 | Acc 0.7352\n",
      "2025-07-27 17:51:54,389 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 310/391 | Loss 0.8291 | Acc 0.7352\n",
      "2025-07-27 17:51:55,364 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 320/391 | Loss 0.9103 | Acc 0.7348\n",
      "2025-07-27 17:51:56,674 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 330/391 | Loss 0.9486 | Acc 0.7339\n",
      "2025-07-27 17:51:57,882 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 340/391 | Loss 0.9525 | Acc 0.7330\n",
      "2025-07-27 17:51:59,328 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 350/391 | Loss 1.0403 | Acc 0.7317\n",
      "2025-07-27 17:52:00,423 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 360/391 | Loss 0.9021 | Acc 0.7313\n",
      "2025-07-27 17:52:01,608 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 370/391 | Loss 0.9750 | Acc 0.7305\n",
      "2025-07-27 17:52:02,697 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 380/391 | Loss 0.9898 | Acc 0.7296\n",
      "2025-07-27 17:52:03,530 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 | Batch 390/391 | Loss 0.9356 | Acc 0.7290\n",
      "2025-07-27 17:52:03,590 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14 completed | Loss: 0.8838 | Acc: 0.7290\n",
      "2025/07/27 17:52:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:52:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:52:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 14\n",
      "Created version '14' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:52:19,261 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '13'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.72898'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:52:19.197607'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:52:19,262 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 14/15 | Time: 40.4s | ETA: 0.6min\n",
      "2025-07-27 17:52:19,262 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 15, total batches: 391\n",
      "2025-07-27 17:52:19,862 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 10/391 | Loss 0.7391 | Acc 0.7734\n",
      "2025-07-27 17:52:20,460 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 20/391 | Loss 0.7721 | Acc 0.7676\n",
      "2025-07-27 17:52:21,140 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 30/391 | Loss 0.7490 | Acc 0.7685\n",
      "2025-07-27 17:52:21,961 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 40/391 | Loss 0.8322 | Acc 0.7635\n",
      "2025-07-27 17:52:22,809 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 50/391 | Loss 0.7706 | Acc 0.7606\n",
      "2025-07-27 17:52:23,602 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 60/391 | Loss 0.8193 | Acc 0.7602\n",
      "2025-07-27 17:52:24,360 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 70/391 | Loss 0.7572 | Acc 0.7607\n",
      "2025-07-27 17:52:25,121 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 80/391 | Loss 0.7838 | Acc 0.7604\n",
      "2025-07-27 17:52:25,876 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 90/391 | Loss 0.7939 | Acc 0.7622\n",
      "2025-07-27 17:52:26,611 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 100/391 | Loss 0.8319 | Acc 0.7592\n",
      "2025-07-27 17:52:27,360 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 110/391 | Loss 0.8162 | Acc 0.7573\n",
      "2025-07-27 17:52:28,098 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 120/391 | Loss 0.7694 | Acc 0.7584\n",
      "2025-07-27 17:52:28,831 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 130/391 | Loss 0.8218 | Acc 0.7570\n",
      "2025-07-27 17:52:29,564 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 140/391 | Loss 0.8199 | Acc 0.7568\n",
      "2025-07-27 17:52:30,299 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 150/391 | Loss 0.8101 | Acc 0.7564\n",
      "2025-07-27 17:52:31,075 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 160/391 | Loss 0.8040 | Acc 0.7557\n",
      "2025-07-27 17:52:31,831 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 170/391 | Loss 0.8604 | Acc 0.7544\n",
      "2025-07-27 17:52:32,571 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 180/391 | Loss 0.8413 | Acc 0.7538\n",
      "2025-07-27 17:52:33,313 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 190/391 | Loss 0.7625 | Acc 0.7546\n",
      "2025-07-27 17:52:34,037 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 200/391 | Loss 0.8524 | Acc 0.7535\n",
      "2025-07-27 17:52:34,759 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 210/391 | Loss 0.8730 | Acc 0.7521\n",
      "2025-07-27 17:52:35,473 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 220/391 | Loss 0.8279 | Acc 0.7517\n",
      "2025-07-27 17:52:36,189 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 230/391 | Loss 0.8140 | Acc 0.7518\n",
      "2025-07-27 17:52:36,907 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 240/391 | Loss 0.9070 | Acc 0.7507\n",
      "2025-07-27 17:52:37,635 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 250/391 | Loss 0.8922 | Acc 0.7493\n",
      "2025-07-27 17:52:38,371 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 260/391 | Loss 0.8508 | Acc 0.7488\n",
      "2025-07-27 17:52:39,092 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 270/391 | Loss 0.8589 | Acc 0.7486\n",
      "2025-07-27 17:52:39,851 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 280/391 | Loss 0.8817 | Acc 0.7478\n",
      "2025-07-27 17:52:40,647 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 290/391 | Loss 0.8282 | Acc 0.7481\n",
      "2025-07-27 17:52:41,451 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 300/391 | Loss 0.8243 | Acc 0.7482\n",
      "2025-07-27 17:52:42,300 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 310/391 | Loss 0.8960 | Acc 0.7477\n",
      "2025-07-27 17:52:43,146 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 320/391 | Loss 0.8806 | Acc 0.7472\n",
      "2025-07-27 17:52:43,984 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 330/391 | Loss 0.8845 | Acc 0.7466\n",
      "2025-07-27 17:52:44,799 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 340/391 | Loss 0.9178 | Acc 0.7457\n",
      "2025-07-27 17:52:45,606 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 350/391 | Loss 0.8549 | Acc 0.7451\n",
      "2025-07-27 17:52:46,404 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 360/391 | Loss 0.8902 | Acc 0.7446\n",
      "2025-07-27 17:52:47,211 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 370/391 | Loss 0.9251 | Acc 0.7439\n",
      "2025-07-27 17:52:48,011 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 380/391 | Loss 0.9333 | Acc 0.7432\n",
      "2025-07-27 17:52:48,814 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 | Batch 390/391 | Loss 1.0277 | Acc 0.7421\n",
      "2025-07-27 17:52:48,872 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15 completed | Loss: 0.8408 | Acc: 0.7420\n",
      "2025/07/27 17:52:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/27 17:52:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'ResNet18-CIFAR-100' already exists. Creating a new version of this model...\n",
      "2025/07/27 17:52:56 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ResNet18-CIFAR-100, version 15\n",
      "Created version '15' of model 'ResNet18-CIFAR-100'.\n",
      "2025-07-27 17:52:57,310 - WARNING - 1164146881.py - PID:35199 - TID:8462606080 - Failed to log model metadata: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Params were already logged='[{'key': 'best_epoch', 'old_value': '0', 'new_value': '14'}, {'key': 'best_accuracy', 'old_value': '0.29494', 'new_value': '0.742'}, {'key': 'checkpoint_time', 'old_value': '2025-07-27T17:42:23.251384', 'new_value': '2025-07-27T17:52:57.246472'}]' for run ID='9350c1d03e464b2ba5ca54f6a3a20942'.\n",
      "2025-07-27 17:52:57,311 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 15/15 | Time: 29.6s | ETA: 0.0min\n",
      "2025-07-27 17:52:57,540 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Training completed. Summary: {'final_total_training_time_minutes': 11.33, 'final_best_accuracy': 0.742, 'final_epochs_completed': 15}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " View run ResNet18_20250727_174137 at: https://neuralripper.com/mlflow/#/experiments/2/runs/9350c1d03e464b2ba5ca54f6a3a20942\n",
      " View experiment at: https://neuralripper.com/mlflow/#/experiments/2\n",
      "\n",
      "Training Summary:\n",
      "Total time: 11.3 minutes\n",
      "Best accuracy: 0.7420\n",
      "Epochs completed: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'final_total_training_time_minutes': 11.33,\n",
       " 'final_best_accuracy': 0.742,\n",
       " 'final_epochs_completed': 15}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training with comprehensive monitoring\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" STARTING ENHANCED RESNET18 TRAINING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset: CIFAR-100 (100 classes)\")\n",
    "print(f\"Model: ResNet18 (pretrained)\")\n",
    "print(f\"Epochs: {model._num_epochs}\")\n",
    "print(f\"Batch size: {model._batch_size}\")\n",
    "print(f\"Learning rate: {model._learning_rate}\")\n",
    "print(f\"MLflow tracking: {'Enabled' if model._use_mlflow else 'Disabled'}\")\n",
    "print(f\"MLflow URI: {model.monitor.mlflow_uri}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Start training\n",
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4azPxuZ3IIJj",
   "metadata": {
    "id": "4azPxuZ3IIJj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ripper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
