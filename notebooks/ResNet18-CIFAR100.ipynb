{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2ggWf9vEG2G-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28384,
     "status": "ok",
     "timestamp": 1752032437012,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "2ggWf9vEG2G-",
    "outputId": "6805092d-2ea7-47b2-d4a8-79216c2b2d25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(51787) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (3.1.1)\n",
      "Requirement already satisfied: mlflow-skinny==3.1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: Flask<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.1.1)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.16.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (3.10.3)\n",
      "Requirement already satisfied: numpy<3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.2.6)\n",
      "Requirement already satisfied: pandas<3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.3.0)\n",
      "Requirement already satisfied: pyarrow<21,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (20.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.7.0)\n",
      "Requirement already satisfied: scipy<2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (1.16.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow) (2.0.41)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.57.0)\n",
      "Requirement already satisfied: fastapi<1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.115.14)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (1.34.1)\n",
      "Requirement already satisfied: packaging<26 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (25.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.1)\n",
      "Requirement already satisfied: uvicorn<1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from mlflow-skinny==3.1.1->mlflow) (0.35.0)\n",
      "Requirement already satisfied: Mako in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.40.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.46.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.7.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (0.55b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/yj/.pyenv/versions/3.11.13/envs/ripper/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import platform\n",
    "import psutil\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "urSU2kGpG2Ev",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752032437016,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "urSU2kGpG2Ev"
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "format = '%(asctime)s - %(levelname)s - %(filename)s - PID:%(process)d - TID:%(thread)d - %(message)s'\n",
    "logger = logging.getLogger(__name__ + str(time.time()))\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False\n",
    "\n",
    "# Add handler if none exists\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(format))\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1ybWcfyuG2Co",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10335,
     "status": "ok",
     "timestamp": 1752032447352,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "1ybWcfyuG2Co",
    "outputId": "e9cd40a4-1969-4734-d3c4-79aeaeb3c2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Number of classes: 100\n",
      "Class names (first 10): ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']\n"
     ]
    }
   ],
   "source": [
    "# Data transforms for CIFAR-100\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Data augmentation\n",
    "    transforms.RandomHorizontalFlip(0.5),   # Random horizontal flip\n",
    "    transforms.ToTensor(),                  # Convert to tensor\n",
    "    transforms.Normalize(                   # Normalize with ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "train_ds = datasets.CIFAR100(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_tf\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {len(train_ds)}\")\n",
    "print(f\"Number of classes: {len(train_ds.classes)}\")\n",
    "print(f\"Class names (first 10): {train_ds.classes[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "FFBn09-QG2AV",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752032447356,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "FFBn09-QG2AV"
   },
   "outputs": [],
   "source": [
    "# Optional: Visualize a sample of the data\n",
    "def visualize_samples(dataset, num_samples=16):\n",
    "    \"\"\"Visualize a sample of images from the dataset\"\"\"\n",
    "    # Create subset for visualization\n",
    "    sample_indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img_tensor, class_idx = dataset[idx]\n",
    "\n",
    "        # Denormalize image for display\n",
    "        img = img_tensor.permute(1, 2, 0)\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Class: {dataset.classes[class_idx]}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to visualize samples\n",
    "# visualize_samples(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "oMNMArItG1-A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752032447361,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "oMNMArItG1-A",
    "outputId": "ec25a78f-703e-4e58-8381-3576f5798d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per epoch: 391\n",
      "Total samples per epoch: 50048\n"
     ]
    }
   ],
   "source": [
    "# Create data loader\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,      # Set to 0 for MPS compatibility\n",
    "    pin_memory=False    # Disable for MPS\n",
    ")\n",
    "\n",
    "print(f\"Number of batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Total samples per epoch: {len(train_loader) * 128}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3pz1kG53G170",
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1752032447485,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "3pz1kG53G170"
   },
   "outputs": [],
   "source": [
    "class ComprehensiveTrainingMonitor:\n",
    "    \"\"\"Enhanced training monitor with MLflow integration and comprehensive metrics\"\"\"\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device, model_name='ResNet18',\n",
    "                 dataset_name='CIFAR-100', batch_size=128, epochs=100,\n",
    "                 input_size=(3, 32, 32), use_mlflow=True,\n",
    "                 learning_rate=5e-3, use_pretrained=True, train_size=50000,\n",
    "                 val_size=10000, num_workers=0):\n",
    "\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        self.dataset_name = dataset_name\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.input_size = input_size\n",
    "        self.use_mlflow = use_mlflow\n",
    "        self.learning_rate = learning_rate\n",
    "        self.use_pretrained = use_pretrained\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        # Tracking variables\n",
    "        self.best_metric = float('-inf')\n",
    "        self.epoch_times = []\n",
    "        self.start_time = time.time()\n",
    "        self.run_started = False\n",
    "\n",
    "        # MLflow configuration\n",
    "        self.mlflow_uri = \"https://neuralripper.com/mlflow/\"\n",
    "\n",
    "        if self.use_mlflow:\n",
    "            self._initialize_mlflow()\n",
    "\n",
    "    def _initialize_mlflow(self):\n",
    "        \"\"\"Initialize MLflow with comprehensive experiment tracking\n",
    "        MLflow routes registry operations through your remote server instead of trying to write locally. \n",
    "        The server handles the separation:\n",
    "        registry metadata goes to your database backend, artifacts go to S3.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mlflow.set_tracking_uri(self.mlflow_uri)\n",
    "            mlflow.set_registry_uri(self.mlflow_uri) \n",
    "            mlflow.set_experiment(f\"{self.model_name}-{self.dataset_name}\")\n",
    "\n",
    "            # Start run with timestamp\n",
    "            run_name = f\"{self.model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "            mlflow.start_run(run_name=run_name)\n",
    "            self.run_started = True\n",
    "\n",
    "            # Log all parameters\n",
    "            params = {\n",
    "                **self._get_model_params(),\n",
    "                **self._get_system_params(),\n",
    "                **self._get_environment_params(),\n",
    "                **self._get_data_params(),\n",
    "                **self._get_training_params(),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(params)\n",
    "            logger.info(f\"MLflow run started: {run_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to initialize MLflow: {e}\")\n",
    "            self.use_mlflow = False\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Model architecture and hyperparameters\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"model_type\": \"classification\",\n",
    "            \"pretrained\": self.use_pretrained,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"optimizer\": self.optimizer.__class__.__name__,\n",
    "            \"criterion\": self.criterion.__class__.__name__,\n",
    "            \"input_channels\": self.input_size[0],\n",
    "            \"input_height\": self.input_size[1],\n",
    "            \"input_width\": self.input_size[2],\n",
    "        }\n",
    "\n",
    "    def _get_system_params(self):\n",
    "        \"\"\"System hardware and software parameters\"\"\"\n",
    "        gpu_info = {}\n",
    "        if torch.cuda.is_available():\n",
    "            props = torch.cuda.get_device_properties(0)\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": torch.cuda.get_device_name(0),\n",
    "                \"gpu_memory_gb\": round(props.total_memory / (1024**3), 2),\n",
    "                \"cuda_version\": torch.version.cuda,\n",
    "                \"num_gpus\": torch.cuda.device_count(),\n",
    "            }\n",
    "        elif torch.backends.mps.is_available():\n",
    "            gpu_info = {\n",
    "                \"gpu_name\": \"Apple Silicon MPS\",\n",
    "                \"device_type\": \"mps\"\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"cpu_count\": psutil.cpu_count(),\n",
    "            \"memory_total_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"python_version\": platform.python_version(),\n",
    "            \"pytorch_version\": torch.__version__,\n",
    "            **gpu_info\n",
    "        }\n",
    "\n",
    "    def _get_environment_params(self):\n",
    "        \"\"\"Environment and reproducibility parameters\"\"\"\n",
    "        git_info = {}\n",
    "        try:\n",
    "            commit = subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip()\n",
    "            branch = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD']).decode().strip()\n",
    "            git_info = {\n",
    "                \"git_commit\": commit[:8],\n",
    "                \"git_branch\": branch,\n",
    "            }\n",
    "        except:\n",
    "            git_info = {\"git_commit\": \"unknown\", \"git_branch\": \"unknown\"}\n",
    "\n",
    "        return git_info\n",
    "\n",
    "    def _get_data_params(self):\n",
    "        \"\"\"Data pipeline parameters\"\"\"\n",
    "        return {\n",
    "            \"train_size\": self.train_size,\n",
    "            \"val_size\": self.val_size,\n",
    "            \"total_samples\": self.train_size + self.val_size,\n",
    "            \"num_workers\": self.num_workers,\n",
    "        }\n",
    "\n",
    "    def _get_training_params(self):\n",
    "        \"\"\"Advanced training configuration\"\"\"\n",
    "        return {\n",
    "            \"mlflow_uri\": self.mlflow_uri,\n",
    "            \"experiment_name\": f\"{self.model_name}-{self.dataset_name}\",\n",
    "        }\n",
    "\n",
    "    def log_epoch_metrics(self, epoch, epoch_loss, epoch_acc, batch_count=None):\n",
    "        \"\"\"Comprehensive epoch metrics logging\"\"\"\n",
    "        if not self.use_mlflow or not self.run_started:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            epoch_time = self.epoch_times[-1] if self.epoch_times else 0\n",
    "\n",
    "            # Core metrics\n",
    "            metrics = {\n",
    "                \"train_loss\": epoch_loss,\n",
    "                \"train_accuracy\": epoch_acc,\n",
    "                \"epoch_time_seconds\": epoch_time,\n",
    "                \"learning_rate\": self.optimizer.param_groups[0]['lr'],\n",
    "            }\n",
    "\n",
    "            # Performance metrics\n",
    "            if batch_count:\n",
    "                metrics[\"batches_per_second\"] = batch_count / epoch_time if epoch_time > 0 else 0\n",
    "                metrics[\"samples_per_second\"] = (batch_count * self.batch_size) / epoch_time if epoch_time > 0 else 0\n",
    "\n",
    "            # Memory metrics\n",
    "            if torch.cuda.is_available():\n",
    "                metrics[\"gpu_memory_allocated_gb\"] = torch.cuda.memory_allocated() / (1024**3)\n",
    "                metrics[\"gpu_memory_reserved_gb\"] = torch.cuda.memory_reserved() / (1024**3)\n",
    "\n",
    "            # Running statistics\n",
    "            total_time = sum(self.epoch_times)\n",
    "            metrics[\"total_time_minutes\"] = total_time / 60\n",
    "            metrics[\"average_epoch_time\"] = np.mean(self.epoch_times) if self.epoch_times else 0\n",
    "\n",
    "            mlflow.log_metrics(metrics, step=epoch)\n",
    "\n",
    "            # Update best model if improved\n",
    "            if epoch_acc > self.best_metric:\n",
    "                self.best_metric = epoch_acc\n",
    "                self._log_model_checkpoint(epoch)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log metrics for epoch {epoch}: {e}\")\n",
    "\n",
    "    def _log_model_checkpoint(self, epoch):\n",
    "        \"\"\"Log model checkpoint and metadata\"\"\"\n",
    "        try:\n",
    "            # Create sample input as numpy array (CPU)\n",
    "            sample_input = torch.randn(1, *self.input_size)\n",
    "            sample_input_np = sample_input.numpy()\n",
    "            \n",
    "            # Get model prediction and convert to numpy\n",
    "            with torch.no_grad():\n",
    "                sample_output = self.model(sample_input.to(self.device))\n",
    "                sample_output_np = sample_output.cpu().numpy()\n",
    "            \n",
    "            # Manually infer signature using numpy arrays\n",
    "            from mlflow.models import infer_signature\n",
    "            signature = infer_signature(sample_input_np, sample_output_np)\n",
    "            \n",
    "            # Log model with signature (no input_example needed)\n",
    "            mlflow.pytorch.log_model(\n",
    "                self.model,\n",
    "                artifact_path=\"model\",\n",
    "                registered_model_name=f\"{self.model_name}-{self.dataset_name}\",\n",
    "                signature=signature,\n",
    "                pip_requirements=[\"torch\", \"torchvision\", \"pillow\", \"numpy\"]\n",
    "            )\n",
    "\n",
    "            # Log additional metadata\n",
    "            model_metadata = {\n",
    "                \"best_epoch\": epoch,\n",
    "                \"best_accuracy\": self.best_metric,\n",
    "                \"checkpoint_time\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(model_metadata)\n",
    "            logger.info(f\"Model metadata logged for accuracy: {self.best_metric:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to log model metadata: {e}\")\n",
    "\n",
    "    def end_run(self, status=\"FINISHED\"):\n",
    "        \"\"\"Clean up and end MLflow run\"\"\"\n",
    "        if self.use_mlflow and self.run_started:\n",
    "            try:\n",
    "                total_time = time.time() - self.start_time\n",
    "                summary = {\n",
    "                    \"final_total_training_time_minutes\": round(total_time / 60, 2),\n",
    "                    \"final_best_accuracy\": self.best_metric,\n",
    "                    \"final_epochs_completed\": len(self.epoch_times),\n",
    "                }\n",
    "                mlflow.log_params(summary)\n",
    "                mlflow.end_run(status=status)\n",
    "                self.run_started = False\n",
    "                return summary\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to end MLflow run properly: {e}\")\n",
    "                return {}\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "J_Cn29LwG15g",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752032447493,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "J_Cn29LwG15g"
   },
   "outputs": [],
   "source": [
    "class EnhancedResNet18:\n",
    "    \"\"\"ResNet18 with comprehensive monitoring integration\"\"\"\n",
    "\n",
    "    def __init__(self, num_epochs=100, batch_size=128, num_classes=100,\n",
    "                 learning_rate=5e-3, use_mlflow=True):\n",
    "        # Core parameters\n",
    "        self._num_classes = num_classes\n",
    "        self._use_mlflow = use_mlflow\n",
    "        self._batch_size = batch_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        # Create model components\n",
    "        self._model = self._create_model()\n",
    "        self._device = self._set_device()\n",
    "        self._model.to(self._device)\n",
    "        self._criterion = self._set_criterion()\n",
    "        self._optimizer = self._set_optimizer()\n",
    "\n",
    "        # Initialize comprehensive monitor\n",
    "        self.monitor = ComprehensiveTrainingMonitor(\n",
    "            model=self._model,\n",
    "            optimizer=self._optimizer,\n",
    "            criterion=self._criterion,\n",
    "            device=self._device,\n",
    "            model_name='ResNet18',\n",
    "            dataset_name='CIFAR-100',\n",
    "            batch_size=batch_size,\n",
    "            epochs=num_epochs,\n",
    "            input_size=(3, 32, 32),\n",
    "            learning_rate=learning_rate,\n",
    "            use_mlflow=use_mlflow,\n",
    "            use_pretrained=True,\n",
    "            train_size=50000,\n",
    "            val_size=10000,\n",
    "            num_workers=0,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Model initialized on device: {self._device}\")\n",
    "        logger.info(f\"Model parameters: {sum(p.numel() for p in self._model.parameters()):,}\")\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Create ResNet18 model with CIFAR-100 adaptation\"\"\"\n",
    "        model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        # Adapt classifier for CIFAR-100 (100 classes)\n",
    "        model.fc = nn.Linear(model.fc.in_features, self._num_classes)\n",
    "        return model\n",
    "\n",
    "    def _set_device(self):\n",
    "        \"\"\"Set appropriate device for training\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def _set_optimizer(self):\n",
    "        \"\"\"Configure SGD optimizer with momentum and weight decay\"\"\"\n",
    "        return optim.SGD(self._model.parameters(),\n",
    "                        lr=self._learning_rate,\n",
    "                        momentum=0.9,\n",
    "                        weight_decay=4e-5)\n",
    "\n",
    "    def _set_criterion(self):\n",
    "        \"\"\"Set loss function for classification\"\"\"\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    def train_epoch(self, data_loader, epoch_idx):\n",
    "        \"\"\"Enhanced training epoch with comprehensive monitoring\"\"\"\n",
    "        logger.info(f\"Starting epoch {epoch_idx+1}, total batches: {len(data_loader)}\")\n",
    "\n",
    "        self._model.train()\n",
    "        epoch_total_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "        batch_count = len(data_loader)\n",
    "\n",
    "        for idx, (images, targets) in enumerate(data_loader):\n",
    "            images = images.to(self._device)\n",
    "            targets = targets.to(self._device)\n",
    "\n",
    "            self._optimizer.zero_grad()\n",
    "            logits = self._model(images)\n",
    "            loss = self._criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            running_correct += (predictions == targets).sum().item()\n",
    "            running_total += targets.size(0)\n",
    "            running_loss += loss.item()\n",
    "            epoch_total_loss += loss.item()\n",
    "\n",
    "            # Log progress every 10 batches\n",
    "            if idx % 10 == 9:\n",
    "                avg_loss = running_loss / 10\n",
    "                acc_sofar = running_correct / running_total\n",
    "                logger.info(f\"Epoch {epoch_idx+1} | Batch {idx+1}/{batch_count} | \"\n",
    "                          f\"Loss {avg_loss:.4f} | Acc {acc_sofar:.4f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = epoch_total_loss / batch_count\n",
    "        epoch_acc = running_correct / running_total\n",
    "\n",
    "        logger.info(f\"Epoch {epoch_idx+1} completed | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    def train(self, data_loader):\n",
    "        \"\"\"Full training loop with comprehensive monitoring\"\"\"\n",
    "        logger.info(\"Starting training process\")\n",
    "\n",
    "        try:\n",
    "            for epoch in range(self._num_epochs):\n",
    "                epoch_start = time.time()\n",
    "\n",
    "                # Train for one epoch\n",
    "                epoch_loss, epoch_acc = self.train_epoch(data_loader, epoch)\n",
    "\n",
    "                # Track timing\n",
    "                epoch_time = time.time() - epoch_start\n",
    "                self.monitor.epoch_times.append(epoch_time)\n",
    "\n",
    "                # Log metrics\n",
    "                self.monitor.log_epoch_metrics(epoch, epoch_loss, epoch_acc, len(data_loader))\n",
    "\n",
    "                # Progress report\n",
    "                eta = np.mean(self.monitor.epoch_times) * (self._num_epochs - epoch - 1)\n",
    "                logger.info(f\"Epoch {epoch+1}/{self._num_epochs} | \"\n",
    "                          f\"Time: {epoch_time:.1f}s | ETA: {eta/60:.1f}min\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            logger.info(\"Training interrupted by user\")\n",
    "            summary = self.monitor.end_run(status=\"KILLED\")\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training failed with error: {e}\")\n",
    "            summary = self.monitor.end_run(status=\"FAILED\")\n",
    "            raise e\n",
    "\n",
    "        # Training completed\n",
    "        summary = self.monitor.end_run(status=\"FINISHED\")\n",
    "        logger.info(f\"Training completed. Summary: {summary}\")\n",
    "\n",
    "        if summary:\n",
    "            print(f\"\\nTraining Summary:\")\n",
    "            print(f\"Total time: {summary.get('final_total_training_time_minutes', 0):.1f} minutes\")\n",
    "            print(f\"Best accuracy: {summary.get('final_best_accuracy', 0):.4f}\")\n",
    "            print(f\"Epochs completed: {summary.get('final_epochs_completed', 0)}\")\n",
    "\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dscyqDcSG13Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4360,
     "status": "ok",
     "timestamp": 1752032451857,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "dscyqDcSG13Y",
    "outputId": "49b47bc4-6282-474f-afb6-9a16e35da61c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 20:42:49,397 - INFO - 2353954694.py - PID:35199 - TID:8462606080 - Initializing Enhanced ResNet18 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No active runs to clear\n",
      "Active run after cleanup: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(76638) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76639) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "2025-08-07 20:42:49,955 - INFO - 1823654903.py - PID:35199 - TID:8462606080 - MLflow run started: ResNet18_20250807_204249\n",
      "2025-08-07 20:42:49,955 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Model initialized on device: mps\n",
      "2025-08-07 20:42:49,956 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Model parameters: 11,227,812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully!\n",
      "Device: mps\n",
      "Total parameters: 11,227,812\n",
      "Trainable parameters: 11,227,812\n"
     ]
    }
   ],
   "source": [
    "# Clear any existing MLflow runs\n",
    "import mlflow\n",
    "\n",
    "# End any active runs\n",
    "try: \n",
    "    if mlflow.active_run():\n",
    "        print(f\"Ending active run: {mlflow.active_run().info.run_id}\")\n",
    "        mlflow.end_run()\n",
    "        print(\"Active run ended\")\n",
    "    else:\n",
    "        print(\"No active runs to clear\")\n",
    "except:\n",
    "    mlflow.end_run(status=\"KILLED\")\n",
    "\n",
    "# Verify no active runs\n",
    "print(f\"Active run after cleanup: {mlflow.active_run()}\")\n",
    "\n",
    "# Initialize and train the model\n",
    "logger.info(\"Initializing Enhanced ResNet18 model\")\n",
    "\n",
    "model = EnhancedResNet18(\n",
    "    num_epochs=1,\n",
    "    batch_size=128,\n",
    "    num_classes=100,\n",
    "    learning_rate=5e-3,\n",
    "    use_mlflow=True\n",
    ")\n",
    "\n",
    "print(\"Model initialized successfully!\")\n",
    "print(f\"Device: {model._device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model._model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model._model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "W7KCg0BcG1xW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1177153,
     "status": "ok",
     "timestamp": 1752033629012,
     "user": {
      "displayName": "DizzyDoze",
      "userId": "13303002129287970688"
     },
     "user_tz": 420
    },
    "id": "W7KCg0BcG1xW",
    "outputId": "49417a52-6e5a-4205-e45a-d57a3cd35ec8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 20:42:49,962 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting training process\n",
      "2025-08-07 20:42:49,963 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Starting epoch 1, total batches: 391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " STARTING ENHANCED RESNET18 TRAINING\n",
      "==================================================\n",
      "Dataset: CIFAR-100 (100 classes)\n",
      "Model: ResNet18 (pretrained)\n",
      "Epochs: 1\n",
      "Batch size: 128\n",
      "Learning rate: 0.005\n",
      "MLflow tracking: Enabled\n",
      "MLflow URI: https://neuralripper.com/mlflow/\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 20:42:50,536 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 10/391 | Loss 4.7956 | Acc 0.0164\n",
      "2025-08-07 20:42:51,082 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 20/391 | Loss 4.4209 | Acc 0.0371\n",
      "2025-08-07 20:42:51,654 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 30/391 | Loss 4.1440 | Acc 0.0565\n",
      "2025-08-07 20:42:52,193 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 40/391 | Loss 3.8468 | Acc 0.0797\n",
      "2025-08-07 20:42:52,727 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 50/391 | Loss 3.6133 | Acc 0.0967\n",
      "2025-08-07 20:42:53,258 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 60/391 | Loss 3.5381 | Acc 0.1100\n",
      "2025-08-07 20:42:53,788 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 70/391 | Loss 3.3313 | Acc 0.1225\n",
      "2025-08-07 20:42:54,320 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 80/391 | Loss 3.2971 | Acc 0.1339\n",
      "2025-08-07 20:42:54,853 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 90/391 | Loss 3.2153 | Acc 0.1439\n",
      "2025-08-07 20:42:55,387 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 100/391 | Loss 2.9875 | Acc 0.1566\n",
      "2025-08-07 20:42:55,922 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 110/391 | Loss 3.0367 | Acc 0.1658\n",
      "2025-08-07 20:42:56,455 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 120/391 | Loss 2.9611 | Acc 0.1745\n",
      "2025-08-07 20:42:56,992 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 130/391 | Loss 2.8286 | Acc 0.1820\n",
      "2025-08-07 20:42:57,526 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 140/391 | Loss 2.7790 | Acc 0.1900\n",
      "2025-08-07 20:42:58,062 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 150/391 | Loss 2.7257 | Acc 0.1981\n",
      "2025-08-07 20:42:58,598 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 160/391 | Loss 2.7467 | Acc 0.2038\n",
      "2025-08-07 20:42:59,132 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 170/391 | Loss 2.7897 | Acc 0.2091\n",
      "2025-08-07 20:42:59,667 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 180/391 | Loss 2.6555 | Acc 0.2161\n",
      "2025-08-07 20:43:00,204 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 190/391 | Loss 2.5302 | Acc 0.2234\n",
      "2025-08-07 20:43:00,740 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 200/391 | Loss 2.5687 | Acc 0.2286\n",
      "2025-08-07 20:43:01,272 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 210/391 | Loss 2.5699 | Acc 0.2342\n",
      "2025-08-07 20:43:01,807 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 220/391 | Loss 2.5766 | Acc 0.2384\n",
      "2025-08-07 20:43:02,342 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 230/391 | Loss 2.5722 | Acc 0.2424\n",
      "2025-08-07 20:43:02,874 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 240/391 | Loss 2.5645 | Acc 0.2461\n",
      "2025-08-07 20:43:03,407 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 250/391 | Loss 2.5777 | Acc 0.2490\n",
      "2025-08-07 20:43:03,944 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 260/391 | Loss 2.4953 | Acc 0.2530\n",
      "2025-08-07 20:43:04,482 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 270/391 | Loss 2.4407 | Acc 0.2575\n",
      "2025-08-07 20:43:05,017 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 280/391 | Loss 2.4257 | Acc 0.2617\n",
      "2025-08-07 20:43:05,552 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 290/391 | Loss 2.4931 | Acc 0.2640\n",
      "2025-08-07 20:43:06,087 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 300/391 | Loss 2.4470 | Acc 0.2667\n",
      "2025-08-07 20:43:06,753 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 310/391 | Loss 2.3705 | Acc 0.2701\n",
      "2025-08-07 20:43:07,415 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 320/391 | Loss 2.3379 | Acc 0.2739\n",
      "2025-08-07 20:43:08,105 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 330/391 | Loss 2.4357 | Acc 0.2764\n",
      "2025-08-07 20:43:08,839 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 340/391 | Loss 2.4717 | Acc 0.2792\n",
      "2025-08-07 20:43:09,652 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 350/391 | Loss 2.3859 | Acc 0.2818\n",
      "2025-08-07 20:43:10,456 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 360/391 | Loss 2.3765 | Acc 0.2845\n",
      "2025-08-07 20:43:11,257 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 370/391 | Loss 2.2871 | Acc 0.2876\n",
      "2025-08-07 20:43:12,059 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 380/391 | Loss 2.3590 | Acc 0.2902\n",
      "2025-08-07 20:43:12,865 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 | Batch 390/391 | Loss 2.3131 | Acc 0.2930\n",
      "2025-08-07 20:43:12,924 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1 completed | Loss: 2.8533 | Acc: 0.2931\n",
      "2025-08-07 20:43:14,215 - WARNING - 1823654903.py - PID:35199 - TID:8462606080 - Failed to log model metadata: Expected more than 1 value per channel when training, got input size torch.Size([1, 512, 1, 1])\n",
      "2025-08-07 20:43:14,215 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Epoch 1/1 | Time: 23.0s | ETA: 0.0min\n",
      "2025-08-07 20:43:14,343 - INFO - 2563978282.py - PID:35199 - TID:8462606080 - Training completed. Summary: {'final_total_training_time_minutes': 0.41, 'final_best_accuracy': 0.29306, 'final_epochs_completed': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run ResNet18_20250807_204249 at: https://neuralripper.com/mlflow/#/experiments/1/runs/ac7ca9878551456db33f0847bef44bc2\n",
      "🧪 View experiment at: https://neuralripper.com/mlflow/#/experiments/1\n",
      "\n",
      "Training Summary:\n",
      "Total time: 0.4 minutes\n",
      "Best accuracy: 0.2931\n",
      "Epochs completed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'final_total_training_time_minutes': 0.41,\n",
       " 'final_best_accuracy': 0.29306,\n",
       " 'final_epochs_completed': 1}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training with comprehensive monitoring\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" STARTING ENHANCED RESNET18 TRAINING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset: CIFAR-100 (100 classes)\")\n",
    "print(f\"Model: ResNet18 (pretrained)\")\n",
    "print(f\"Epochs: {model._num_epochs}\")\n",
    "print(f\"Batch size: {model._batch_size}\")\n",
    "print(f\"Learning rate: {model._learning_rate}\")\n",
    "print(f\"MLflow tracking: {'Enabled' if model._use_mlflow else 'Disabled'}\")\n",
    "print(f\"MLflow URI: {model.monitor.mlflow_uri}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Start training\n",
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95768784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c8743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ripper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
